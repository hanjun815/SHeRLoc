  0%|                                                    | 0/80 [00:00<?, ?it/s]
0 82941 0.23922792077064514
1 82941 0.2464444935321808
2 82941 0.2222079485654831
3 82941 0.242836132645607
4 82941 0.2239437997341156
5 82941 0.20848573744297028
6 82941 0.20688138902187347
7 82941 0.20524828135967255
8 82941 0.2112174779176712
9 82941 0.20861764252185822
10 82941 0.21498888731002808
11 82941 0.21105773746967316
12 82941 0.21884344518184662
13 82941 0.21244919300079346
14 82941 0.20800234377384186
15 82941 0.20681189000606537
16 82941 0.20263732969760895
17 82941 0.20908698439598083
18 82941 0.20547670125961304
19 82941 0.2072724997997284
20 82941 0.20532360672950745
21 82941 0.20347726345062256
22 82941 0.20376121997833252
23 82941 0.20416520535945892
24 82941 0.20307770371437073
25 82941 0.2034226953983307
26 82941 0.20420362055301666
27 82941 0.20537494122982025
28 82941 0.2087915688753128
29 82941 0.2079043686389923
30 82941 0.20540018379688263
31 82941 0.20405833423137665
32 82941 0.20200078189373016
33 82941 0.2030126303434372
34 82941 0.2044835388660431
35 82941 0.20462535321712494
36 82941 0.20278790593147278
37 82941 0.20177672803401947
38 82941 0.20096434652805328
39 82941 0.20164528489112854
40 82941 0.2018793374300003
41 82941 0.2031966596841812
42 82941 0.20421729981899261
43 82941 0.20112387835979462
44 82941 0.20047608017921448
45 82941 0.19896596670150757
46 82941 0.20651111006736755
47 82941 0.20599162578582764
48 82941 0.19815200567245483
49 82941 0.19846664369106293
50 82941 0.19835712015628815
51 82941 0.19912143051624298
52 82941 0.20008151233196259
53 82941 0.20523706078529358
54 82941 0.1959424763917923
55 82941 0.19871936738491058
56 82941 0.200423926115036
57 82941 0.19780804216861725
58 82941 0.1868097186088562
59 82941 0.1981908082962036
60 82941 0.21056640148162842
61 82941 0.1999497264623642
62 82941 0.1945343166589737
63 82941 0.19547101855278015
64 82941 0.19939734041690826
65 82941 0.1961537003517151
66 82941 0.20148569345474243
67 82941 0.19769489765167236
68 82941 0.20311717689037323
69 82941 0.19316816329956055
70 82941 0.18422098457813263
71 82941 0.20814095437526703
72 82941 0.19774354994297028
73 82941 0.19642719626426697
74 82941 0.19943872094154358
75 82941 0.21303749084472656
76 82941 0.19168764352798462
77 82941 0.17340415716171265
78 82941 0.1827106922864914
79 82941 0.20437656342983246
80 82941 0.14352816343307495
81 82941 0.13770413398742676
82 82941 0.1892147809267044
83 82941 0.16029632091522217
84 82941 0.10241924971342087
85 82941 0.24393875896930695
86 82941 0.2671634256839752
87 82941 0.21342158317565918
88 82941 0.22099901735782623
89 82941 0.21489790081977844
90 82941 0.22113603353500366
91 82941 0.2067495584487915
92 82941 0.20782187581062317
93 82941 0.2071273922920227
94 82941 0.20397204160690308
95 82941 0.2047257274389267
96 82941 0.203270822763443
97 82941 0.20410244166851044
98 82941 0.2038542926311493
99 82941 0.20335568487644196
100 82941 0.20429319143295288
101 82941 0.20585274696350098
102 82941 0.20306621491909027
103 82941 0.20260068774223328
104 82941 0.20370547473430634
105 82941 0.20358256995677948
106 82941 0.2019517868757248
107 82941 0.20143701136112213
108 82941 0.20076651871204376
109 82941 0.20161184668540955
110 82941 0.2018182873725891
111 82941 0.20170378684997559
112 82941 0.20237964391708374
113 82941 0.20256198942661285
114 82941 0.20117826759815216
115 82941 0.19990216195583344
116 82941 0.2000642567873001
117 82941 0.2016438990831375
118 82941 0.20204313099384308
119 82941 0.20082345604896545
120 82941 0.19898384809494019
121 82941 0.2073216736316681
122 82941 0.20019225776195526
123 82941 0.20099660754203796
124 82941 0.20268471539020538
125 82941 0.20413820445537567
126 82941 0.20214131474494934
127 82941 0.1991479992866516
128 82941 0.19907623529434204
129 82941 0.19790595769882202
130 82941 0.19650696218013763
131 82941 0.19530680775642395
132 82941 0.19239966571331024
133 82941 0.1916697919368744
134 82941 0.19013959169387817
135 82941 0.18659812211990356
136 82941 0.18139752745628357
137 82941 0.20417846739292145
138 82941 0.21277914941310883
139 82941 0.20837628841400146
140 82941 0.20732228457927704
141 82941 0.2087692767381668
142 82941 0.20775316655635834
143 82941 0.20761454105377197
144 82941 0.20837882161140442
145 82941 0.2082919180393219
146 82941 0.20837153494358063
147 82941 0.20850251615047455
148 82941 0.2128039002418518
149 82941 0.21073609590530396
150 82941 0.20929892361164093
151 82941 0.2062927484512329
152 82941 0.207077294588089
153 82941 0.20736072957515717
154 82941 0.2060462385416031
155 82941 0.1961144059896469
156 82941 0.19045932590961456
157 82941 0.18461541831493378
158 82941 0.17209167778491974
159 82941 0.1558685451745987
160 82941 0.13651256263256073
161 82941 0.19642625749111176
162 82941 0.24412335455417633
163 82941 0.2098521739244461
164 82941 0.20533180236816406
165 82941 0.20460626482963562
166 82941 0.20388956367969513
167 82941 0.205400288105011
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 367, in do_train
    for index, (query, positives, negatives) in enumerate(dataloaders[phase]):
  File "/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1376, in _next_data
    return self._process_data(data)
  File "/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _process_data
    data.reraise()
  File "/usr/local/lib/python3.9/site-packages/torch/_utils.py", line 460, in reraise
    raise RuntimeError(msg) from None
RuntimeError: Caught UFuncTypeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/usr/local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 49, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/code/RLoc/training/dataset.py", line 642, in __getitem__
    closest_pos_idx = np.argmin(np.abs(np.array(seq_data['query_images'][index]) - np.array(seq_data['pos_images'])))
numpy.core._exceptions._UFuncNoLoopError: ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U96'), dtype('<U86')) -> None
