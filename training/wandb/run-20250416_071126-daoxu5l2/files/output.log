  0%|                                                    | 0/80 [00:00<?, ?it/s]
0 25113 0.5828163623809814
1 25113 0.9724087119102478
2 25113 0.802169680595398
3 25113 0.6883344054222107
4 25113 0.5903605222702026
5 25113 0.6485776901245117
6 25113 0.6911595463752747
7 25113 0.5434586405754089
8 25113 0.46542835235595703
9 25113 0.5392898917198181
10 25113 0.5088093876838684
11 25113 0.44528672099113464
12 25113 0.38056424260139465
13 25113 0.39380499720573425
14 25113 0.4266175627708435
15 25113 0.4595140218734741
16 25113 0.49605217576026917
17 25113 0.5599209070205688
18 25113 0.440833181142807
19 25113 0.4722317159175873
20 25113 0.569922685623169
21 25113 0.4514175057411194
22 25113 0.36273160576820374
23 25113 0.3397146761417389
24 25113 0.37838202714920044
25 25113 0.34408900141716003
26 25113 0.39540883898735046
27 25113 0.4653896391391754
28 25113 0.46518462896347046
29 25113 0.3948133885860443
30 25113 0.4149458408355713
31 25113 0.43410784006118774
32 25113 0.47585994005203247
33 25113 0.44257330894470215
34 25113 0.5019246339797974
35 25113 0.4737573266029358
36 25113 0.4831985533237457
37 25113 0.48148685693740845
38 25113 0.5137513875961304
39 25113 0.49469196796417236
40 25113 0.4678295850753784
41 25113 0.47932446002960205
42 25113 0.5234137773513794
43 25113 0.5446808934211731
44 25113 0.3945716619491577
45 25113 0.3683372735977173
46 25113 0.4397149085998535
47 25113 0.40864261984825134
48 25113 0.28029078245162964
49 25113 0.31897327303886414
50 25113 0.4147424101829529
51 25113 0.37690842151641846
52 25113 0.3879493772983551
53 25113 0.34634101390838623
54 25113 0.3819408416748047
55 25113 0.4248298406600952
56 25113 0.3309715986251831
57 25113 0.44608074426651
58 25113 0.45142698287963867
59 25113 0.3363705575466156
60 25113 0.23650440573692322
61 25113 0.25216251611709595
62 25113 0.3171076476573944
63 25113 0.3097323179244995
64 25113 0.34521567821502686
65 25113 0.40685296058654785
66 25113 0.3820632994174957
67 25113 0.3332856297492981
68 25113 0.39885151386260986
69 25113 0.4098193347454071
70 25113 0.37066298723220825
71 25113 0.40466782450675964
72 25113 0.4443981647491455
73 25113 0.4090367257595062
74 25113 0.44240856170654297
75 25113 0.3976910412311554
76 25113 0.45642486214637756
77 25113 0.45580577850341797
78 25113 0.4147340953350067
79 25113 0.4254835844039917
80 25113 0.396115779876709
81 25113 0.3832164406776428
82 25113 0.49653488397598267
83 25113 0.3753378689289093
84 25113 0.4726811647415161
85 25113 0.4930713176727295
86 25113 0.42413026094436646
87 25113 0.3629426956176758
88 25113 0.4240584373474121
89 25113 0.40666690468788147
90 25113 0.3268480896949768
91 25113 0.40359750390052795
92 25113 0.3936429023742676
93 25113 0.3167738616466522
94 25113 0.4125376045703888
95 25113 0.4118889272212982
96 25113 0.4296700358390808
97 25113 0.4098692834377289
98 25113 0.4526222348213196
99 25113 0.46015092730522156
100 25113 0.4081535339355469
101 25113 0.444922536611557
102 25113 0.3781867027282715
103 25113 0.350536972284317
104 25113 0.4286837577819824
105 25113 0.4681260287761688
106 25113 0.3553023934364319
107 25113 0.4451640248298645
108 25113 0.48001909255981445
109 25113 0.3716052174568176
110 25113 0.4598977565765381
111 25113 0.5002169013023376
112 25113 0.3852761387825012
113 25113 0.3814329504966736
114 25113 0.3325398564338684
115 25113 0.4437216818332672
116 25113 0.4028684198856354
117 25113 0.4156756103038788
118 25113 0.44571787118911743
119 25113 0.38855835795402527
120 25113 0.31780171394348145
121 25113 0.3931446075439453
122 25113 0.38462162017822266
123 25113 0.29566311836242676
124 25113 0.377017080783844
125 25113 0.3566414713859558
126 25113 0.3693068027496338
127 25113 0.3812129497528076
128 25113 0.3595277965068817
129 25113 0.4280366599559784
130 25113 0.3463660776615143
131 25113 0.45027291774749756
132 25113 0.42803019285202026
133 25113 0.37012195587158203
134 25113 0.38581234216690063
135 25113 0.35523444414138794
136 25113 0.3540951609611511
137 25113 0.4619240164756775
138 25113 0.4092072546482086
139 25113 0.3703884482383728
140 25113 0.45213010907173157
141 25113 0.404185950756073
142 25113 0.35996130108833313
143 25113 0.35412681102752686
144 25113 0.35470062494277954
145 25113 0.3839900493621826
146 25113 0.42817434668540955
147 25113 0.4192262887954712
148 25113 0.3603443205356598
149 25113 0.34557342529296875
150 25113 0.4048992097377777
151 25113 0.4674201011657715
152 25113 0.29229846596717834
153 25113 0.2578798830509186
154 25113 0.4192156195640564
155 25113 0.333178848028183
156 25113 0.35186445713043213
157 25113 0.31598812341690063
158 25113 0.38217419385910034
159 25113 0.2017524540424347
160 25113 0.303139328956604
161 25113 0.28575050830841064
162 25113 0.24415363371372223
163 25113 0.36627644300460815
164 25113 0.3122809827327728
165 25113 0.2443811446428299
166 25113 0.43553125858306885
167 25113 0.33712291717529297
168 25113 0.2221895009279251
169 25113 0.20775990188121796
170 25113 0.28134286403656006
171 25113 0.3238524794578552
172 25113 0.21901501715183258
173 25113 0.280502051115036
174 25113 0.22513766586780548
175 25113 0.298526793718338
176 25113 0.3107875883579254
177 25113 0.28183215856552124
178 25113 0.22968269884586334
179 25113 0.2955532968044281
180 25113 0.26354530453681946
181 25113 0.2869951128959656
182 25113 0.3235315978527069
183 25113 0.31619277596473694
184 25113 0.25985658168792725
185 25113 0.29336467385292053
186 25113 0.32083144783973694
187 25113 0.40713807940483093
188 25113 0.3405078649520874
189 25113 0.19957756996154785
190 25113 0.39629197120666504
191 25113 0.22880391776561737
192 25113 0.23727869987487793
193 25113 0.25058960914611816
194 25113 0.23538601398468018
195 25113 0.2003905475139618
196 25113 0.2577589154243469
train - Global loss: 0.394277    Embedding norm: 1.0000   Triplets (all/active): 127.5/15743.5
Pos dist (min/mean/max): 1.0299/1.3525/1.5998   Neg dist (min/mean/max): 1.0049/1.4061/1.6739
0 1011 0.6720801591873169
1 1011 0.7772216796875
2 1011 0.7632260322570801
3 1011 0.6002849340438843
4 1011 0.7134826183319092
5 1011 0.6940358281135559
6 1011 0.7179606556892395
7 1011 0.7203402519226074
val - Global loss: 0.707329    Embedding norm: 1.0000   Triplets (all/active): 126.4/15782.8
Pos dist (min/mean/max): 0.9852/1.2871/1.4640   Neg dist (min/mean/max): 0.5899/1.2735/1.5384
0 25113 0.3189845085144043
1 25113 0.2443651407957077
2 25113 0.23323486745357513
3 25113 0.27827274799346924
4 25113 0.28912219405174255
5 25113 0.287972092628479
6 25113 0.36434802412986755
7 25113 0.2663862407207489
8 25113 0.19099754095077515
9 25113 0.3008024990558624
10 25113 0.23082658648490906
11 25113 0.16336660087108612
12 25113 0.15868617594242096
13 25113 0.1741965115070343
14 25113 0.2896515130996704
15 25113 0.23119501769542694
16 25113 0.23043465614318848
17 25113 0.29942283034324646
18 25113 0.26976391673088074
19 25113 0.22843459248542786
20 25113 0.24411819875240326
21 25113 0.2664481997489929
22 25113 0.18180403113365173
23 25113 0.16262109577655792
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 372, in do_train
    for index, (query, positives, negatives, sim_p, sim_n) in enumerate(dataloaders[phase]):
  File "/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _next_data
    idx, data = self._get_data()
  File "/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1315, in _get_data
    success, data = self._try_get_data()
  File "/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1163, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/usr/local/lib/python3.9/queue.py", line 180, in get
    self.not_empty.wait(remaining)
  File "/usr/local/lib/python3.9/threading.py", line 316, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
