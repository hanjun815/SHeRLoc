  0%|                                                    | 0/80 [00:00<?, ?it/s]
0 25113 0.47663000226020813
1 25113 0.5897381901741028
2 25113 0.4831688404083252
3 25113 0.46634340286254883
4 25113 0.5181050896644592
5 25113 0.43047308921813965
6 25113 0.5679036378860474
7 25113 0.4848123788833618
8 25113 0.42516395449638367
9 25113 0.4865010976791382
10 25113 0.6395389437675476
11 25113 0.566343367099762
12 25113 0.6719878315925598
13 25113 0.5239108800888062
14 25113 0.6102288365364075
15 25113 0.6266311407089233
16 25113 0.5731481313705444
17 25113 0.42141807079315186
18 25113 0.5169984102249146
19 25113 0.5043618679046631
20 25113 0.4548897445201874
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 410, in do_train
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.9/site-packages/torch/cuda/memory.py", line 121, in empty_cache
    torch._C._cuda_emptyCache()
KeyboardInterrupt
