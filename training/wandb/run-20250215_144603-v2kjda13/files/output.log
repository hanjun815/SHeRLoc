  0%|                                                                     | 0/120 [00:00<?, ?it/s]
0 25113 43.993465423583984
1 25113 42.042972564697266
2 25113 39.15861892700195
3 25113 36.84613037109375
4 25113 34.7232666015625
5 25113 19.1449031829834
6 25113 28.143312454223633
7 25113 13.628061294555664
8 25113 13.311314582824707
9 25113 26.517742156982422
10 25113 18.201805114746094
11 25113 17.268436431884766
12 25113 13.671834945678711
13 25113 16.89540672302246
14 25113 11.963858604431152
15 25113 9.571553230285645
16 25113 10.151034355163574
17 25113 12.807682991027832
18 25113 9.442858695983887
19 25113 8.222259521484375
20 25113 7.699649810791016
21 25113 4.248454570770264
22 25113 6.468129634857178
23 25113 5.63088846206665
24 25113 5.939465522766113
25 25113 7.3378753662109375
26 25113 5.512521266937256
27 25113 4.977677822113037
28 25113 4.266834735870361
29 25113 4.930128574371338
30 25113 3.399610996246338
31 25113 5.311635494232178
32 25113 3.250758647918701
33 25113 3.723642349243164
34 25113 3.4299700260162354
35 25113 4.065323829650879
36 25113 3.469688892364502
37 25113 7.766796588897705
38 25113 4.468207359313965
39 25113 3.1812031269073486
40 25113 3.8898355960845947
41 25113 2.672372341156006
42 25113 2.4139347076416016
43 25113 2.7597124576568604
44 25113 1.8599523305892944
45 25113 4.367142677307129
46 25113 2.7957868576049805
47 25113 1.9053964614868164
48 25113 2.683741569519043
49 25113 3.7801005840301514
50 25113 3.42919921875
51 25113 5.330865383148193
52 25113 4.318337440490723
53 25113 2.0367677211761475
54 25113 2.483020782470703
55 25113 2.7134673595428467
56 25113 1.9560871124267578
57 25113 2.1385881900787354
58 25113 1.6567937135696411
59 25113 3.30120587348938
60 25113 2.4580347537994385
61 25113 2.4432904720306396
62 25113 2.827880382537842
63 25113 2.671138048171997
64 25113 2.004185914993286
65 25113 6.083364486694336
66 25113 2.486835241317749
67 25113 2.1570253372192383
68 25113 3.24220609664917
69 25113 3.1603198051452637
70 25113 3.7643396854400635
71 25113 3.252784490585327
72 25113 4.71597957611084
73 25113 3.9102437496185303
74 25113 2.652830123901367
75 25113 2.397914171218872
76 25113 2.5374679565429688
77 25113 2.5633575916290283
78 25113 2.738954782485962
79 25113 2.2161805629730225
80 25113 7.153602123260498
81 25113 2.549654245376587
82 25113 2.1301631927490234
83 25113 2.8464362621307373
train - Global loss: 7.836208    Embedding norm: 171.5316   Triplets (all/active): 299.0/73657.1
Pos dist (min/mean/max): 15.8516/26.2862/42.8243   Neg dist (min/mean/max): 14.6038/25.7720/54.0979
0 1011 6.7162065505981445
1 1011 8.237337112426758
2 1011 6.6501054763793945
3 1011 13.80278491973877
val - Global loss: 8.851609    Embedding norm: 157.4386   Triplets (all/active): 252.8/63874.0
Pos dist (min/mean/max): 16.0342/27.0352/41.3897   Neg dist (min/mean/max): 13.5067/24.3637/41.3314
0 25113 2.3810319900512695
1 25113 1.8874722719192505
2 25113 2.9322776794433594
3 25113 2.177762031555176
4 25113 1.9766556024551392
5 25113 2.5157809257507324
6 25113 2.5072124004364014
7 25113 3.1079347133636475
8 25113 2.282041072845459
9 25113 3.0953896045684814
10 25113 2.612494468688965
11 25113 1.9338781833648682
12 25113 1.9134610891342163
13 25113 1.8101773262023926
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 405, in do_train
    loss.backward()
  File "/usr/local/lib/python3.9/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/threading.py", line 1073, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt
