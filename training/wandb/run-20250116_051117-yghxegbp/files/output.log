  0%|                                                                           | 0/120 [00:00<?, ?it/s]
0 37587 3.787292957305908
1 37587 1.6184651851654053
2 37587 0.9340965151786804
3 37587 0.6959941387176514
4 37587 1.154445767402649
5 37587 0.9338733553886414
6 37587 0.7167389392852783
7 37587 0.578417181968689
8 37587 0.4142287075519562
9 37587 0.392795205116272
10 37587 0.5343130230903625
11 37587 0.42354151606559753
12 37587 0.3458256721496582
13 37587 0.3802551031112671
14 37587 0.30566972494125366
15 37587 0.5284282565116882
16 37587 0.4071400463581085
17 37587 0.42701420187950134
18 37587 0.41751304268836975
19 37587 0.4062969982624054
20 37587 0.4889189600944519
21 37587 0.5305219292640686
22 37587 0.6315289735794067
23 37587 0.4263247847557068
24 37587 0.5787143707275391
25 37587 0.6511123776435852
26 37587 0.36384040117263794
27 37587 0.34429609775543213
28 37587 0.3416992723941803
29 37587 0.31480929255485535
30 37587 0.46676018834114075
31 37587 0.28343281149864197
32 37587 0.2512701749801636
33 37587 0.2966480553150177
34 37587 0.3878459930419922
35 37587 0.33596450090408325
36 37587 0.33722180128097534
37 37587 0.3254530131816864
38 37587 0.30964791774749756
39 37587 0.439357191324234
40 37587 0.28300634026527405
41 37587 0.4841441810131073
42 37587 0.32620152831077576
43 37587 0.2977481186389923
44 37587 0.3056068420410156
45 37587 0.4255446493625641
46 37587 0.383034884929657
47 37587 0.38572826981544495
48 37587 0.7211551070213318
49 37587 0.5689892172813416
50 37587 0.39972323179244995
51 37587 0.29037028551101685
52 37587 0.21137243509292603
53 37587 0.22455717623233795
54 37587 0.31381523609161377
55 37587 0.5774478912353516
56 37587 0.5740451216697693
57 37587 0.4350747764110565
58 37587 0.34035858511924744
59 37587 0.333012193441391
60 37587 0.4946315586566925
61 37587 0.3263837993144989
62 37587 0.3743993639945984
63 37587 0.36984407901763916
64 37587 0.44144949316978455
65 37587 0.250234454870224
66 37587 0.3523321747779846
67 37587 0.3569837212562561
68 37587 0.3315490484237671
69 37587 0.30475467443466187
70 37587 0.27610084414482117
71 37587 0.47129207849502563
72 37587 0.2909891605377197
73 37587 0.4382017254829407
74 37587 0.32969021797180176
75 37587 0.34687158465385437
76 37587 0.30242323875427246
77 37587 0.3509270250797272
78 37587 0.3490350842475891
79 37587 0.5368016362190247
80 37587 0.5164807438850403
81 37587 0.2966565191745758
82 37587 0.3078293204307556
83 37587 0.4211164116859436
84 37587 0.38312578201293945
85 37587 0.37663912773132324
86 37587 0.5832801461219788
87 37587 0.2119624763727188
88 37587 0.24309521913528442
89 37587 0.3431228697299957
90 37587 0.7308839559555054
91 37587 0.7382143139839172
92 37587 0.6731572151184082
93 37587 0.550095796585083
94 37587 0.31555119156837463
95 37587 0.39296475052833557
96 37587 0.7246086597442627
97 37587 0.40942245721817017
98 37587 0.475936621427536
99 37587 0.5443983674049377
100 37587 0.3260439336299896
101 37587 0.5190865397453308
102 37587 0.6478392481803894
103 37587 0.3438238203525543
104 37587 0.5194184184074402
105 37587 0.43502482771873474
106 37587 0.3517729640007019
107 37587 0.24941767752170563
108 37587 0.30770012736320496
109 37587 0.29005780816078186
110 37587 0.3910471796989441
111 37587 0.413250595331192
112 37587 0.7372469902038574
113 37587 1.1710618734359741
114 37587 1.6547632217407227
115 37587 0.8678067326545715
116 37587 0.6991128921508789
117 37587 0.48668184876441956
118 37587 0.9833652377128601
119 37587 1.4381990432739258
120 37587 0.8596925735473633
121 37587 0.6539251208305359
122 37587 0.9874609708786011
123 37587 0.5664119720458984
124 37587 0.5656089782714844
125 37587 0.5095551609992981
126 37587 0.5409572720527649
127 37587 0.5902332067489624
128 37587 0.40901726484298706
129 37587 0.3306926190853119
130 37587 0.34170979261398315
131 37587 0.3708401322364807
132 37587 0.2675275504589081
133 37587 0.13938598334789276
134 37587 0.093431755900383
135 37587 0.06697481870651245
136 37587 0.3353571891784668
137 37587 0.2519531548023224
138 37587 0.46926021575927734
139 37587 0.49861279129981995
140 37587 0.4966484308242798
141 37587 0.2875654995441437
142 37587 0.26901453733444214
143 37587 0.3204725980758667
144 37587 0.39031273126602173
145 37587 0.5103575587272644
146 37587 0.5336713194847107
147 37587 0.7460379600524902
148 37587 0.46585017442703247
149 37587 0.5616096258163452
150 37587 0.9611202478408813
151 37587 0.6579330563545227
152 37587 0.6557703614234924
153 37587 0.3976772725582123
154 37587 0.40897154808044434
155 37587 0.3638041615486145
156 37587 0.3126307427883148
157 37587 0.3032112121582031
158 37587 0.4250444173812866
159 37587 0.3311900794506073
160 37587 0.28269630670547485
161 37587 0.3165140450000763
162 37587 0.4445030093193054
163 37587 0.5781223177909851
164 37587 0.2786928713321686
165 37587 0.4175398647785187
166 37587 0.709608256816864
167 37587 0.2905498445034027
168 37587 0.37279045581817627
169 37587 0.4285491704940796
170 37587 0.39451864361763
171 37587 0.378238707780838
172 37587 0.37692034244537354
173 37587 0.8442280292510986
174 37587 0.554815948009491
175 37587 0.44620051980018616
176 37587 0.3195716440677643
177 37587 0.39411693811416626
178 37587 0.4402090311050415
179 37587 0.3324005901813507
180 37587 0.6780357956886292
181 37587 0.6489549279212952
182 37587 0.6637808680534363
183 37587 0.4084552824497223
184 37587 0.5294804573059082
185 37587 0.6048568487167358
186 37587 0.4655294418334961
187 37587 0.4491525888442993
188 37587 0.4829394817352295
189 37587 0.3979879319667816
190 37587 0.42861053347587585
191 37587 0.44031497836112976
192 37587 0.5880268812179565
193 37587 0.6951295733451843
194 37587 0.6951372623443604
195 37587 0.6053965091705322
196 37587 0.7952001690864563
197 37587 1.0541459321975708
198 37587 0.4260229170322418
199 37587 0.3909379243850708
200 37587 0.13411623239517212
201 37587 0.3697696924209595
202 37587 0.35199418663978577
203 37587 0.1753869503736496
204 37587 0.5531098246574402
205 37587 0.8866077065467834
206 37587 1.3496447801589966
207 37587 0.8376474380493164
208 37587 0.4253184497356415
209 37587 0.3260779082775116
210 37587 0.2418482005596161
211 37587 0.29495805501937866
212 37587 0.12685123085975647
213 37587 0.09925878047943115
214 37587 0.16321735084056854
215 37587 0.5883804559707642
216 37587 0.2727346122264862
217 37587 0.1285441815853119
218 37587 0.25289061665534973
219 37587 0.6367916464805603
220 37587 0.7870389819145203
221 37587 0.38290438055992126
222 37587 0.46358147263526917
223 37587 0.6726701259613037
224 37587 0.547075092792511
225 37587 0.45643043518066406
226 37587 0.364479660987854
227 37587 0.28270232677459717
228 37587 0.42026376724243164
229 37587 0.3276748061180115
230 37587 0.4322841167449951
231 37587 0.6716797947883606
232 37587 0.5937495827674866
233 37587 0.6105396747589111
234 37587 0.39595213532447815
train - Global loss: 0.487980    Embedding norm: 9.7715   Triplets (all/active): 159.9/14274.6
Pos dist (min/mean/max): 1.8882/2.5574/3.4096   Neg dist (min/mean/max): 1.9731/3.7861/6.4092
0 2857 1.927636981010437
1 2857 1.412308692932129
2 2857 1.2134840488433838
3 2857 1.3647383451461792
4 2857 0.9593591094017029
5 2857 1.5662589073181152
6 2857 1.5812771320343018
7 2857 1.4952727556228638
8 2857 1.1589690446853638
9 2857 1.1806749105453491
10 2857 0.9841248393058777
11 2857 1.7024098634719849
12 2857 1.8789544105529785
13 2857 1.2926266193389893
14 2857 1.3346338272094727
15 2857 1.1240798234939575
16 2857 1.3178603649139404
17 2857 1.988913893699646
val - Global loss: 1.415755    Embedding norm: 8.3928   Triplets (all/active): 158.7/23253.8
Pos dist (min/mean/max): 2.8977/4.3616/6.1303   Neg dist (min/mean/max): 1.7040/4.6166/8.0443
0 37587 0.8708176612854004
1 37587 1.162257432937622
2 37587 1.0990437269210815
3 37587 1.2000482082366943
4 37587 0.9081495404243469
5 37587 0.7735296487808228
6 37587 0.7800253629684448
7 37587 0.5058010816574097
8 37587 0.5218229293823242
9 37587 0.46280962228775024
10 37587 0.4887734353542328
11 37587 0.346988707780838
12 37587 0.24894562363624573
13 37587 0.2475479692220688
14 37587 0.3372945487499237
15 37587 0.6694871187210083
16 37587 0.31656649708747864
17 37587 0.4129023849964142
18 37587 0.5732932686805725
19 37587 0.40416744351387024
20 37587 0.8009809851646423
21 37587 0.6994131803512573
22 37587 0.6474955677986145
23 37587 0.36094531416893005
24 37587 0.5582691431045532
25 37587 0.47734618186950684
26 37587 0.6203709244728088
27 37587 0.3501349985599518
28 37587 0.43553274869918823
29 37587 0.3058429956436157
30 37587 0.45488908886909485
31 37587 0.27306094765663147
32 37587 0.21234455704689026
33 37587 0.2984366714954376
34 37587 0.40172886848449707
35 37587 0.3795349597930908
36 37587 0.35741662979125977
37 37587 0.5076226592063904
38 37587 0.2720105051994324
39 37587 0.5183821320533752
40 37587 0.40831828117370605
41 37587 0.6443423628807068
42 37587 0.5189511775970459
43 37587 1.0076173543930054
44 37587 0.44949573278427124
45 37587 0.4418194890022278
46 37587 0.4391663074493408
47 37587 0.4976711571216583
48 37587 0.34224316477775574
49 37587 0.46756425499916077
50 37587 0.3304325342178345
51 37587 0.432903528213501
52 37587 0.24932950735092163
53 37587 0.26271936297416687
54 37587 0.3185155987739563
55 37587 0.6716363430023193
56 37587 1.5242130756378174
57 37587 2.118399143218994
58 37587 1.0083402395248413
59 37587 0.42052921652793884
60 37587 1.0788747072219849
61 37587 0.45053598284721375
62 37587 0.7982693910598755
63 37587 0.4337368905544281
64 37587 0.46748071908950806
65 37587 0.3479274809360504
66 37587 0.4719685912132263
67 37587 0.7722734808921814
68 37587 0.30339574813842773
69 37587 0.43410152196884155
70 37587 0.4669967293739319
71 37587 0.4917648434638977
72 37587 0.41964495182037354
73 37587 0.2862183749675751
74 37587 0.27782702445983887
75 37587 0.3859284222126007
76 37587 0.4218137860298157
77 37587 0.3802959620952606
78 37587 0.2800411581993103
79 37587 0.3286187946796417
80 37587 0.26744529604911804
81 37587 0.3029504418373108
82 37587 0.20913945138454437
83 37587 0.3217425048351288
84 37587 0.2526297867298126
85 37587 0.21319973468780518
86 37587 0.33767369389533997
87 37587 0.2852555215358734
88 37587 0.19412778317928314
89 37587 0.2215762436389923
90 37587 0.35775256156921387
91 37587 0.4690152704715729
92 37587 0.7346981167793274
93 37587 0.5513914227485657
94 37587 0.651091456413269
95 37587 0.37839657068252563
96 37587 0.7513377070426941
97 37587 0.6319149136543274
98 37587 0.4597347378730774
99 37587 0.5286115407943726
100 37587 0.3408648669719696
101 37587 0.351222425699234
102 37587 0.665788471698761
103 37587 0.3289063274860382
104 37587 0.5019048452377319
105 37587 0.5873162150382996
106 37587 0.32221052050590515
107 37587 0.35430482029914856
108 37587 0.29098954796791077
109 37587 0.31920066475868225
110 37587 0.4287068843841553
111 37587 0.4785710573196411
112 37587 0.5367380976676941
113 37587 0.5416947603225708
114 37587 0.6146305203437805
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 398, in do_train
    loss.backward()
  File "/usr/local/lib/python3.9/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 2; 10.75 GiB total capacity; 8.72 GiB already allocated; 156.69 MiB free; 8.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
