  0%|                                                    | 0/80 [00:41<?, ?it/s]
0 25113 0.3595174252986908
1 25113 0.3914134204387665
2 25113 0.3738943636417389
3 25113 0.3540276288986206
4 25113 0.3395754098892212
5 25113 0.3158046305179596
6 25113 0.39553025364875793
7 25113 0.3894922733306885
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 393, in do_train
    outputs = model(inputs, n_pos, n_neg)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 78, in parallel_apply
    thread.join()
  File "/usr/local/lib/python3.9/threading.py", line 1053, in join
    self._wait_for_tstate_lock()
  File "/usr/local/lib/python3.9/threading.py", line 1073, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt
