  0%|                                                                     | 0/120 [00:00<?, ?it/s]
0 25113 1.3874337673187256
1 25113 1.2044239044189453
2 25113 0.9946644306182861
3 25113 1.0430796146392822
4 25113 1.0176444053649902
5 25113 0.9714550375938416
6 25113 1.139761209487915
7 25113 1.0546281337738037
8 25113 0.9507436752319336
9 25113 0.8560380935668945
10 25113 0.8279674649238586
11 25113 0.9407402873039246
12 25113 0.8892266750335693
13 25113 0.9028844833374023
14 25113 0.7873896360397339
15 25113 0.8308672904968262
16 25113 0.8233272433280945
17 25113 0.7047469019889832
18 25113 0.6715823411941528
19 25113 0.6657444834709167
20 25113 0.6666148900985718
21 25113 0.6864091753959656
22 25113 0.752493143081665
23 25113 0.7545770406723022
24 25113 0.7187464833259583
25 25113 0.7077746987342834
26 25113 0.7158526182174683
27 25113 0.6683852076530457
28 25113 0.6592987179756165
29 25113 0.6530393958091736
30 25113 0.6844797730445862
31 25113 0.7179460525512695
32 25113 0.6238604187965393
33 25113 0.6407157778739929
34 25113 0.6485733985900879
35 25113 0.6021126508712769
36 25113 0.6064165234565735
37 25113 0.5927957892417908
38 25113 0.6532002091407776
39 25113 0.6369037628173828
40 25113 0.6151613593101501
41 25113 0.6090373396873474
42 25113 0.6594170331954956
43 25113 0.6750859022140503
44 25113 0.6683907508850098
45 25113 0.6361554861068726
46 25113 0.5611507296562195
47 25113 0.5290371775627136
48 25113 0.6218027472496033
49 25113 0.6162822246551514
50 25113 0.5953433513641357
51 25113 0.579998254776001
52 25113 0.5978043675422668
53 25113 0.8339762687683105
54 25113 0.6077548265457153
55 25113 0.5208883881568909
56 25113 0.5441440939903259
57 25113 0.47847980260849
58 25113 0.48318740725517273
59 25113 0.5068039894104004
60 25113 0.5401021242141724
61 25113 0.537625789642334
62 25113 0.4747134745121002
63 25113 0.518493115901947
64 25113 0.46318700909614563
65 25113 0.4509497284889221
66 25113 0.4409864842891693
67 25113 0.5103898644447327
68 25113 0.5759490132331848
69 25113 0.473523885011673
70 25113 0.6046342253684998
71 25113 0.4151962995529175
72 25113 0.4537310004234314
73 25113 0.4991810619831085
74 25113 0.4974517524242401
75 25113 0.4294452667236328
76 25113 0.4755374789237976
77 25113 0.4812261760234833
78 25113 0.4672161042690277
79 25113 0.40038880705833435
80 25113 0.4291660785675049
81 25113 0.4346829354763031
82 25113 0.4064468741416931
83 25113 0.48771071434020996
84 25113 0.3867363929748535
85 25113 0.3040314018726349
86 25113 0.3444204032421112
87 25113 0.49530449509620667
88 25113 0.6103726625442505
89 25113 0.4090220034122467
90 25113 0.4089469909667969
91 25113 0.3451154828071594
92 25113 0.3529326021671295
93 25113 0.566028892993927
94 25113 0.33237746357917786
95 25113 0.4217405617237091
96 25113 0.3180990219116211
97 25113 0.3642280101776123
98 25113 0.3471207022666931
99 25113 0.30332523584365845
100 25113 0.35326850414276123
101 25113 0.2984246015548706
102 25113 0.236000195145607
103 25113 0.2482127547264099
104 25113 0.3119404911994934
105 25113 0.3937003016471863
106 25113 0.340764582157135
107 25113 0.3842390775680542
108 25113 0.37299975752830505
109 25113 0.30424848198890686
110 25113 0.280235230922699
111 25113 0.3278759717941284
112 25113 0.39287251234054565
113 25113 0.2731246054172516
114 25113 0.2462095320224762
115 25113 0.2939525544643402
116 25113 0.6024567484855652
117 25113 0.3388678729534149
118 25113 0.2672891616821289
119 25113 0.37334194779396057
120 25113 0.4004363417625427
121 25113 0.378990113735199
122 25113 0.3638518452644348
123 25113 0.5211955308914185
124 25113 0.2986281216144562
125 25113 0.37963661551475525
126 25113 0.3835340738296509
127 25113 0.3782912492752075
128 25113 0.510547935962677
129 25113 0.22979560494422913
130 25113 0.38871482014656067
131 25113 0.47551295161247253
132 25113 0.22814366221427917
133 25113 0.3531874716281891
134 25113 0.25166642665863037
135 25113 0.2138834297657013
136 25113 0.18689659237861633
137 25113 0.44760382175445557
138 25113 0.22640028595924377
139 25113 0.34019196033477783
140 25113 0.3019253611564636
141 25113 0.44255417585372925
142 25113 0.36159831285476685
143 25113 0.2536900043487549
144 25113 0.29048243165016174
145 25113 0.24388305842876434
146 25113 0.26551011204719543
147 25113 0.3860391080379486
148 25113 0.24571354687213898
149 25113 0.27366217970848083
150 25113 0.19691379368305206
151 25113 0.49282485246658325
152 25113 0.2714173495769501
153 25113 0.5189396142959595
154 25113 0.5993542075157166
155 25113 0.40955325961112976
156 25113 0.5962228775024414
157 25113 0.35715508460998535
158 25113 0.6378397941589355
159 25113 0.5189228057861328
160 25113 0.5196221470832825
161 25113 0.5225628614425659
162 25113 0.19743870198726654
163 25113 0.44668734073638916
164 25113 0.9387838840484619
165 25113 0.5020233988761902
166 25113 0.2446899265050888
167 25113 0.38955333828926086
168 25113 0.5314961671829224
169 25113 0.4318588674068451
170 25113 0.21106332540512085
171 25113 0.6010693311691284
172 25113 0.5858311653137207
173 25113 0.37796834111213684
174 25113 0.30731213092803955
175 25113 0.4541759490966797
176 25113 0.4470444321632385
177 25113 0.5346164703369141
178 25113 0.27950936555862427
179 25113 0.39600035548210144
180 25113 0.2672317624092102
181 25113 0.2705206573009491
182 25113 0.5899943113327026
183 25113 0.3898203372955322
184 25113 0.2708357870578766
185 25113 0.17253968119621277
186 25113 0.20270296931266785
187 25113 0.2344374656677246
188 25113 0.2500167489051819
189 25113 0.2692750096321106
190 25113 0.5353813171386719
191 25113 0.3894539773464203
192 25113 0.38567492365837097
193 25113 0.3238001763820648
194 25113 0.3965160846710205
195 25113 0.6056882739067078
196 25113 0.3315431773662567
train - Global loss: 0.496641    Embedding norm: 10.9782   Triplets (all/active): 127.5/12418.9
Pos dist (min/mean/max): 3.2920/3.9691/4.9835   Neg dist (min/mean/max): 3.3921/4.5174/6.2600
0 1011 1.0595860481262207
1 1011 0.46953535079956055
2 1011 0.6523878574371338
3 1011 1.1458182334899902
4 1011 1.7263238430023193
5 1011 0.6206910610198975
6 1011 0.6360984444618225
7 1011 2.395214080810547
val - Global loss: 1.088207    Embedding norm: 10.7386   Triplets (all/active): 126.4/13900.9
Pos dist (min/mean/max): 1.4928/2.8070/5.0852   Neg dist (min/mean/max): 1.3911/3.3702/6.7490
0 25113 0.2652650773525238
1 25113 0.21676014363765717
2 25113 0.15557824075222015
3 25113 0.28531697392463684
4 25113 0.26203614473342896
5 25113 0.21049685776233673
6 25113 0.3556249439716339
7 25113 0.3716205656528473
8 25113 0.15250174701213837
9 25113 0.4812621772289276
10 25113 0.4366730749607086
11 25113 0.1590414196252823
12 25113 0.2107297033071518
13 25113 0.7041589617729187
14 25113 0.42517900466918945
15 25113 0.21323567628860474
16 25113 0.03973319008946419
17 25113 0.27153143286705017
18 25113 0.6570730209350586
19 25113 0.44527867436408997
20 25113 0.24642176926136017
21 25113 0.4848465025424957
22 25113 0.2559693455696106
23 25113 0.26004084944725037
24 25113 0.1919889599084854
25 25113 0.7309826612472534
26 25113 0.30304720997810364
27 25113 0.4104401469230652
28 25113 0.17681372165679932
29 25113 0.409132719039917
30 25113 0.6436476111412048
31 25113 0.8029565811157227
32 25113 0.18828119337558746
33 25113 0.6593124270439148
34 25113 0.44801846146583557
35 25113 0.3090718686580658
36 25113 0.1587820202112198
37 25113 0.2191476821899414
38 25113 0.2564973831176758
39 25113 0.13813135027885437
40 25113 0.019190803170204163
41 25113 0.08502928912639618
42 25113 0.21157048642635345
43 25113 0.28412550687789917
44 25113 0.12153089791536331
45 25113 0.15852224826812744
46 25113 0.5204260349273682
47 25113 0.37868809700012207
48 25113 0.0784916877746582
49 25113 0.0
50 25113 0.5514593720436096
51 25113 0.669806182384491
52 25113 0.39207202196121216
53 25113 0.7111544609069824
54 25113 0.1458597332239151
55 25113 0.21538317203521729
56 25113 0.5410371422767639
57 25113 0.3832036256790161
58 25113 0.07275404036045074
59 25113 0.43381354212760925
60 25113 0.0
61 25113 0.1855340152978897
62 25113 0.15742820501327515
63 25113 0.9306095242500305
64 25113 0.17277580499649048
65 25113 1.1423914432525635
66 25113 0.06738835573196411
67 25113 0.4772133529186249
68 25113 0.46794116497039795
69 25113 1.1727418899536133
70 25113 0.3684151768684387
71 25113 0.8722495436668396
72 25113 0.24087250232696533
73 25113 1.1980211734771729
74 25113 0.5478684306144714
75 25113 0.13529181480407715
76 25113 0.0
77 25113 0.0
78 25113 0.9032284617424011
79 25113 0.32210150361061096
80 25113 0.1986047774553299
81 25113 0.16125081479549408
82 25113 0.09571445733308792
83 25113 0.669844388961792
84 25113 0.26016566157341003
85 25113 0.14131347835063934
86 25113 0.30102816224098206
87 25113 0.8592411279678345
88 25113 1.049294114112854
89 25113 1.2802032232284546
90 25113 0.3829943537712097
91 25113 0.3838605582714081
92 25113 0.18047261238098145
93 25113 0.5916438698768616
94 25113 0.21265198290348053
95 25113 1.0977840423583984
96 25113 0.23004066944122314
97 25113 0.42748352885246277
98 25113 0.12109385430812836
99 25113 0.0
100 25113 0.3023393154144287
101 25113 0.11241704225540161
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.37398406863212585
106 25113 0.0
107 25113 0.25586432218551636
108 25113 0.28208136558532715
109 25113 0.0
110 25113 0.0
111 25113 0.1914830207824707
112 25113 0.1458839774131775
113 25113 0.11690936237573624
114 25113 0.17870639264583588
115 25113 0.0
116 25113 0.5623525381088257
117 25113 0.4029586613178253
118 25113 0.16855134069919586
119 25113 0.37762269377708435
120 25113 0.169585183262825
121 25113 0.20790347456932068
122 25113 0.0
123 25113 0.6344708204269409
124 25113 0.20486167073249817
125 25113 0.3809022903442383
126 25113 0.23072536289691925
127 25113 0.443576842546463
128 25113 0.23342101275920868
129 25113 0.15073591470718384
130 25113 1.0921128988265991
131 25113 1.0633589029312134
132 25113 0.0
133 25113 0.16006146371364594
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 1.0369293689727783
138 25113 0.0
139 25113 0.17069782316684723
140 25113 0.3103688955307007
141 25113 0.5459359288215637
142 25113 0.34303975105285645
143 25113 0.3213786482810974
144 25113 0.23491428792476654
145 25113 0.2255762815475464
146 25113 0.09773977100849152
147 25113 0.2888507843017578
148 25113 0.11692208051681519
149 25113 0.12994824349880219
150 25113 0.06463323533535004
151 25113 0.5291993618011475
152 25113 0.12618902325630188
153 25113 0.25002312660217285
154 25113 0.460864782333374
155 25113 0.34586286544799805
156 25113 0.34270966053009033
157 25113 0.12397059053182602
158 25113 0.23420311510562897
159 25113 0.6333680152893066
160 25113 0.5565409064292908
161 25113 0.15737269818782806
162 25113 0.0
163 25113 0.0
164 25113 0.4600411653518677
165 25113 0.3833392560482025
166 25113 0.36035823822021484
167 25113 0.3601868748664856
168 25113 0.3587249219417572
169 25113 0.25191405415534973
170 25113 0.10156863927841187
171 25113 0.8127644658088684
172 25113 0.2555047273635864
173 25113 0.3309005796909332
174 25113 0.3459916114807129
175 25113 0.24288496375083923
176 25113 0.2298826277256012
177 25113 0.7154955267906189
178 25113 0.0
179 25113 0.5023554563522339
180 25113 0.0
181 25113 0.07288962602615356
182 25113 0.4026203453540802
183 25113 0.22110940515995026
184 25113 0.0
185 25113 0.0
186 25113 0.1274712234735489
187 25113 0.28801229596138
188 25113 0.29969483613967896
189 25113 0.0
190 25113 1.0969645977020264
191 25113 0.46104440093040466
192 25113 0.0
193 25113 0.3483228087425232
194 25113 0.0
195 25113 0.9038571715354919
196 25113 0.4165230393409729
train - Global loss: 0.325046    Embedding norm: 11.5319   Triplets (all/active): 127.5/2530.8
Pos dist (min/mean/max): 3.6356/4.4294/5.6481   Neg dist (min/mean/max): 4.7146/6.7032/8.8921
0 1011 1.282689094543457
1 1011 0.6119539737701416
2 1011 0.7841821312904358
3 1011 1.0588968992233276
4 1011 1.7928236722946167
5 1011 0.7826728224754333
6 1011 0.9523367285728455
7 1011 3.050320863723755
val - Global loss: 1.289485    Embedding norm: 10.7356   Triplets (all/active): 126.4/12144.5
Pos dist (min/mean/max): 2.3557/4.2468/6.7838   Neg dist (min/mean/max): 2.2853/5.2313/9.0900
0 25113 0.2966274917125702
1 25113 0.0
2 25113 0.0
3 25113 0.2052723467350006
4 25113 0.0
5 25113 0.0
6 25113 0.4335778057575226
7 25113 0.0
8 25113 0.0
9 25113 0.4918414354324341
10 25113 0.14413225650787354
11 25113 0.0
12 25113 0.0
13 25113 0.6243932843208313
14 25113 0.708834707736969
15 25113 0.0
16 25113 0.0
17 25113 0.2405620813369751
18 25113 0.5271040797233582
19 25113 0.4292283058166504
20 25113 0.13979864120483398
21 25113 0.24184103310108185
22 25113 0.0
23 25113 0.0
24 25113 0.2618715167045593
25 25113 0.8153254389762878
26 25113 0.09240293502807617
27 25113 0.16712826490402222
28 25113 0.0
29 25113 0.21442973613739014
30 25113 0.2750093340873718
31 25113 1.1364293098449707
32 25113 0.0
33 25113 0.3607090413570404
34 25113 0.1538592278957367
35 25113 0.11938152462244034
36 25113 0.177601158618927
37 25113 0.07352596521377563
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.28897348046302795
44 25113 0.0
45 25113 0.0
46 25113 0.38103988766670227
47 25113 0.3783186674118042
48 25113 0.0
49 25113 0.0
50 25113 0.09642994403839111
51 25113 0.37129467725753784
52 25113 0.3395441770553589
53 25113 0.6660852432250977
54 25113 0.0
55 25113 0.02492588758468628
56 25113 0.38788557052612305
57 25113 0.3261398375034332
58 25113 0.0037716031074523926
59 25113 0.16928210854530334
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.7901073694229126
64 25113 0.0
65 25113 0.4170096814632416
66 25113 0.0
67 25113 0.35218337178230286
68 25113 0.20099399983882904
69 25113 0.7292709946632385
70 25113 0.2283870130777359
71 25113 0.2505846917629242
72 25113 0.0
73 25113 0.2857155501842499
74 25113 0.3537273705005646
75 25113 0.0
76 25113 0.0
77 25113 0.03663760423660278
78 25113 0.46609050035476685
79 25113 0.2632690668106079
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.3600335717201233
84 25113 0.38573184609413147
85 25113 0.0
86 25113 0.11528047919273376
87 25113 1.5161694288253784
88 25113 1.3455742597579956
89 25113 1.3557859659194946
90 25113 0.08685380220413208
91 25113 0.21697957813739777
92 25113 0.1447954922914505
93 25113 0.45628485083580017
94 25113 0.0
95 25113 1.2779408693313599
96 25113 0.3973662853240967
97 25113 0.42373207211494446
98 25113 0.0
99 25113 0.0
100 25113 0.15655528008937836
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.17346903681755066
105 25113 0.09344412386417389
106 25113 0.029553472995758057
107 25113 0.1749371886253357
108 25113 0.13068276643753052
109 25113 0.17649424076080322
110 25113 0.0
111 25113 0.20594246685504913
112 25113 0.2419644296169281
113 25113 0.11709164083003998
114 25113 0.0
115 25113 0.025230228900909424
116 25113 0.5196918249130249
117 25113 0.5065534114837646
118 25113 0.08492249995470047
119 25113 0.23302581906318665
120 25113 0.0
121 25113 0.015967031940817833
122 25113 0.0233444981276989
123 25113 0.5148966312408447
124 25113 0.03477282077074051
125 25113 0.18390055000782013
126 25113 0.2319718301296234
127 25113 0.3205353319644928
128 25113 0.16801102459430695
129 25113 0.16955962777137756
130 25113 0.45327362418174744
131 25113 0.11021652072668076
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.7059443593025208
138 25113 0.0
139 25113 0.0
140 25113 0.26294440031051636
141 25113 0.6225989460945129
142 25113 0.2127404361963272
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.1479995846748352
150 25113 0.0
151 25113 0.5579116344451904
152 25113 0.0
153 25113 0.0
154 25113 0.8783503174781799
155 25113 0.4141298830509186
156 25113 0.2022741287946701
157 25113 0.21805411577224731
158 25113 0.08780919760465622
159 25113 0.7773956060409546
160 25113 0.36779627203941345
161 25113 0.23513084650039673
162 25113 0.0
163 25113 0.1818167269229889
164 25113 0.43565115332603455
165 25113 0.3050597906112671
166 25113 0.21748486161231995
167 25113 0.26437756419181824
168 25113 0.22843922674655914
169 25113 0.17268063127994537
170 25113 0.0
171 25113 0.7064388990402222
172 25113 0.28114229440689087
173 25113 0.29788318276405334
174 25113 0.2632628083229065
175 25113 0.23559097945690155
176 25113 0.1488962471485138
177 25113 0.5420240759849548
178 25113 0.0
179 25113 0.2814819812774658
180 25113 0.0
181 25113 0.0
182 25113 0.28781697154045105
183 25113 0.1888108104467392
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.12121813744306564
188 25113 0.0
189 25113 0.0
190 25113 0.4452506899833679
191 25113 0.19909387826919556
192 25113 0.0556376576423645
193 25113 0.0
194 25113 0.1518447995185852
195 25113 0.4320208728313446
196 25113 0.0
train - Global loss: 0.210417    Embedding norm: 11.5793   Triplets (all/active): 127.5/1020.8
Pos dist (min/mean/max): 3.9797/4.8277/5.9690   Neg dist (min/mean/max): 5.6966/7.8425/9.9791
0 1011 1.2765765190124512
1 1011 0.6489861607551575
2 1011 0.7025330066680908
3 1011 1.123335599899292
4 1011 1.7952059507369995
5 1011 0.7787352204322815
6 1011 0.8829393982887268
7 1011 2.6160125732421875
val - Global loss: 1.228041    Embedding norm: 10.8859   Triplets (all/active): 126.4/13405.4
Pos dist (min/mean/max): 1.9560/3.6611/6.2445   Neg dist (min/mean/max): 1.8090/4.3534/7.8699
0 25113 0.1586761772632599
1 25113 0.047454655170440674
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.3113470673561096
7 25113 0.0
8 25113 0.0
9 25113 0.30074819922447205
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.6191296577453613
14 25113 0.5721997022628784
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.41899168491363525
19 25113 0.3202989399433136
20 25113 0.0
21 25113 0.14226511120796204
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.5178201198577881
26 25113 0.008506596088409424
27 25113 0.14325083792209625
28 25113 0.24027806520462036
29 25113 0.1652289479970932
30 25113 0.29132014513015747
31 25113 0.8510093688964844
32 25113 0.0
33 25113 0.3044266402721405
34 25113 0.05789393186569214
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.06849664449691772
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.06739901006221771
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.34903639554977417
47 25113 0.05938631296157837
48 25113 0.0
49 25113 0.0
50 25113 0.07747679948806763
51 25113 0.3123375177383423
52 25113 0.1772918701171875
53 25113 0.6056898832321167
54 25113 0.0
55 25113 0.0
56 25113 0.49771684408187866
57 25113 0.3693773150444031
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.9688333868980408
64 25113 0.0
65 25113 0.2477118819952011
66 25113 0.0
67 25113 0.23050503432750702
68 25113 0.15605540573596954
69 25113 0.8758283257484436
70 25113 0.20705263316631317
71 25113 0.09286955744028091
72 25113 0.0
73 25113 0.18717923760414124
74 25113 0.5033547878265381
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.25251516699790955
79 25113 0.0
80 25113 0.0
81 25113 0.21431833505630493
82 25113 0.0
83 25113 0.32121267914772034
84 25113 0.2661557197570801
85 25113 0.0
86 25113 0.0
87 25113 0.29886594414711
88 25113 0.3487749397754669
89 25113 0.7064756155014038
90 25113 0.11275798082351685
91 25113 0.2696565091609955
92 25113 0.0
93 25113 0.2980651557445526
94 25113 0.0
95 25113 1.0831419229507446
96 25113 0.16912826895713806
97 25113 0.17208415269851685
98 25113 0.0
99 25113 0.0
100 25113 0.115870900452137
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.11691170185804367
105 25113 0.13577024638652802
106 25113 0.0
107 25113 0.5513803362846375
108 25113 0.07149980962276459
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.14018526673316956
113 25113 0.09682631492614746
114 25113 0.04325324296951294
115 25113 0.0
116 25113 0.3357273042201996
117 25113 0.23952186107635498
118 25113 0.0
119 25113 0.09150922298431396
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.6623110771179199
124 25113 0.05632144212722778
125 25113 0.0
126 25113 0.06685572862625122
127 25113 0.17191141843795776
128 25113 0.1354474276304245
129 25113 0.0
130 25113 0.3526599705219269
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.39822959899902344
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.4834381937980652
142 25113 0.13029414415359497
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.7404583692550659
152 25113 0.0
153 25113 0.0
154 25113 0.36397069692611694
155 25113 0.17072607576847076
156 25113 0.21161696314811707
157 25113 0.0
158 25113 0.0
159 25113 0.40876537561416626
160 25113 0.1271335929632187
161 25113 0.20777007937431335
162 25113 0.0
163 25113 0.0
164 25113 0.3243326246738434
165 25113 0.05978936329483986
166 25113 0.0
167 25113 0.03214564174413681
168 25113 0.027980394661426544
169 25113 0.0
170 25113 0.0
171 25113 0.558086097240448
172 25113 0.1044648289680481
173 25113 0.15319710969924927
174 25113 0.0
175 25113 0.1679030954837799
176 25113 0.4335777163505554
177 25113 0.4230153262615204
178 25113 0.0
179 25113 0.09078001230955124
180 25113 0.0
181 25113 0.0
182 25113 0.2105710655450821
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.4328423738479614
191 25113 0.08519499003887177
192 25113 0.11680155992507935
193 25113 0.0
194 25113 0.0
195 25113 0.2556154429912567
196 25113 0.0
train - Global loss: 0.132692    Embedding norm: 11.6516   Triplets (all/active): 127.5/364.1
Pos dist (min/mean/max): 4.0887/4.9292/6.0180   Neg dist (min/mean/max): 6.2346/8.5422/10.7439
0 1011 1.2966089248657227
1 1011 0.6773943305015564
2 1011 0.6906280517578125
3 1011 0.9670519232749939
4 1011 1.880110740661621
5 1011 0.7652730345726013
6 1011 0.8994966745376587
7 1011 2.529085159301758
val - Global loss: 1.213206    Embedding norm: 10.8065   Triplets (all/active): 126.4/13159.5
Pos dist (min/mean/max): 2.0316/3.7483/6.4784   Neg dist (min/mean/max): 2.0010/4.5601/8.0546
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.10100823640823364
10 25113 0.26228228211402893
11 25113 0.0
12 25113 0.0
13 25113 0.20246285200119019
14 25113 0.26206088066101074
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.15372638404369354
19 25113 0.3002801835536957
20 25113 0.0
21 25113 0.13537928462028503
22 25113 0.0
23 25113 0.17772823572158813
24 25113 0.0
25 25113 0.6144990921020508
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.14363297820091248
30 25113 0.0
31 25113 0.633719265460968
32 25113 0.0
33 25113 0.22494558990001678
34 25113 0.08017988502979279
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.17562367022037506
52 25113 0.22441191971302032
53 25113 0.19731707870960236
54 25113 0.0
55 25113 0.0031695961952209473
56 25113 0.0
57 25113 0.27150240540504456
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.6375181078910828
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.05082365497946739
69 25113 0.4377436339855194
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.07138115167617798
74 25113 0.17746387422084808
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.1454458385705948
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.2136993706226349
84 25113 0.5864112973213196
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.5888364315032959
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.18760043382644653
94 25113 0.0
95 25113 0.20693182945251465
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.10680446028709412
105 25113 0.0
106 25113 0.11168326437473297
107 25113 0.128066286444664
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.20658570528030396
117 25113 0.13298416137695312
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.164303719997406
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.2057320773601532
129 25113 0.0
130 25113 0.18403416872024536
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.39788180589675903
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.6287598013877869
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.462360680103302
152 25113 0.0
153 25113 0.0
154 25113 0.317040354013443
155 25113 0.0
156 25113 0.0885709747672081
157 25113 0.0
158 25113 0.0
159 25113 0.12964867055416107
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.19781595468521118
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0022495388984680176
169 25113 0.0
170 25113 0.0
171 25113 0.4479045271873474
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.12286487221717834
178 25113 0.0
179 25113 0.18865326046943665
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.13307109475135803
190 25113 0.20558159053325653
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.09711022675037384
196 25113 0.07105523347854614
train - Global loss: 0.061922    Embedding norm: 11.6044   Triplets (all/active): 127.5/113.9
Pos dist (min/mean/max): 3.9229/4.7251/5.7310   Neg dist (min/mean/max): 6.3892/8.6447/10.7158
0 1011 1.3150382041931152
1 1011 0.6184682846069336
2 1011 0.6795214414596558
3 1011 1.019458532333374
4 1011 1.7638434171676636
5 1011 0.7410818934440613
6 1011 0.8232870697975159
7 1011 2.5904064178466797
val - Global loss: 1.193888    Embedding norm: 10.8513   Triplets (all/active): 126.4/13012.8
Pos dist (min/mean/max): 2.3114/4.0328/6.4929   Neg dist (min/mean/max): 2.3105/4.8046/7.9608
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.2677604854106903
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.2749767303466797
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.2209455966949463
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.15470367670059204
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.2965049147605896
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.3124789595603943
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.3048408627510071
70 25113 0.0
71 25113 0.09073096513748169
72 25113 0.0
73 25113 0.0
74 25113 0.16975226998329163
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.25972315669059753
79 25113 0.13113002479076385
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.09538527578115463
85 25113 0.0
86 25113 0.0
87 25113 0.22985631227493286
88 25113 0.0
89 25113 0.2863922715187073
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.17997899651527405
94 25113 0.0
95 25113 0.27295422554016113
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.3391004204750061
117 25113 0.26725485920906067
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.09621196985244751
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.15490612387657166
129 25113 0.0
130 25113 0.17883697152137756
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.46419379115104675
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.3206517696380615
142 25113 0.03205233812332153
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.3872833251953125
152 25113 0.0
153 25113 0.0
154 25113 0.11250512301921844
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.11229906231164932
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.020379364490509033
171 25113 0.24708083271980286
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.029428541660308838
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.04460960626602173
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.2146294116973877
188 25113 0.13099336624145508
189 25113 0.0
190 25113 0.10174114257097244
191 25113 0.0
192 25113 0.136103093624115
193 25113 0.0
194 25113 0.0
195 25113 0.046534519642591476
196 25113 0.0
train - Global loss: 0.035456    Embedding norm: 11.5695   Triplets (all/active): 127.5/30.2
Pos dist (min/mean/max): 3.8411/4.5908/5.5356   Neg dist (min/mean/max): 6.3816/8.7148/10.8590
0 1011 1.3767749071121216
1 1011 0.7840221524238586
2 1011 0.6659554243087769
3 1011 0.8755229115486145
4 1011 1.872978687286377
5 1011 0.824362576007843
6 1011 0.8819246292114258
7 1011 2.5076630115509033
val - Global loss: 1.223651    Embedding norm: 10.8208   Triplets (all/active): 126.4/13309.6
Pos dist (min/mean/max): 2.1109/3.8297/6.3119   Neg dist (min/mean/max): 2.0674/4.4652/7.7023
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.013896763324737549
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.18268081545829773
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.008784592151641846
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.4029608368873596
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.16927289962768555
30 25113 0.0
31 25113 0.31960123777389526
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.05754993483424187
46 25113 0.13326123356819153
47 25113 0.24039696156978607
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.11047297716140747
63 25113 0.1266888976097107
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.5064215064048767
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.1333063244819641
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.16804057359695435
89 25113 0.18474286794662476
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.20610789954662323
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.1628320962190628
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.34771549701690674
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.020380795001983643
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.30860352516174316
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.0
152 25113 0.0
153 25113 0.0
154 25113 0.11215381324291229
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.11761599034070969
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.10329569876194
171 25113 0.1960703283548355
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.19134922325611115
177 25113 0.19019180536270142
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.21504434943199158
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.07894068956375122
195 25113 0.10664206743240356
196 25113 0.0
train - Global loss: 0.025965    Embedding norm: 11.5487   Triplets (all/active): 127.5/23.0
Pos dist (min/mean/max): 3.7753/4.5200/5.4506   Neg dist (min/mean/max): 6.5885/8.9841/11.1426
0 1011 1.31003999710083
1 1011 0.6186618208885193
2 1011 0.6754176020622253
3 1011 1.0141183137893677
4 1011 1.754326343536377
5 1011 0.7631728053092957
6 1011 0.8819724917411804
7 1011 2.366403818130493
val - Global loss: 1.173014    Embedding norm: 10.8544   Triplets (all/active): 126.4/13869.0
Pos dist (min/mean/max): 1.9166/3.5620/6.0679   Neg dist (min/mean/max): 1.8570/4.1461/7.3542
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.27977320551872253
14 25113 0.09040304273366928
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.07735250890254974
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.4819008708000183
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.09525567293167114
30 25113 0.0
31 25113 0.06828579306602478
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.038709938526153564
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.10723240673542023
52 25113 0.0916140004992485
53 25113 0.03691917657852173
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.09147721529006958
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.5339665412902832
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.5531200170516968
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.27442944049835205
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0221443772315979
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.15421615540981293
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.014807522296905518
96 25113 0.0
97 25113 0.29380834102630615
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.03931671380996704
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.313360333442688
129 25113 0.0
130 25113 0.0
131 25113 0.22617743909358978
132 25113 0.08871244639158249
133 25113 0.17711417376995087
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.18089471757411957
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.38128986954689026
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.16026972234249115
152 25113 0.0
153 25113 0.0
154 25113 0.39521563053131104
155 25113 0.0
156 25113 0.19444939494132996
157 25113 0.0
158 25113 0.0
159 25113 0.2388741672039032
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.2892147898674011
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.0
train - Global loss: 0.030408    Embedding norm: 11.5643   Triplets (all/active): 127.5/11.5
Pos dist (min/mean/max): 3.6435/4.3694/5.2515   Neg dist (min/mean/max): 6.4010/8.8686/11.0543
0 1011 1.3578909635543823
1 1011 0.8828291296958923
2 1011 0.7088221907615662
3 1011 1.1226117610931396
4 1011 1.9608049392700195
5 1011 0.9222676753997803
6 1011 1.1149938106536865
7 1011 2.9593393802642822
val - Global loss: 1.378695    Embedding norm: 10.9322   Triplets (all/active): 126.4/14256.2
Pos dist (min/mean/max): 2.0681/3.9666/6.5516   Neg dist (min/mean/max): 1.9893/4.4896/7.9874
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.3383250832557678
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.08090060949325562
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.08877688646316528
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.12846815586090088
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.3789050877094269
58 25113 0.0
59 25113 0.16738921403884888
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.20554117858409882
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.15231063961982727
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.0
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.0
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.0
152 25113 0.0
153 25113 0.0
154 25113 0.0
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.1764937788248062
165 25113 0.02869635820388794
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.0
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.0
train - Global loss: 0.008862    Embedding norm: 11.5402   Triplets (all/active): 127.5/3.5
Pos dist (min/mean/max): 3.6621/4.3651/5.2224   Neg dist (min/mean/max): 6.5960/9.1001/11.4873
0 1011 1.4210487604141235
1 1011 0.809441864490509
2 1011 0.7081624269485474
3 1011 1.2227108478546143
4 1011 1.8334068059921265
5 1011 0.8701694011688232
6 1011 0.9800011515617371
7 1011 2.46915340423584
val - Global loss: 1.289262    Embedding norm: 10.8811   Triplets (all/active): 126.4/13777.2
Pos dist (min/mean/max): 2.3668/4.2304/6.7665   Neg dist (min/mean/max): 2.3308/4.9181/7.8995
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.2328505963087082
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.20314587652683258
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.16767245531082153
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.03215247392654419
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.0
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.0
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.26294881105422974
152 25113 0.0
153 25113 0.4129078984260559
154 25113 0.0
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.04390746355056763
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.2606537938117981
183 25113 0.058721840381622314
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.0
train - Global loss: 0.008502    Embedding norm: 11.5000   Triplets (all/active): 127.5/2.3
Pos dist (min/mean/max): 3.7343/4.4555/5.3654   Neg dist (min/mean/max): 7.0363/9.6055/11.6952
0 1011 1.4045237302780151
1 1011 0.7454330921173096
2 1011 0.6860253214836121
3 1011 1.1412065029144287
4 1011 1.845292568206787
5 1011 0.853315532207489
6 1011 1.0981923341751099
7 1011 2.655977249145508
val - Global loss: 1.303746    Embedding norm: 10.8579   Triplets (all/active): 126.4/13290.5
Pos dist (min/mean/max): 2.2911/4.1792/7.0432   Neg dist (min/mean/max): 2.3377/4.9711/8.1542
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.2694590091705322
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.1665017455816269
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.060288362205028534
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0010855793952941895
30 25113 0.0
31 25113 0.09260255098342896
32 25113 0.0
33 25113 0.0
34 25113 0.05242210626602173
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.14056716859340668
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.053191643208265305
54 25113 0.0
55 25113 0.0
56 25113 0.11400729417800903
57 25113 0.05387554317712784
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.28092390298843384
64 25113 0.0
65 25113 0.09101945161819458
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0729568600654602
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.0
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.1430535614490509
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.2370237559080124
152 25113 0.0
153 25113 0.0
154 25113 0.13291364908218384
155 25113 0.0
156 25113 0.05379897356033325
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.15838652849197388
169 25113 0.0
170 25113 0.0
171 25113 0.1717759668827057
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.2719026505947113
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.0
train - Global loss: 0.013288    Embedding norm: 11.4548   Triplets (all/active): 127.5/3.2
Pos dist (min/mean/max): 3.5458/4.2631/5.1541   Neg dist (min/mean/max): 6.5430/9.0240/11.2376
0 1011 1.1108366250991821
1 1011 0.7435217499732971
2 1011 0.632640540599823
3 1011 1.052730679512024
4 1011 1.5382049083709717
5 1011 0.8443987369537354
6 1011 0.8854467272758484
7 1011 2.0368034839630127
val - Global loss: 1.105573    Embedding norm: 10.8824   Triplets (all/active): 126.4/14604.8
Pos dist (min/mean/max): 1.6270/3.1308/5.4289   Neg dist (min/mean/max): 1.5565/3.5821/6.2857
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.1537167727947235
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.21359892189502716
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.059913892298936844
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.24874654412269592
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.13521194458007812
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.16672834753990173
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.025116264820098877
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.13285867869853973
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.041880905628204346
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.0
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.0
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.0
152 25113 0.0
153 25113 0.0
154 25113 0.0
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.21583563089370728
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.07643061876296997
train - Global loss: 0.007462    Embedding norm: 11.4066   Triplets (all/active): 127.5/1.3
Pos dist (min/mean/max): 3.4547/4.1391/4.9721   Neg dist (min/mean/max): 6.4934/9.1959/11.5546
0 1011 1.0795947313308716
1 1011 0.812821090221405
2 1011 0.6841067671775818
3 1011 0.9150671362876892
4 1011 1.3097385168075562
5 1011 0.8031159043312073
6 1011 0.8641177415847778
7 1011 1.894021987915039
val - Global loss: 1.045323    Embedding norm: 10.8300   Triplets (all/active): 126.4/13660.6
Pos dist (min/mean/max): 2.2909/3.7133/5.8237   Neg dist (min/mean/max): 2.2764/4.4919/7.1302
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.18320518732070923
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.16066652536392212
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.07580319792032242
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.16624408960342407
52 25113 0.0
53 25113 0.1018361896276474
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.10632839053869247
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.33161497116088867
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.0
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.0
152 25113 0.0
153 25113 0.0
154 25113 0.1318580061197281
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.006616413593292236
162 25113 0.0
163 25113 0.0
164 25113 0.32671642303466797
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.0
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.0
train - Global loss: 0.008076    Embedding norm: 11.4500   Triplets (all/active): 127.5/2.0
Pos dist (min/mean/max): 3.5503/4.2986/5.2470   Neg dist (min/mean/max): 7.0604/9.7289/11.9354
0 1011 0.9061768651008606
1 1011 0.8205408453941345
2 1011 0.708965539932251
3 1011 1.0610734224319458
4 1011 1.1181951761245728
5 1011 0.8845261335372925
6 1011 0.8521480560302734
7 1011 1.825915813446045
val - Global loss: 1.022193    Embedding norm: 10.7696   Triplets (all/active): 126.4/13858.5
Pos dist (min/mean/max): 2.0239/3.3888/5.6107   Neg dist (min/mean/max): 1.9126/4.1065/6.6081
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.10968941450119019
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.1605096459388733
68 25113 0.11477166414260864
69 25113 0.004916965961456299
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.35383233428001404
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.14433985948562622
88 25113 0.2674277722835541
89 25113 0.1587643325328827
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.1747339367866516
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.6534954905509949
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.0
138 25113 0.0
139 25113 0.11433615535497665
140 25113 0.0
141 25113 0.0
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.06940227746963501
149 25113 0.0
150 25113 0.0
151 25113 0.0
152 25113 0.0
153 25113 0.0
154 25113 0.0
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.0
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.03221946954727173
196 25113 0.0
train - Global loss: 0.011972    Embedding norm: 11.3457   Triplets (all/active): 127.5/2.5
Pos dist (min/mean/max): 3.4115/4.0929/4.9537   Neg dist (min/mean/max): 6.5491/9.3010/11.4656
0 1011 0.87199467420578
1 1011 0.5523165464401245
2 1011 0.605867326259613
3 1011 0.9950699806213379
4 1011 1.1522692441940308
5 1011 0.6509599685668945
6 1011 0.7252175807952881
7 1011 1.967819094657898
val - Global loss: 0.940189    Embedding norm: 10.7583   Triplets (all/active): 126.4/13656.0
Pos dist (min/mean/max): 1.6620/2.9713/5.0039   Neg dist (min/mean/max): 1.7098/3.6471/6.1820
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.17863470315933228
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.2364528477191925
69 25113 0.2986859381198883
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.6159241795539856
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.3058059811592102
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.1072349101305008
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.0
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.0
152 25113 0.0
153 25113 0.0
154 25113 0.0
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.0
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.1691872775554657
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.0
train - Global loss: 0.009705    Embedding norm: 11.2681   Triplets (all/active): 127.5/0.8
Pos dist (min/mean/max): 3.3549/4.0177/4.8591   Neg dist (min/mean/max): 6.6566/9.4960/11.7331
0 1011 0.8954439759254456
1 1011 0.6324922442436218
2 1011 0.699695348739624
3 1011 0.9902499318122864
4 1011 1.2336831092834473
5 1011 0.686958372592926
6 1011 0.8805785179138184
7 1011 2.113297462463379
val - Global loss: 1.016550    Embedding norm: 10.6968   Triplets (all/active): 126.4/13872.5
Pos dist (min/mean/max): 1.7929/3.2605/5.6267   Neg dist (min/mean/max): 1.7638/3.8906/6.5489
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.3477412164211273
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.1147531121969223
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.08515673875808716
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.0
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.0
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.0
152 25113 0.0
153 25113 0.0
154 25113 0.11383891105651855
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.13179734349250793
165 25113 0.18384385108947754
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.0
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.20094925165176392
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.0
train - Global loss: 0.005980    Embedding norm: 11.3024   Triplets (all/active): 127.5/1.8
Pos dist (min/mean/max): 3.3447/4.0169/4.8759   Neg dist (min/mean/max): 6.6790/9.2334/11.5146
0 1011 1.0279163122177124
1 1011 0.521068811416626
2 1011 0.6878980994224548
3 1011 0.9938313961029053
4 1011 1.3793741464614868
5 1011 0.6607027649879456
6 1011 0.9215208888053894
7 1011 2.3218376636505127
val - Global loss: 1.064269    Embedding norm: 10.6705   Triplets (all/active): 126.4/14010.2
Pos dist (min/mean/max): 1.7471/3.1675/5.3428   Neg dist (min/mean/max): 1.7181/3.8086/6.5827
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.2486916184425354
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.0
65 25113 0.009173691272735596
66 25113 0.0
67 25113 0.0
68 25113 0.03755289316177368
69 25113 0.0
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.3786606788635254
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.0
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.2896171510219574
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.0
152 25113 0.0
153 25113 0.0
154 25113 0.0
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.11687397956848145
160 25113 0.0
161 25113 0.15033693611621857
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.21902191638946533
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.0
train - Global loss: 0.007360    Embedding norm: 11.2242   Triplets (all/active): 127.5/1.7
Pos dist (min/mean/max): 3.4467/4.1468/5.0417   Neg dist (min/mean/max): 7.2823/9.9435/12.0618
0 1011 0.9509221315383911
1 1011 0.7232955694198608
2 1011 0.7177051901817322
3 1011 1.1615419387817383
4 1011 1.3218659162521362
5 1011 0.7534401416778564
6 1011 0.957195520401001
7 1011 2.1699960231781006
val - Global loss: 1.094495    Embedding norm: 10.6795   Triplets (all/active): 126.4/13764.0
Pos dist (min/mean/max): 2.1021/3.6333/5.9339   Neg dist (min/mean/max): 2.1117/4.4027/7.1585
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.21941035985946655
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.12388483434915543
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.11782421916723251
69 25113 0.0
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.06431275606155396
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.07490774244070053
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.19961649179458618
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.0
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.0
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.02336341142654419
152 25113 0.0
153 25113 0.0
154 25113 0.0
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.12263458967208862
169 25113 0.28130751848220825
170 25113 0.0
171 25113 0.17240197956562042
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.30178290605545044
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.0
train - Global loss: 0.008637    Embedding norm: 11.2651   Triplets (all/active): 127.5/1.4
Pos dist (min/mean/max): 3.3519/4.0264/4.8512   Neg dist (min/mean/max): 6.9101/9.5152/11.7566
0 1011 0.9655439853668213
1 1011 0.7328085899353027
2 1011 0.6388673782348633
3 1011 1.2397747039794922
4 1011 1.409398078918457
5 1011 0.7622174620628357
6 1011 0.9987502694129944
7 1011 2.034194231033325
val - Global loss: 1.097694    Embedding norm: 10.7255   Triplets (all/active): 126.4/14278.4
Pos dist (min/mean/max): 1.7790/3.2415/5.4593   Neg dist (min/mean/max): 1.7344/3.7633/6.3887
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.05842071771621704
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.1498156189918518
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.0
65 25113 0.3424667716026306
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.0
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.15206539630889893
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.0
152 25113 0.0
153 25113 0.16109532117843628
154 25113 0.16937582194805145
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.0
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.2848365902900696
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.09762746095657349
196 25113 0.0
train - Global loss: 0.007186    Embedding norm: 11.2422   Triplets (all/active): 127.5/1.1
Pos dist (min/mean/max): 3.1409/3.7456/4.5084   Neg dist (min/mean/max): 6.2076/8.6418/10.7583
0 1011 0.8953345417976379
1 1011 0.5527442097663879
2 1011 0.619047224521637
3 1011 0.9184343218803406
4 1011 1.1049197912216187
5 1011 0.6759600639343262
6 1011 0.7462074756622314
7 1011 1.6491398811340332
val - Global loss: 0.895223    Embedding norm: 10.5824   Triplets (all/active): 126.4/14293.6
Pos dist (min/mean/max): 1.5294/2.6411/4.4451   Neg dist (min/mean/max): 1.4747/3.1038/5.1492
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.1990833282470703
14 25113 0.11380704492330551
15 25113 0.0
16 25113 0.0
17 25113 0.024308979511260986
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.07935544103384018
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.27064257860183716
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.1846361756324768
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.011891186237335205
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.0
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.0
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.12645147740840912
152 25113 0.0
153 25113 0.0820196270942688
154 25113 0.0
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.04120061919093132
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.14895281195640564
train - Global loss: 0.006509    Embedding norm: 11.1811   Triplets (all/active): 127.5/2.5
Pos dist (min/mean/max): 3.1448/3.7388/4.4727   Neg dist (min/mean/max): 6.0712/8.4522/10.6110
0 1011 0.9060398936271667
1 1011 0.7013920545578003
2 1011 0.5455140471458435
3 1011 0.9835647940635681
4 1011 1.1361385583877563
5 1011 0.7629445195198059
6 1011 0.769631028175354
7 1011 1.6004865169525146
val - Global loss: 0.925714    Embedding norm: 10.5843   Triplets (all/active): 126.4/14496.9
Pos dist (min/mean/max): 1.6975/2.8533/4.6586   Neg dist (min/mean/max): 1.6229/3.3515/5.4538
0 25113 0.07567077875137329
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0942569375038147
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.0
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.0
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.0
152 25113 0.0
153 25113 0.0
154 25113 0.0
155 25113 0.3636167645454407
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.0
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.0
train - Global loss: 0.002708    Embedding norm: 11.2505   Triplets (all/active): 127.5/0.7
Pos dist (min/mean/max): 3.3423/4.0006/4.7954   Neg dist (min/mean/max): 7.2311/9.9983/11.9235
0 1011 1.0781996250152588
1 1011 0.819074273109436
2 1011 0.6665487289428711
3 1011 1.0702241659164429
4 1011 1.3999154567718506
5 1011 0.8317204117774963
6 1011 0.9593533277511597
7 1011 1.9814082384109497
val - Global loss: 1.100806    Embedding norm: 10.6055   Triplets (all/active): 126.4/14305.1
Pos dist (min/mean/max): 1.9519/3.3745/5.4877   Neg dist (min/mean/max): 1.7548/3.9500/6.4761
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.138080894947052
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.13985823094844818
80 25113 0.0558105930685997
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.0
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.0
142 25113 0.20721589028835297
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.0
152 25113 0.0
153 25113 0.0
154 25113 0.0
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.0
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.0
train - Global loss: 0.002746    Embedding norm: 11.3006   Triplets (all/active): 127.5/1.1
Pos dist (min/mean/max): 3.3442/4.0121/4.8441   Neg dist (min/mean/max): 7.4659/9.9868/12.0048
0 1011 1.0015684366226196
1 1011 0.8031172752380371
2 1011 0.6873427033424377
3 1011 0.9862592816352844
4 1011 1.3544330596923828
5 1011 0.8187850117683411
6 1011 0.9334630370140076
7 1011 2.0118324756622314
val - Global loss: 1.074600    Embedding norm: 10.6386   Triplets (all/active): 126.4/13851.4
Pos dist (min/mean/max): 1.8959/3.2937/5.3921   Neg dist (min/mean/max): 1.7750/3.9571/6.5908
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.0
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.0
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.0
152 25113 0.0
153 25113 0.0
154 25113 0.0
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.0
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.0
train - Global loss: 0.000000    Embedding norm: 11.3031   Triplets (all/active): 127.5/0.0
Pos dist (min/mean/max): 3.1776/3.7897/4.5401   Neg dist (min/mean/max): 6.9436/9.5192/11.6502
0 1011 0.988008439540863
1 1011 0.8032736778259277
2 1011 0.6380205750465393
3 1011 0.9535180330276489
4 1011 1.3614124059677124
5 1011 0.8010828495025635
6 1011 0.9268223643302917
7 1011 2.0177454948425293
val - Global loss: 1.061235    Embedding norm: 10.6384   Triplets (all/active): 126.4/14006.0
Pos dist (min/mean/max): 1.8959/3.2936/5.3920   Neg dist (min/mean/max): 1.8075/3.9638/6.4954
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.08680635690689087
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.018648922443389893
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.0
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.0
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.0
152 25113 0.0
153 25113 0.0
154 25113 0.0
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.0
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.0
train - Global loss: 0.000535    Embedding norm: 11.2838   Triplets (all/active): 127.5/0.0
Pos dist (min/mean/max): 3.1009/3.7001/4.4254   Neg dist (min/mean/max): 6.3005/8.9674/11.1641
0 1011 0.8649675250053406
1 1011 0.5931397676467896
2 1011 0.6352758407592773
3 1011 0.8715193867683411
4 1011 1.1854643821716309
5 1011 0.665615975856781
6 1011 0.7984693646430969
7 1011 1.7842555046081543
val - Global loss: 0.924838    Embedding norm: 10.5951   Triplets (all/active): 126.4/14077.8
Pos dist (min/mean/max): 1.6408/2.8671/4.8321   Neg dist (min/mean/max): 1.6291/3.5438/6.0134
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.24906498193740845
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.1447700560092926
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.09082183241844177
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.30469685792922974
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.0
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.14179575443267822
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.0
152 25113 0.12040303647518158
153 25113 0.0
154 25113 0.14897948503494263
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.0
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.3403584361076355
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.020796015858650208
193 25113 0.22447745501995087
194 25113 0.0
195 25113 0.0
196 25113 0.18659764528274536
train - Global loss: 0.010014    Embedding norm: 11.2938   Triplets (all/active): 127.5/2.6
Pos dist (min/mean/max): 3.1736/3.8112/4.6326   Neg dist (min/mean/max): 6.3695/9.0857/11.3619
0 1011 0.8871500492095947
1 1011 0.5897096395492554
2 1011 0.5485811233520508
3 1011 0.9292129874229431
4 1011 1.2136114835739136
5 1011 0.6987131834030151
6 1011 0.7956362366676331
7 1011 1.6401622295379639
val - Global loss: 0.912847    Embedding norm: 10.6737   Triplets (all/active): 126.4/14571.8
Pos dist (min/mean/max): 1.3191/2.4544/4.3274   Neg dist (min/mean/max): 1.2316/2.9524/5.1743
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.3618462383747101
69 25113 0.0
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.0
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.0
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.0
152 25113 0.0
153 25113 0.0
154 25113 0.0
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.1146160364151001
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.0
176 25113 0.0
177 25113 0.0
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.0
train - Global loss: 0.002419    Embedding norm: 11.2660   Triplets (all/active): 127.5/0.5
Pos dist (min/mean/max): 3.1476/3.7694/4.5363   Neg dist (min/mean/max): 6.6272/9.1574/11.4089
0 1011 1.2138817310333252
1 1011 0.7620803713798523
2 1011 0.7369020581245422
3 1011 0.9955690503120422
4 1011 1.659129023551941
5 1011 0.7961632609367371
6 1011 1.0958232879638672
7 1011 2.2157399654388428
val - Global loss: 1.184411    Embedding norm: 10.6465   Triplets (all/active): 126.4/14514.9
Pos dist (min/mean/max): 1.9412/3.4648/5.6998   Neg dist (min/mean/max): 1.7586/4.0605/6.8505
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.18173471093177795
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0929662436246872
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 386, in do_train
    inputs = torch.cat([query, positives, negatives]).to(device)
KeyboardInterrupt
