  0%|                                                                      | 0/80 [00:00<?, ?it/s]
0 35906 1.2673404216766357
1 35906 0.8164836764335632
2 35906 0.7051688432693481
3 35906 0.9804207682609558
4 35906 0.9069845676422119
5 35906 0.7771608829498291
6 35906 0.9816828966140747
7 35906 0.7085926532745361
8 35906 0.7285877466201782
9 35906 0.8683431148529053
10 35906 0.6187528371810913
11 35906 0.7657709717750549
12 35906 0.6293770670890808
13 35906 0.509963870048523
14 35906 0.8558033108711243
15 35906 0.6455078721046448
16 35906 0.5842298269271851
17 35906 0.5793230533599854
18 35906 0.5014750957489014
19 35906 0.5555068850517273
20 35906 0.6394921541213989
21 35906 0.6169427633285522
22 35906 0.5440545678138733
23 35906 0.5060729384422302
24 35906 0.518947422504425
25 35906 0.542749285697937
26 35906 0.5610447525978088
27 35906 0.5454807877540588
28 35906 0.4854186773300171
29 35906 0.5710570216178894
30 35906 0.5896693468093872
31 35906 0.5036786794662476
32 35906 0.5137505531311035
33 35906 0.47768357396125793
34 35906 0.5159643292427063
35 35906 0.6140258312225342
36 35906 0.5313739776611328
37 35906 0.5501313209533691
38 35906 0.5821782350540161
39 35906 0.48141932487487793
40 35906 0.42022961378097534
41 35906 0.5698432326316833
42 35906 0.43960487842559814
43 35906 0.43713611364364624
44 35906 0.4540751874446869
45 35906 0.45524075627326965
46 35906 0.49156972765922546
47 35906 0.5074651837348938
48 35906 0.4671058654785156
49 35906 0.4341597557067871
50 35906 0.44121435284614563
51 35906 0.41498059034347534
52 35906 0.45039603114128113
53 35906 0.4548546075820923
54 35906 0.4203641414642334
55 35906 0.4634886085987091
56 35906 0.4234360158443451
57 35906 0.4075332581996918
58 35906 0.4687802195549011
59 35906 0.4416576623916626
60 35906 0.4551844298839569
61 35906 0.380740225315094
62 35906 0.5020895600318909
63 35906 0.4270068109035492
64 35906 0.4210265874862671
65 35906 0.44342148303985596
66 35906 0.45222195982933044
67 35906 0.42948171496391296
68 35906 0.4473227560520172
69 35906 0.42207327485084534
70 35906 0.43902474641799927
71 35906 0.42249414324760437
72 35906 0.4322343170642853
73 35906 0.4237602949142456
74 35906 0.43002229928970337
75 35906 0.42286649346351624
76 35906 0.4227767586708069
77 35906 0.41038450598716736
78 35906 0.4474736750125885
79 35906 0.4225672781467438
80 35906 0.40218016505241394
81 35906 0.40212059020996094
82 35906 0.40317338705062866
83 35906 0.4097871482372284
84 35906 0.4273822605609894
85 35906 0.38896703720092773
86 35906 0.3855038583278656
87 35906 0.38879790902137756
88 35906 0.37786728143692017
89 35906 0.39047423005104065
train - Global loss: 0.528569    Embedding norm: 9.2283   Triplets (all/active): 399.0/159099.4
Pos dist (min/mean/max): 1.6061/2.0398/2.7868   Neg dist (min/mean/max): 1.5265/2.0192/3.0954
0 1011 0.393638014793396
1 1011 0.45295941829681396
2 1011 0.5270991921424866
val - Global loss: 0.457899    Embedding norm: 8.9621   Triplets (all/active): 337.0/120954.0
Pos dist (min/mean/max): 0.9401/1.2759/1.9108   Neg dist (min/mean/max): 0.8497/1.3108/2.1168
0 35906 0.41741079092025757
1 35906 0.38198399543762207
2 35906 0.36054548621177673
3 35906 0.3389238715171814
4 35906 0.3832612633705139
5 35906 0.3558316230773926
6 35906 0.41242918372154236
7 35906 0.36343708634376526
8 35906 0.37268826365470886
9 35906 0.38547876477241516
10 35906 0.3766615092754364
11 35906 0.4010789692401886
12 35906 0.35661450028419495
13 35906 0.35034409165382385
14 35906 0.3646791875362396
15 35906 0.3762992322444916
16 35906 0.3351142108440399
17 35906 0.3441699743270874
18 35906 0.3237300515174866
19 35906 0.3445601165294647
20 35906 0.35621118545532227
21 35906 0.3365512192249298
22 35906 0.3688616156578064
23 35906 0.34323233366012573
24 35906 0.3617634177207947
25 35906 0.35760971903800964
26 35906 0.3576342463493347
27 35906 0.3504636287689209
28 35906 0.3575144410133362
29 35906 0.4015241861343384
30 35906 0.34384238719940186
31 35906 0.311860591173172
32 35906 0.3223482370376587
33 35906 0.31738027930259705
34 35906 0.3190135657787323
35 35906 0.3931073248386383
36 35906 0.3368857204914093
37 35906 0.3433569371700287
38 35906 0.3730680048465729
39 35906 0.3521287739276886
40 35906 0.286421537399292
41 35906 0.3954995572566986
42 35906 0.2809111177921295
43 35906 0.31101369857788086
44 35906 0.3101609945297241
45 35906 0.3390600383281708
46 35906 0.3892350196838379
47 35906 0.40372028946876526
48 35906 0.3294185698032379
49 35906 0.310808390378952
50 35906 0.2847956120967865
51 35906 0.27713364362716675
52 35906 0.3207848072052002
53 35906 0.32954487204551697
54 35906 0.31043195724487305
55 35906 0.2999004125595093
56 35906 0.32111498713493347
57 35906 0.29261186718940735
58 35906 0.28533169627189636
59 35906 0.24291931092739105
60 35906 0.32878392934799194
61 35906 0.2773337662220001
62 35906 0.4012818932533264
63 35906 0.35717952251434326
64 35906 0.34018781781196594
65 35906 0.3461928367614746
66 35906 0.3568325936794281
67 35906 0.3447383940219879
68 35906 0.3588189482688904
69 35906 0.312479168176651
70 35906 0.34777575731277466
71 35906 0.3688948154449463
72 35906 0.3221307694911957
73 35906 0.3396509885787964
74 35906 0.3414554297924042
75 35906 0.3135991394519806
76 35906 0.3060060739517212
77 35906 0.3235054612159729
78 35906 0.38581761717796326
79 35906 0.33091551065444946
80 35906 0.3268858790397644
81 35906 0.30334484577178955
82 35906 0.28053438663482666
83 35906 0.2849932610988617
84 35906 0.3760085105895996
85 35906 0.29161494970321655
86 35906 0.28499940037727356
87 35906 0.3069779574871063
88 35906 0.29302868247032166
89 35906 0.3050476610660553
train - Global loss: 0.339194    Embedding norm: 9.2240   Triplets (all/active): 399.0/158840.9
Pos dist (min/mean/max): 1.1763/1.4473/1.8616   Neg dist (min/mean/max): 1.2024/1.5915/2.3610
0 1011 0.3641470670700073
1 1011 0.4330872595310211
2 1011 0.5757201313972473
val - Global loss: 0.457651    Embedding norm: 8.9189   Triplets (all/active): 337.0/119549.7
Pos dist (min/mean/max): 0.7921/1.2057/2.0619   Neg dist (min/mean/max): 0.7461/1.3430/2.5165
0 35906 0.23527595400810242
1 35906 0.2826126217842102
2 35906 0.2808572053909302
3 35906 0.24029365181922913
4 35906 0.3096490502357483
5 35906 0.20823778212070465
6 35906 0.3137294054031372
7 35906 0.23650223016738892
8 35906 0.23726986348628998
9 35906 0.2602027654647827
10 35906 0.26374441385269165
11 35906 0.22267939150333405
12 35906 0.2537654936313629
13 35906 0.24801549315452576
14 35906 0.29722195863723755
15 35906 0.3186976909637451
16 35906 0.2051125168800354
17 35906 0.24480976164340973
18 35906 0.20541901886463165
19 35906 0.19269058108329773
20 35906 0.23159606754779816
21 35906 0.23039641976356506
22 35906 0.3125147819519043
23 35906 0.2573716938495636
24 35906 0.2670449912548065
25 35906 0.20377206802368164
26 35906 0.2769716680049896
27 35906 0.27007901668548584
28 35906 0.22321265935897827
29 35906 0.3569377362728119
30 35906 0.2940296232700348
31 35906 0.21964654326438904
32 35906 0.2520800530910492
33 35906 0.23740065097808838
34 35906 0.2369275838136673
35 35906 0.3491186201572418
36 35906 0.2704122066497803
37 35906 0.3078562319278717
38 35906 0.34121257066726685
39 35906 0.24940797686576843
40 35906 0.1902604103088379
41 35906 0.3567548394203186
42 35906 0.18189381062984467
43 35906 0.17474636435508728
44 35906 0.17367959022521973
45 35906 0.29337525367736816
46 35906 0.4897189438343048
47 35906 0.4509289860725403
48 35906 0.28580158948898315
49 35906 0.25101199746131897
50 35906 0.20997865498065948
51 35906 0.16813820600509644
52 35906 0.23743046820163727
53 35906 0.33473020792007446
54 35906 0.26030808687210083
55 35906 0.29133838415145874
56 35906 0.26011502742767334
57 35906 0.25984257459640503
58 35906 0.21362332999706268
59 35906 0.18007297813892365
60 35906 0.3749387860298157
61 35906 0.2075446993112564
62 35906 0.40163469314575195
63 35906 0.33162111043930054
64 35906 0.31662312150001526
65 35906 0.26020538806915283
66 35906 0.2599036991596222
67 35906 0.3183344602584839
68 35906 0.3230740427970886
69 35906 0.2354571670293808
70 35906 0.22198615968227386
71 35906 0.30009016394615173
72 35906 0.27160313725471497
73 35906 0.31521058082580566
74 35906 0.3085816204547882
75 35906 0.20157209038734436
76 35906 0.20063915848731995
77 35906 0.2533489465713501
78 35906 0.4155867397785187
79 35906 0.29036930203437805
80 35906 0.27976781129837036
81 35906 0.23683862388134003
82 35906 0.21464066207408905
83 35906 0.16210053861141205
84 35906 0.3576880097389221
85 35906 0.23075565695762634
86 35906 0.21397660672664642
87 35906 0.2582680284976959
88 35906 0.2359696626663208
89 35906 0.241227388381958
train - Global loss: 0.266090    Embedding norm: 9.4683   Triplets (all/active): 399.0/133572.1
Pos dist (min/mean/max): 1.1712/1.5250/2.1757   Neg dist (min/mean/max): 1.2955/1.9863/3.1787
0 1011 0.37629184126853943
1 1011 0.44452640414237976
2 1011 0.7296639084815979
val - Global loss: 0.516827    Embedding norm: 9.0562   Triplets (all/active): 337.0/114944.0
Pos dist (min/mean/max): 0.7563/1.3422/2.5429   Neg dist (min/mean/max): 0.6933/1.6655/3.2297
0 35906 0.16988909244537354
1 35906 0.25755757093429565
2 35906 0.25463008880615234
3 35906 0.19016966223716736
4 35906 0.25610876083374023
5 35906 0.17389245331287384
6 35906 0.3021794855594635
7 35906 0.1709844470024109
8 35906 0.15508133172988892
9 35906 0.19840659201145172
10 35906 0.21346700191497803
11 35906 0.14397576451301575
12 35906 0.21094584465026855
13 35906 0.23184368014335632
14 35906 0.25664249062538147
15 35906 0.26292383670806885
16 35906 0.16681905090808868
17 35906 0.21577084064483643
18 35906 0.1421855241060257
19 35906 0.12539783120155334
20 35906 0.1839165836572647
21 35906 0.178347647190094
22 35906 0.34118130803108215
23 35906 0.1725650429725647
24 35906 0.18268203735351562
25 35906 0.17621643841266632
26 35906 0.22976140677928925
27 35906 0.2728884816169739
28 35906 0.17366129159927368
29 35906 0.38908594846725464
30 35906 0.23312336206436157
31 35906 0.20068341493606567
32 35906 0.2095666229724884
33 35906 0.21729698777198792
34 35906 0.23186637461185455
35 35906 0.3312019109725952
36 35906 0.25371861457824707
37 35906 0.3455524742603302
38 35906 0.3513483703136444
39 35906 0.22594164311885834
40 35906 0.17339393496513367
41 35906 0.3666589856147766
42 35906 0.14633801579475403
43 35906 0.10458746552467346
44 35906 0.12977978587150574
45 35906 0.2521348297595978
46 35906 0.3685860335826874
47 35906 0.3552287817001343
48 35906 0.21134716272354126
49 35906 0.2565474510192871
50 35906 0.2033945620059967
51 35906 0.16225984692573547
52 35906 0.22670727968215942
53 35906 0.36730581521987915
54 35906 0.25499653816223145
55 35906 0.25951728224754333
56 35906 0.19938158988952637
57 35906 0.27008384466171265
58 35906 0.18204408884048462
59 35906 0.15791209042072296
60 35906 0.4819210469722748
61 35906 0.18526631593704224
62 35906 0.43413329124450684
63 35906 0.30844244360923767
64 35906 0.2678034007549286
65 35906 0.19477006793022156
66 35906 0.1807098239660263
67 35906 0.28304824233055115
68 35906 0.26805925369262695
69 35906 0.193820059299469
70 35906 0.1559688001871109
71 35906 0.26788991689682007
72 35906 0.24237419664859772
73 35906 0.2759384512901306
74 35906 0.27561986446380615
75 35906 0.18150940537452698
76 35906 0.1340114176273346
77 35906 0.18880082666873932
78 35906 0.36678916215896606
79 35906 0.30540770292282104
80 35906 0.22990699112415314
81 35906 0.20244768261909485
82 35906 0.16813655197620392
83 35906 0.10332952439785004
84 35906 0.36435237526893616
85 35906 0.20087602734565735
86 35906 0.182730033993721
87 35906 0.2032686471939087
88 35906 0.2075539529323578
89 35906 0.1836455911397934
train - Global loss: 0.232069    Embedding norm: 9.7324   Triplets (all/active): 399.0/83668.6
Pos dist (min/mean/max): 1.2514/1.6509/2.4385   Neg dist (min/mean/max): 1.4703/2.4174/3.7382
0 1011 0.3789369761943817
1 1011 0.4419386386871338
2 1011 0.7601177096366882
val - Global loss: 0.526998    Embedding norm: 9.2507   Triplets (all/active): 337.0/105357.7
Pos dist (min/mean/max): 0.7279/1.4402/2.7424   Neg dist (min/mean/max): 0.6492/1.9163/3.4085
0 35906 0.13906140625476837
1 35906 0.22158902883529663
2 35906 0.26778531074523926
3 35906 0.16778592765331268
4 35906 0.23942749202251434
5 35906 0.15821214020252228
6 35906 0.2929662764072418
7 35906 0.1377687156200409
8 35906 0.1133059561252594
9 35906 0.16511407494544983
10 35906 0.18713003396987915
11 35906 0.12287454307079315
12 35906 0.15833112597465515
13 35906 0.20950017869472504
14 35906 0.22744910418987274
15 35906 0.24443340301513672
16 35906 0.15161345899105072
17 35906 0.19807198643684387
18 35906 0.10593271255493164
19 35906 0.09637599438428879
20 35906 0.16439244151115417
21 35906 0.15117239952087402
22 35906 0.3733006715774536
23 35906 0.1271638125181198
24 35906 0.11252540349960327
25 35906 0.1555185168981552
26 35906 0.19598965346813202
27 35906 0.18535234034061432
28 35906 0.0909600630402565
29 35906 0.3553237020969391
30 35906 0.193884938955307
31 35906 0.18281173706054688
32 35906 0.2332952469587326
33 35906 0.19804923236370087
34 35906 0.2097809761762619
35 35906 0.30065011978149414
36 35906 0.2093971073627472
37 35906 0.3218041658401489
38 35906 0.31794577836990356
39 35906 0.19927017390727997
40 35906 0.17486828565597534
41 35906 0.3764079809188843
42 35906 0.08870492875576019
43 35906 0.04835887625813484
44 35906 0.08873248845338821
45 35906 0.23331628739833832
46 35906 0.2023642510175705
47 35906 0.25619110465049744
48 35906 0.13258866965770721
49 35906 0.2846211791038513
50 35906 0.18778885900974274
51 35906 0.11937923729419708
52 35906 0.23785924911499023
53 35906 0.3242238759994507
54 35906 0.3035380244255066
55 35906 0.22577700018882751
56 35906 0.16646982729434967
57 35906 0.2688867747783661
58 35906 0.18127664923667908
59 35906 0.0856822282075882
60 35906 0.40931928157806396
61 35906 0.1918455958366394
62 35906 0.41828522086143494
63 35906 0.29116979241371155
64 35906 0.20918673276901245
65 35906 0.1882351040840149
66 35906 0.09446489065885544
67 35906 0.2793586850166321
68 35906 0.2050660401582718
69 35906 0.16802340745925903
70 35906 0.13320955634117126
71 35906 0.390432208776474
72 35906 0.20950143039226532
73 35906 0.23709805309772491
74 35906 0.2267906218767166
75 35906 0.17199766635894775
76 35906 0.10603939741849899
77 35906 0.17551517486572266
78 35906 0.34525156021118164
79 35906 0.31996384263038635
80 35906 0.22545862197875977
81 35906 0.18305793404579163
82 35906 0.1752789467573166
83 35906 0.056106533855199814
84 35906 0.3841750919818878
85 35906 0.17350131273269653
86 35906 0.17683763802051544
87 35906 0.18800467252731323
88 35906 0.2401025891304016
89 35906 0.16224899888038635
train - Global loss: 0.206732    Embedding norm: 9.9147   Triplets (all/active): 399.0/49090.9
Pos dist (min/mean/max): 1.3677/1.7974/2.5742   Neg dist (min/mean/max): 1.7250/2.8137/4.2757
0 1011 0.40965715050697327
1 1011 0.47502002120018005
2 1011 0.7960708737373352
val - Global loss: 0.560249    Embedding norm: 9.3526   Triplets (all/active): 337.0/103305.0
Pos dist (min/mean/max): 0.7446/1.5269/2.8486   Neg dist (min/mean/max): 0.6850/2.0743/3.6580
0 35906 0.12904490530490875
1 35906 0.2149551659822464
2 35906 0.35861748456954956
3 35906 0.17817842960357666
4 35906 0.22888478636741638
5 35906 0.1323668211698532
6 35906 0.274098664522171
7 35906 0.13064078986644745
8 35906 0.09932989627122879
9 35906 0.1706520915031433
10 35906 0.17104601860046387
11 35906 0.09746246784925461
12 35906 0.1367160826921463
13 35906 0.19218803942203522
14 35906 0.2074156254529953
15 35906 0.2478199452161789
16 35906 0.13871970772743225
17 35906 0.21341395378112793
18 35906 0.06258688122034073
19 35906 0.09472038596868515
20 35906 0.15192054212093353
21 35906 0.17128713428974152
22 35906 0.36375370621681213
23 35906 0.1390886753797531
24 35906 0.038381095975637436
25 35906 0.08391178399324417
26 35906 0.19029030203819275
27 35906 0.05178985372185707
28 35906 0.0
29 35906 0.2846345007419586
30 35906 0.11558816581964493
31 35906 0.16118235886096954
32 35906 0.21952147781848907
33 35906 0.20436450839042664
34 35906 0.17879703640937805
35 35906 0.295504629611969
36 35906 0.17889435589313507
37 35906 0.26411446928977966
38 35906 0.3061665892601013
39 35906 0.22779481112957
40 35906 0.1807253658771515
41 35906 0.3620830476284027
42 35906 0.05334421619772911
43 35906 0.09131509810686111
44 35906 0.09798997640609741
45 35906 0.15268027782440186
46 35906 0.03652156516909599
47 35906 0.2140488475561142
48 35906 0.1378006786108017
49 35906 0.3372479975223541
50 35906 0.17823733389377594
51 35906 0.1531132459640503
52 35906 0.34338244795799255
53 35906 0.3757055103778839
54 35906 0.3920157849788666
55 35906 0.26733294129371643
56 35906 0.21520119905471802
57 35906 0.29254814982414246
58 35906 0.2149180769920349
59 35906 0.0
60 35906 0.3718647360801697
61 35906 0.20006151497364044
62 35906 0.48670342564582825
63 35906 0.28085726499557495
64 35906 0.17170847952365875
65 35906 0.22780248522758484
66 35906 0.07059325277805328
67 35906 0.3099101781845093
68 35906 0.16753751039505005
69 35906 0.17277240753173828
70 35906 0.05999845266342163
71 35906 0.5378515720367432
72 35906 0.23164913058280945
73 35906 0.2237708866596222
74 35906 0.22648417949676514
75 35906 0.12080683559179306
76 35906 0.0
77 35906 0.25093430280685425
78 35906 0.33115410804748535
79 35906 0.35056227445602417
80 35906 0.1962682455778122
81 35906 0.09973154962062836
82 35906 0.12033948302268982
83 35906 0.02949223481118679
84 35906 0.37704041600227356
85 35906 0.12074093520641327
86 35906 0.11919566988945007
87 35906 0.15880106389522552
88 35906 0.1506618708372116
89 35906 0.14890851080417633
train - Global loss: 0.194625    Embedding norm: 10.0606   Triplets (all/active): 399.0/31828.8
Pos dist (min/mean/max): 1.5245/1.9933/2.8123   Neg dist (min/mean/max): 2.0391/3.2617/4.8512
0 1011 0.43860065937042236
1 1011 0.5102352499961853
2 1011 0.9017312526702881
val - Global loss: 0.616856    Embedding norm: 9.4894   Triplets (all/active): 337.0/103185.0
Pos dist (min/mean/max): 0.7515/1.5987/2.9262   Neg dist (min/mean/max): 0.6359/2.1161/3.6008
0 35906 0.13912534713745117
1 35906 0.21132831275463104
2 35906 0.4347187578678131
3 35906 0.19192884862422943
4 35906 0.2502567172050476
5 35906 0.16337119042873383
6 35906 0.2806258201599121
7 35906 0.10624302178621292
8 35906 0.08679938316345215
9 35906 0.20545503497123718
10 35906 0.1659625917673111
11 35906 0.12257684767246246
12 35906 0.13965177536010742
13 35906 0.19151709973812103
14 35906 0.21626006066799164
15 35906 0.23525725305080414
16 35906 0.12116962671279907
17 35906 0.2069079428911209
18 35906 0.07583251595497131
19 35906 0.06586533039808273
20 35906 0.1259821504354477
21 35906 0.16431015729904175
22 35906 0.32231131196022034
23 35906 0.08864296972751617
24 35906 0.0
25 35906 0.009733498096466064
26 35906 0.12218397110700607
27 35906 0.0
28 35906 0.0
29 35906 0.10453992336988449
30 35906 0.053341858088970184
31 35906 0.14670026302337646
32 35906 0.21880708634853363
33 35906 0.2003263533115387
34 35906 0.15972527861595154
35 35906 0.3584444224834442
36 35906 0.14968015253543854
37 35906 0.27384260296821594
38 35906 0.20028981566429138
39 35906 0.2113504409790039
40 35906 0.19284316897392273
41 35906 0.36560967564582825
42 35906 0.12067119032144547
43 35906 0.006384670734405518
44 35906 0.0
45 35906 0.10769437998533249
46 35906 0.0520632341504097
47 35906 0.12473432719707489
48 35906 0.0
49 35906 0.36052924394607544
50 35906 0.21667377650737762
51 35906 0.1590680181980133
52 35906 0.5097138285636902
53 35906 0.33565133810043335
54 35906 0.49875757098197937
55 35906 0.30752867460250854
56 35906 0.32543718814849854
57 35906 0.2594597637653351
58 35906 0.2565697133541107
59 35906 0.0
60 35906 0.3172895908355713
61 35906 0.1925383061170578
62 35906 0.5615825057029724
63 35906 0.2721570134162903
64 35906 0.1100556030869484
65 35906 0.18250998854637146
66 35906 0.0
67 35906 0.2930799424648285
68 35906 0.12403760105371475
69 35906 0.1509244292974472
70 35906 0.059139274060726166
71 35906 0.30039820075035095
72 35906 0.26653197407722473
73 35906 0.21741200983524323
74 35906 0.21930453181266785
75 35906 0.05454636365175247
76 35906 0.04982759803533554
77 35906 0.19242322444915771
78 35906 0.27022019028663635
79 35906 0.24468779563903809
80 35906 0.1688263863325119
81 35906 0.1375638246536255
82 35906 0.09363672882318497
83 35906 0.0
84 35906 0.5143583416938782
85 35906 0.07256963104009628
86 35906 0.09277543425559998
87 35906 0.2519429922103882
88 35906 0.16111379861831665
89 35906 0.08165237307548523
train - Global loss: 0.181928    Embedding norm: 10.1511   Triplets (all/active): 399.0/20979.5
Pos dist (min/mean/max): 1.6863/2.2023/3.0631   Neg dist (min/mean/max): 2.3378/3.7569/5.6152
0 1011 0.47356975078582764
1 1011 0.5433279871940613
2 1011 0.8738873600959778
val - Global loss: 0.630262    Embedding norm: 9.5394   Triplets (all/active): 337.0/104961.3
Pos dist (min/mean/max): 0.7720/1.6253/2.8881   Neg dist (min/mean/max): 0.6384/2.1750/3.7176
0 35906 0.11320740729570389
1 35906 0.2218484729528427
2 35906 0.43500953912734985
3 35906 0.15879803895950317
4 35906 0.23269052803516388
5 35906 0.14713042974472046
6 35906 0.2781343460083008
7 35906 0.10100805014371872
8 35906 0.0846557468175888
9 35906 0.16744637489318848
10 35906 0.1648317277431488
11 35906 0.10853560268878937
12 35906 0.11452381312847137
13 35906 0.2079717367887497
14 35906 0.2339383065700531
15 35906 0.24752163887023926
16 35906 0.12041404843330383
17 35906 0.20659393072128296
18 35906 0.0769982859492302
19 35906 0.047941308468580246
20 35906 0.12883763015270233
21 35906 0.13664749264717102
22 35906 0.3483651578426361
23 35906 0.09085416048765182
24 35906 0.0
25 35906 0.0
26 35906 0.12046484649181366
27 35906 0.0
28 35906 0.0
29 35906 0.0
30 35906 0.016433147713541985
31 35906 0.08973368257284164
32 35906 0.12499536573886871
33 35906 0.19380144774913788
34 35906 0.1572837084531784
35 35906 0.12493906170129776
36 35906 0.09883490949869156
37 35906 0.24937042593955994
38 35906 0.26420557498931885
39 35906 0.31300634145736694
40 35906 0.13473503291606903
41 35906 0.29238617420196533
42 35906 0.0
43 35906 0.0
44 35906 0.0
45 35906 0.026115238666534424
46 35906 0.0
47 35906 0.0
48 35906 0.0
49 35906 0.23114320635795593
50 35906 0.18164297938346863
51 35906 0.22816653549671173
52 35906 0.3417947590351105
53 35906 0.26693323254585266
54 35906 0.2649039328098297
55 35906 0.15763531625270844
56 35906 0.05109744891524315
57 35906 0.18638010323047638
58 35906 0.27383285760879517
59 35906 0.0
60 35906 0.2684333026409149
61 35906 0.24747486412525177
62 35906 0.550300657749176
63 35906 0.20382608473300934
64 35906 0.03760629892349243
65 35906 0.06898865103721619
66 35906 0.0
67 35906 0.3512822389602661
68 35906 0.16438435018062592
69 35906 0.2606353163719177
70 35906 0.0
71 35906 0.2638854384422302
72 35906 0.26468613743782043
73 35906 0.0960378348827362
74 35906 0.15223437547683716
75 35906 0.062471210956573486
76 35906 0.0
77 35906 0.18092560768127441
78 35906 0.23458310961723328
79 35906 0.1844591498374939
80 35906 0.14427673816680908
81 35906 0.06235186383128166
82 35906 0.0
83 35906 0.0
84 35906 0.5765997171401978
85 35906 0.0
86 35906 0.09410306066274643
87 35906 0.13195370137691498
88 35906 0.09802084416151047
89 35906 0.05057327821850777
train - Global loss: 0.147931    Embedding norm: 10.2067   Triplets (all/active): 399.0/15150.8
Pos dist (min/mean/max): 1.7576/2.2705/3.0450   Neg dist (min/mean/max): 2.5926/4.0647/6.0292
0 1011 0.5157054662704468
1 1011 0.58744215965271
2 1011 0.9139164686203003
val - Global loss: 0.672355    Embedding norm: 9.7837   Triplets (all/active): 337.0/105826.7
Pos dist (min/mean/max): 0.8065/1.6783/2.9706   Neg dist (min/mean/max): 0.5972/2.2156/4.0569
0 35906 0.11288783699274063
1 35906 0.23548807203769684
2 35906 0.31992870569229126
3 35906 0.13266144692897797
4 35906 0.2410614937543869
5 35906 0.12927180528640747
6 35906 0.28829047083854675
7 35906 0.09071516990661621
8 35906 0.07618482410907745
9 35906 0.2068662941455841
10 35906 0.14433342218399048
11 35906 0.09688843041658401
12 35906 0.10912104696035385
13 35906 0.21966224908828735
14 35906 0.23116473853588104
15 35906 0.21422648429870605
16 35906 0.1344868242740631
17 35906 0.22245563566684723
18 35906 0.07159655541181564
19 35906 0.0316452793776989
20 35906 0.13970635831356049
21 35906 0.15539661049842834
22 35906 0.22213098406791687
23 35906 0.0
24 35906 0.0
25 35906 0.0
26 35906 0.053425345569849014
27 35906 0.0
28 35906 0.0
29 35906 0.0
30 35906 0.0
31 35906 0.0
32 35906 0.20378154516220093
33 35906 0.14998270571231842
34 35906 0.1171940267086029
35 35906 0.06182907894253731
36 35906 0.08376342058181763
37 35906 0.15809553861618042
38 35906 0.2104363739490509
39 35906 0.36219894886016846
40 35906 0.12638165056705475
41 35906 0.1557687371969223
42 35906 0.0
43 35906 0.0
44 35906 0.0
45 35906 0.0
46 35906 0.0
47 35906 0.0
48 35906 0.0
49 35906 0.3194314241409302
50 35906 0.12367663532495499
51 35906 0.0
52 35906 0.25264880061149597
53 35906 0.1810663938522339
54 35906 0.30946841835975647
55 35906 0.0
56 35906 0.14925359189510345
57 35906 0.014768932946026325
58 35906 0.22430431842803955
59 35906 0.0
60 35906 0.1436079889535904
61 35906 0.26361584663391113
62 35906 0.41896575689315796
63 35906 0.1487809270620346
64 35906 0.02323538064956665
65 35906 0.0
66 35906 0.0
67 35906 0.45186731219291687
68 35906 0.11935071647167206
69 35906 0.16685661673545837
70 35906 0.17150147259235382
71 35906 0.302028626203537
72 35906 0.2285490483045578
73 35906 0.11297152936458588
74 35906 0.010683834552764893
75 35906 0.07541017979383469
76 35906 0.0
77 35906 0.26058652997016907
78 35906 0.3142295479774475
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 372, in do_train
    for index, (query, positives, negatives) in enumerate(dataloaders[phase]):
  File "/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _next_data
    idx, data = self._get_data()
  File "/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1315, in _get_data
    success, data = self._try_get_data()
  File "/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1163, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/usr/local/lib/python3.9/queue.py", line 180, in get
    self.not_empty.wait(remaining)
  File "/usr/local/lib/python3.9/threading.py", line 316, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
