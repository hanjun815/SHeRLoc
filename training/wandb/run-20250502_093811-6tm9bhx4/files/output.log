  0%|                                                   | 0/20 [00:00<?, ?it/s]
0 11083 0.427619606256485
1 11083 0.5372024774551392
2 11083 0.49884599447250366
3 11083 0.49576884508132935
4 11083 0.4147905707359314
5 11083 0.358206182718277
6 11083 0.2781486511230469
7 11083 0.38912448287010193
8 11083 0.3426658809185028
9 11083 0.2783645987510681
10 11083 0.2485577017068863
11 11083 0.25605857372283936
12 11083 0.2879260182380676
13 11083 0.2149779349565506
14 11083 0.2384682595729828
15 11083 0.2648349106311798
16 11083 0.20928655564785004
17 11083 0.23820601403713226
18 11083 0.29622551798820496
19 11083 0.2727055847644806
20 11083 0.19143973290920258
21 11083 0.20473997294902802
22 11083 0.2107315957546234
23 11083 0.22527241706848145
24 11083 0.1315380483865738
25 11083 0.1500856876373291
26 11083 0.2190522700548172
27 11083 0.12471378594636917
28 11083 0.12796084582805634
29 11083 0.144102081656456
30 11083 0.13871154189109802
31 11083 0.1619955599308014
32 11083 0.10934009402990341
33 11083 0.13156984746456146
34 11083 0.08101653307676315
35 11083 0.1402888149023056
36 11083 0.12574170529842377
37 11083 0.09010296314954758
38 11083 0.14233094453811646
39 11083 0.1228921040892601
40 11083 0.15859344601631165
41 11083 0.10010078549385071
42 11083 0.10808077454566956
43 11083 0.13298749923706055
44 11083 0.13394153118133545
45 11083 0.12436627596616745
46 11083 0.14864680171012878
47 11083 0.1065380871295929
48 11083 0.20923762023448944
49 11083 0.1631200909614563
50 11083 0.11240934580564499
51 11083 0.09126204252243042
52 11083 0.08996168524026871
53 11083 0.12114562839269638
54 11083 0.08935726433992386
55 11083 0.12259582430124283
56 11083 0.20008882880210876
57 11083 0.21654291450977325
58 11083 0.30983808636665344
59 11083 0.3859000504016876
60 11083 0.3706279695034027
61 11083 0.18331517279148102
62 11083 0.22592385113239288
63 11083 0.21142353117465973
64 11083 0.1474958062171936
65 11083 0.14136388897895813
66 11083 0.23159325122833252
67 11083 0.27845659852027893
68 11083 0.22116021811962128
69 11083 0.25568637251853943
70 11083 0.24859274923801422
71 11083 0.11314672976732254
72 11083 0.09017158299684525
73 11083 0.16299356520175934
74 11083 0.1362101137638092
75 11083 0.15934938192367554
76 11083 0.11963695287704468
77 11083 0.09796629846096039
78 11083 0.13345178961753845
79 11083 0.24401138722896576
80 11083 0.10844159871339798
81 11083 0.09886272251605988
82 11083 0.09718145430088043
83 11083 0.09276527911424637
84 11083 0.1493566483259201
85 11083 0.2878553569316864
86 11083 0.0831206887960434
87 11083 0.15000638365745544
88 11083 0.07599496841430664
89 11083 0.06752100586891174
90 11083 0.13001637160778046
91 11083 0.17090819776058197
92 11083 0.3035099506378174
93 11083 0.06776278465986252
94 11083 0.090823233127594
95 11083 0.08677861839532852
96 11083 0.12444356083869934
97 11083 0.1388835906982422
98 11083 0.10244403779506683
99 11083 0.12169349193572998
100 11083 0.07420418411493301
101 11083 0.09526841342449188
102 11083 0.1406804472208023
103 11083 0.1305864006280899
104 11083 0.15776470303535461
105 11083 0.1453721523284912
106 11083 0.11327031999826431
107 11083 0.13299325108528137
108 11083 0.0935104563832283
109 11083 0.10470206290483475
110 11083 0.0799923688173294
train - Global loss: 0.182303    Embedding norm: 1.0000   Triplets (all/active): 99.8/4071.8
Pos dist (min/mean/max): 0.3922/0.8446/1.3209   Neg dist (min/mean/max): 0.9138/1.4062/1.7569
0 445 0.0
1 445 0.06108854338526726
2 445 0.04102282598614693
3 445 0.08649097383022308
4 445 0.0
val - Global loss: 0.037720    Embedding norm: 1.0000   Triplets (all/active): 89.0/115.0
Pos dist (min/mean/max): 0.1238/0.2473/0.4797   Neg dist (min/mean/max): 0.8091/1.1615/1.4609
0 11083 0.14139710366725922
1 11083 0.0854807049036026
2 11083 0.09251675009727478
3 11083 0.05331108719110489
4 11083 0.15887737274169922
5 11083 0.08663021773099899
6 11083 0.0528251975774765
7 11083 0.13587306439876556
8 11083 0.08395983278751373
9 11083 0.07570743560791016
10 11083 0.09654538333415985
11 11083 0.10444387793540955
12 11083 0.16891802847385406
13 11083 0.08378250896930695
14 11083 0.08731502294540405
15 11083 0.06709933280944824
16 11083 0.04328467696905136
17 11083 0.08837724477052689
18 11083 0.07988298684358597
19 11083 0.11797063797712326
20 11083 0.04961005598306656
21 11083 0.07172004133462906
22 11083 0.11870408803224564
23 11083 0.11749554425477982
24 11083 0.06499388068914413
25 11083 0.07662265002727509
26 11083 0.09406653046607971
27 11083 0.07679612189531326
28 11083 0.11514554172754288
29 11083 0.08041287958621979
30 11083 0.0798870399594307
31 11083 0.07565077394247055
32 11083 0.09761589020490646
33 11083 0.06825244426727295
34 11083 0.04224388673901558
35 11083 0.07488923519849777
36 11083 0.07856228947639465
37 11083 0.044840894639492035
38 11083 0.06399063020944595
39 11083 0.0740945041179657
40 11083 0.07309288531541824
41 11083 0.1496051698923111
42 11083 0.0784427598118782
43 11083 0.09894555807113647
44 11083 0.09660421311855316
45 11083 0.07862918078899384
46 11083 0.0655171126127243
47 11083 0.06008913367986679
48 11083 0.14354200661182404
49 11083 0.11786019802093506
50 11083 0.044493552297353745
51 11083 0.04796793311834335
52 11083 0.04505833610892296
53 11083 0.09846382588148117
54 11083 0.07071185111999512
55 11083 0.04547165334224701
56 11083 0.15554186701774597
57 11083 0.12283572554588318
58 11083 0.26569870114326477
59 11083 0.36765480041503906
60 11083 0.3391311466693878
61 11083 0.14494666457176208
62 11083 0.12942396104335785
63 11083 0.1597607582807541
64 11083 0.12727497518062592
65 11083 0.047839801758527756
66 11083 0.16560012102127075
67 11083 0.23749688267707825
68 11083 0.1855023056268692
69 11083 0.23416109383106232
70 11083 0.17921051383018494
71 11083 0.13529783487319946
72 11083 0.0875282883644104
73 11083 0.1548391431570053
74 11083 0.09764998406171799
75 11083 0.15900343656539917
76 11083 0.06992201507091522
77 11083 0.05298684164881706
78 11083 0.10383705794811249
79 11083 0.18185731768608093
80 11083 0.09235873073339462
81 11083 0.07984062284231186
82 11083 0.06417782604694366
83 11083 0.10230426490306854
84 11083 0.11818669736385345
85 11083 0.27448248863220215
86 11083 0.07309591770172119
87 11083 0.09043426811695099
88 11083 0.033544883131980896
89 11083 0.08159104734659195
90 11083 0.18701666593551636
91 11083 0.17968522012233734
92 11083 0.22075344622135162
93 11083 0.07534844428300858
94 11083 0.08286330848932266
95 11083 0.08258888125419617
96 11083 0.15053805708885193
97 11083 0.14576779305934906
98 11083 0.07185892760753632
99 11083 0.076382115483284
100 11083 0.06416069716215134
101 11083 0.08092715591192245
102 11083 0.12094587832689285
103 11083 0.09101814776659012
104 11083 0.12081483751535416
105 11083 0.1047283485531807
106 11083 0.10965248197317123
107 11083 0.10768158733844757
108 11083 0.06860516965389252
109 11083 0.10081953555345535
110 11083 0.10897459089756012
train - Global loss: 0.108563    Embedding norm: 1.0000   Triplets (all/active): 99.8/2378.5
Pos dist (min/mean/max): 0.4146/0.8044/1.1642   Neg dist (min/mean/max): 1.0405/1.4096/1.6900
0 445 0.016629278659820557
1 445 0.020133111625909805
2 445 0.013778376393020153
3 445 0.04085814207792282
4 445 0.0
val - Global loss: 0.018280    Embedding norm: 1.0000   Triplets (all/active): 89.0/26.8
Pos dist (min/mean/max): 0.1296/0.2871/0.5338   Neg dist (min/mean/max): 0.9413/1.2366/1.5086
0 11083 0.10468636453151703
1 11083 0.07951121032238007
2 11083 0.08632718771696091
3 11083 0.0758914053440094
4 11083 0.12668564915657043
5 11083 0.05800583213567734
6 11083 0.08725342899560928
7 11083 0.08955585211515427
8 11083 0.06995446979999542
9 11083 0.06858263909816742
10 11083 0.07504066079854965
11 11083 0.12154418230056763
12 11083 0.09678058326244354
13 11083 0.0565163753926754
14 11083 0.05858111381530762
15 11083 0.09122295677661896
16 11083 0.05210469663143158
17 11083 0.057032957673072815
18 11083 0.06903349608182907
19 11083 0.08059769123792648
20 11083 0.08186019957065582
21 11083 0.045384619385004044
22 11083 0.0992405042052269
23 11083 0.050814855843782425
24 11083 0.08506180346012115
25 11083 0.04328269511461258
26 11083 0.09909608960151672
27 11083 0.045451708137989044
28 11083 0.09022752195596695
29 11083 0.08421455323696136
30 11083 0.0992625430226326
31 11083 0.0686822161078453
32 11083 0.0759480819106102
33 11083 0.050610095262527466
34 11083 0.2572653889656067
35 11083 0.07620786875486374
36 11083 0.050934601575136185
37 11083 0.020865775644779205
38 11083 0.04997100681066513
39 11083 0.07969427853822708
40 11083 0.08098568767309189
41 11083 0.06731291860342026
42 11083 0.07260904461145401
43 11083 0.13256250321865082
44 11083 0.07375184446573257
45 11083 0.09302294254302979
46 11083 0.07492104172706604
47 11083 0.0526396818459034
48 11083 0.10429469496011734
49 11083 0.08375916630029678
50 11083 0.04404127597808838
51 11083 0.0902441143989563
52 11083 0.07283274084329605
53 11083 0.10189884901046753
54 11083 0.08564496785402298
55 11083 0.05753275379538536
56 11083 0.1012972891330719
57 11083 0.12444546073675156
58 11083 0.23926138877868652
59 11083 0.34438273310661316
60 11083 0.3283478915691376
61 11083 0.13070179522037506
62 11083 0.0793333649635315
63 11083 0.14918597042560577
64 11083 0.08103091269731522
65 11083 0.04907459765672684
66 11083 0.1543462872505188
67 11083 0.21782001852989197
68 11083 0.1720876693725586
69 11083 0.1639472097158432
70 11083 0.15734060108661652
71 11083 0.1387719362974167
72 11083 0.0937487855553627
73 11083 0.15752418339252472
74 11083 0.0599852129817009
75 11083 0.0989859476685524
76 11083 0.06508094072341919
77 11083 0.06788050383329391
78 11083 0.10645001381635666
79 11083 0.22991810739040375
80 11083 0.11140081286430359
81 11083 0.06958454847335815
82 11083 0.05539785698056221
83 11083 0.059055984020233154
84 11083 0.09407267719507217
85 11083 0.3440634310245514
86 11083 0.0360291488468647
87 11083 0.029603036120533943
88 11083 0.07312367856502533
89 11083 0.04047784209251404
90 11083 0.13877278566360474
91 11083 0.1336636245250702
92 11083 0.2152058482170105
93 11083 0.033951468765735626
94 11083 0.06055383384227753
95 11083 0.0865674689412117
96 11083 0.1059379130601883
97 11083 0.1687770038843155
98 11083 0.049311280250549316
99 11083 0.09306231886148453
100 11083 0.05992743745446205
101 11083 0.07311958819627762
102 11083 0.148466095328331
103 11083 0.06591793149709702
104 11083 0.10041370242834091
105 11083 0.15133164823055267
106 11083 0.09207937866449356
107 11083 0.09849249571561813
108 11083 0.11524663865566254
109 11083 0.10456522554159164
110 11083 0.07984931021928787
train - Global loss: 0.099514    Embedding norm: 1.0000   Triplets (all/active): 99.8/1961.3
Pos dist (min/mean/max): 0.4222/0.8000/1.1535   Neg dist (min/mean/max): 1.0626/1.4107/1.6655
0 445 0.0
1 445 0.030688505619764328
2 445 0.04738598316907883
3 445 0.022205615416169167
4 445 0.0
val - Global loss: 0.020056    Embedding norm: 1.0000   Triplets (all/active): 89.0/28.4
Pos dist (min/mean/max): 0.1238/0.2961/0.5760   Neg dist (min/mean/max): 0.9686/1.3186/1.6021
0 11083 0.10483924299478531
1 11083 0.04918598011136055
2 11083 0.10604944825172424
3 11083 0.07581813633441925
4 11083 0.08567412197589874
5 11083 0.07727591693401337
6 11083 0.040864329785108566
7 11083 0.08773967623710632
8 11083 0.06916950643062592
9 11083 0.048804283142089844
10 11083 0.05822988599538803
11 11083 0.0525866337120533
12 11083 0.14035476744174957
13 11083 0.04928279295563698
14 11083 0.05691070109605789
15 11083 0.07449629157781601
16 11083 0.053391940891742706
17 11083 0.03854641318321228
18 11083 0.08529186248779297
19 11083 0.07883213460445404
20 11083 0.03993937745690346
21 11083 0.0548313669860363
22 11083 0.07119453698396683
23 11083 0.06608805060386658
24 11083 0.07059014588594437
25 11083 0.04913707077503204
26 11083 0.06398063153028488
27 11083 0.05034320801496506
28 11083 0.087949737906456
29 11083 0.08083375543355942
30 11083 0.09995272755622864
31 11083 0.08465222269296646
32 11083 0.08318939059972763
33 11083 0.11484140902757645
34 11083 0.06477280706167221
35 11083 0.04981447011232376
36 11083 0.03471892699599266
37 11083 0.03707500547170639
38 11083 0.08558961004018784
39 11083 0.07466290891170502
40 11083 0.09334491938352585
41 11083 0.07679365575313568
42 11083 0.04861056059598923
43 11083 0.09978669881820679
44 11083 0.05832696706056595
45 11083 0.06479871273040771
46 11083 0.1050182431936264
47 11083 0.06697511672973633
48 11083 0.10880102217197418
49 11083 0.07471760362386703
50 11083 0.07795727252960205
51 11083 0.035105638206005096
52 11083 0.038895927369594574
53 11083 0.056737225502729416
54 11083 0.05399009957909584
55 11083 0.07288172841072083
56 11083 0.086807981133461
57 11083 0.0955343246459961
58 11083 0.24060794711112976
59 11083 0.32451045513153076
60 11083 0.3240323066711426
61 11083 0.17412111163139343
62 11083 0.11335854232311249
63 11083 0.12091459333896637
64 11083 0.13419951498508453
65 11083 0.09179633855819702
66 11083 0.15596020221710205
67 11083 0.2171677201986313
68 11083 0.18676075339317322
69 11083 0.19698722660541534
70 11083 0.14268308877944946
71 11083 0.09537631273269653
72 11083 0.0725536122918129
73 11083 0.11904486268758774
74 11083 0.11161942780017853
75 11083 0.10465764999389648
76 11083 0.08742621541023254
77 11083 0.05014607310295105
78 11083 0.08590439707040787
79 11083 0.24076388776302338
80 11083 0.08759231120347977
81 11083 0.057320740073919296
82 11083 0.06480668485164642
83 11083 0.024151215329766273
84 11083 0.1393248736858368
85 11083 0.27670371532440186
86 11083 0.05100571736693382
87 11083 0.09513122588396072
88 11083 0.06214291229844093
89 11083 0.04743122681975365
90 11083 0.15229853987693787
91 11083 0.12835440039634705
92 11083 0.20785103738307953
93 11083 0.024145714938640594
94 11083 0.1131414845585823
95 11083 0.042570561170578
96 11083 0.07199496030807495
97 11083 0.19625486433506012
98 11083 0.061452947556972504
99 11083 0.07144083082675934
100 11083 0.05236172676086426
101 11083 0.06271680444478989
102 11083 0.10280714929103851
103 11083 0.0584232322871685
104 11083 0.11584414541721344
105 11083 0.13368819653987885
106 11083 0.11525150388479233
107 11083 0.08199197798967361
108 11083 0.08873086422681808
109 11083 0.0758262649178505
110 11083 0.0948743000626564
train - Global loss: 0.094242    Embedding norm: 1.0000   Triplets (all/active): 99.8/1759.4
Pos dist (min/mean/max): 0.4180/0.7887/1.1291   Neg dist (min/mean/max): 1.0753/1.4102/1.6650
0 445 0.0
1 445 0.030055485665798187
2 445 0.01068844459950924
3 445 0.024106908589601517
4 445 0.0
val - Global loss: 0.012970    Embedding norm: 1.0000   Triplets (all/active): 89.0/9.2
Pos dist (min/mean/max): 0.1434/0.2915/0.5248   Neg dist (min/mean/max): 0.9526/1.2769/1.5201
0 11083 0.12014327943325043
1 11083 0.05442904680967331
2 11083 0.12264267355203629
3 11083 0.08333966135978699
4 11083 0.0996352881193161
5 11083 0.09627978503704071
6 11083 0.03549182415008545
7 11083 0.10006682574748993
8 11083 0.06266620755195618
9 11083 0.07712358981370926
10 11083 0.037706244736909866
11 11083 0.07964286208152771
12 11083 0.07356417924165726
13 11083 0.066401407122612
14 11083 0.06571070849895477
15 11083 0.05153961107134819
16 11083 0.10039275139570236
17 11083 0.036955561488866806
18 11083 0.1067904457449913
19 11083 0.0585777647793293
20 11083 0.03976830095052719
21 11083 0.04044123739004135
22 11083 0.10453664511442184
23 11083 0.050807517021894455
24 11083 0.05480441078543663
25 11083 0.06342532485723495
26 11083 0.08371641486883163
27 11083 0.057827383279800415
28 11083 0.04435582458972931
29 11083 0.07385731488466263
30 11083 0.06314346194267273
31 11083 0.0833229199051857
32 11083 0.058736711740493774
33 11083 0.05214086174964905
34 11083 0.042674239724874496
35 11083 0.06753809750080109
36 11083 0.060368482023477554
37 11083 0.03238474577665329
38 11083 0.058736201375722885
39 11083 0.05987265706062317
40 11083 0.0408785417675972
41 11083 0.06901732087135315
42 11083 0.030904851853847504
43 11083 0.14072705805301666
44 11083 0.09849430620670319
45 11083 0.02815529704093933
46 11083 0.06668009608983994
47 11083 0.04194552078843117
48 11083 0.11911030113697052
49 11083 0.09310020506381989
50 11083 0.10422702878713608
51 11083 0.041766028851270676
52 11083 0.03738021478056908
53 11083 0.07642649859189987
54 11083 0.060025960206985474
55 11083 0.05568581074476242
56 11083 0.11145645380020142
57 11083 0.1117515042424202
58 11083 0.22666719555854797
59 11083 0.3135780990123749
60 11083 0.31782248616218567
61 11083 0.1480950266122818
62 11083 0.10214262455701828
63 11083 0.1252862513065338
64 11083 0.10448040068149567
65 11083 0.04190051183104515
66 11083 0.1609714925289154
67 11083 0.23003315925598145
68 11083 0.19292913377285004
69 11083 0.18189887702465057
70 11083 0.13568422198295593
71 11083 0.15993939340114594
72 11083 0.08527114242315292
73 11083 0.1753043383359909
74 11083 0.09370515495538712
75 11083 0.06933923810720444
76 11083 0.07534364610910416
77 11083 0.07200729846954346
78 11083 0.09059173613786697
79 11083 0.21538035571575165
80 11083 0.0994824692606926
81 11083 0.06863727420568466
82 11083 0.06394118815660477
83 11083 0.036328986287117004
84 11083 0.11398427188396454
85 11083 0.29707449674606323
86 11083 0.06106383726000786
87 11083 0.0653240978717804
88 11083 0.09797166287899017
89 11083 0.08434053510427475
90 11083 0.1456008106470108
91 11083 0.12688539922237396
92 11083 0.20747260749340057
93 11083 0.044097937643527985
94 11083 0.07019942253828049
95 11083 0.04883017763495445
96 11083 0.08277421444654465
97 11083 0.14208944141864777
98 11083 0.06048994138836861
99 11083 0.09517545998096466
100 11083 0.050977978855371475
101 11083 0.07501377165317535
102 11083 0.09040319919586182
103 11083 0.07476798444986343
104 11083 0.08519312739372253
105 11083 0.12446165084838867
106 11083 0.06370612233877182
107 11083 0.05380712077021599
108 11083 0.0983273908495903
109 11083 0.061278194189071655
110 11083 0.10554546862840652
train - Global loss: 0.092459    Embedding norm: 1.0000   Triplets (all/active): 99.8/1794.7
Pos dist (min/mean/max): 0.4324/0.7965/1.1378   Neg dist (min/mean/max): 1.0855/1.4111/1.6572
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.025006473064422607
4 445 0.0
val - Global loss: 0.005001    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.4
Pos dist (min/mean/max): 0.1664/0.3293/0.5695   Neg dist (min/mean/max): 1.0787/1.3444/1.5487
0 11083 0.07159121334552765
1 11083 0.09934961795806885
2 11083 0.039992555975914
3 11083 0.06159834563732147
4 11083 0.07313169538974762
5 11083 0.07718445360660553
6 11083 0.05262666195631027
7 11083 0.07608776539564133
8 11083 0.04227730259299278
9 11083 0.05500738322734833
10 11083 0.04383891820907593
11 11083 0.08539644628763199
12 11083 0.11695230007171631
13 11083 0.06274940818548203
14 11083 0.09483395516872406
15 11083 0.09790050983428955
16 11083 0.029535934329032898
17 11083 0.0931486114859581
18 11083 0.09551426768302917
19 11083 0.13749165832996368
20 11083 0.025156773626804352
21 11083 0.05007005110383034
22 11083 0.08231108635663986
23 11083 0.06845591962337494
24 11083 0.07101179659366608
25 11083 0.06267210096120834
26 11083 0.05722908675670624
27 11083 0.032863035798072815
28 11083 0.04730449244379997
29 11083 0.09171301871538162
30 11083 0.041822731494903564
31 11083 0.053609300404787064
32 11083 0.08630523085594177
33 11083 0.044264428317546844
34 11083 0.06801169365644455
35 11083 0.058922700583934784
36 11083 0.03721509873867035
37 11083 0.030342387035489082
38 11083 0.062167078256607056
39 11083 0.06674584746360779
40 11083 0.053947292268276215
41 11083 0.09383807331323624
42 11083 0.012468811124563217
43 11083 0.07846355438232422
44 11083 0.09421242773532867
45 11083 0.06304249167442322
46 11083 0.06067529320716858
47 11083 0.028655147179961205
48 11083 0.11993709206581116
49 11083 0.08528397977352142
50 11083 0.10121840238571167
51 11083 0.031980402767658234
52 11083 0.05965706333518028
53 11083 0.06260595470666885
54 11083 0.050767309963703156
55 11083 0.04150208830833435
56 11083 0.06616264581680298
57 11083 0.13061945140361786
58 11083 0.22010503709316254
59 11083 0.3314458131790161
60 11083 0.2929193675518036
61 11083 0.1382424682378769
62 11083 0.12433572858572006
63 11083 0.11129644513130188
64 11083 0.11827028542757034
65 11083 0.048317234963178635
66 11083 0.13222256302833557
67 11083 0.2278105616569519
68 11083 0.18492478132247925
69 11083 0.18934091925621033
70 11083 0.10947831720113754
71 11083 0.11545448005199432
72 11083 0.04732702672481537
73 11083 0.13385123014450073
74 11083 0.0957571268081665
75 11083 0.07702939212322235
76 11083 0.07929639518260956
77 11083 0.05150957405567169
78 11083 0.07637470960617065
79 11083 0.23589372634887695
80 11083 0.07890110462903976
81 11083 0.060862258076667786
82 11083 0.0395708791911602
83 11083 0.02904895693063736
84 11083 0.12003704160451889
85 11083 0.29731473326683044
86 11083 0.04506957530975342
87 11083 0.06874042749404907
88 11083 0.0426165908575058
89 11083 0.05329573526978493
90 11083 0.11090271174907684
91 11083 0.13251416385173798
92 11083 0.24252918362617493
93 11083 0.048462916165590286
94 11083 0.055236831307411194
95 11083 0.03247760981321335
96 11083 0.09318286925554276
97 11083 0.1214701384305954
98 11083 0.09003522247076035
99 11083 0.06371159106492996
100 11083 0.08983571827411652
101 11083 0.06604412198066711
102 11083 0.10308056324720383
103 11083 0.0882364809513092
104 11083 0.08779806643724442
105 11083 0.1049625501036644
106 11083 0.04741126298904419
107 11083 0.086224764585495
108 11083 0.07813402265310287
109 11083 0.06964876502752304
110 11083 0.08786424994468689
train - Global loss: 0.087891    Embedding norm: 1.0000   Triplets (all/active): 99.8/1612.9
Pos dist (min/mean/max): 0.4288/0.7923/1.1272   Neg dist (min/mean/max): 1.0924/1.4108/1.6486
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1426/0.2966/0.5546   Neg dist (min/mean/max): 1.0857/1.3460/1.5946
0 11083 0.06360232830047607
1 11083 0.05904696509242058
2 11083 0.11002761870622635
3 11083 0.06604044884443283
4 11083 0.11243391036987305
5 11083 0.10278842598199844
6 11083 0.04044730216264725
7 11083 0.06900383532047272
8 11083 0.059097323566675186
9 11083 0.1066906601190567
10 11083 0.07256694883108139
11 11083 0.06610143929719925
12 11083 0.08061325550079346
13 11083 0.07100705057382584
14 11083 0.07238342612981796
15 11083 0.08306676894426346
16 11083 0.05976790189743042
17 11083 0.03151099011301994
18 11083 0.047799356281757355
19 11083 0.07527295500040054
20 11083 0.04193434864282608
21 11083 0.04495735839009285
22 11083 0.06232341751456261
23 11083 0.08021052926778793
24 11083 0.042653888463974
25 11083 0.04963252693414688
26 11083 0.09309384971857071
27 11083 0.06753528863191605
28 11083 0.06814952939748764
29 11083 0.05072405934333801
30 11083 0.07455386221408844
31 11083 0.09592150151729584
32 11083 0.06648612767457962
33 11083 0.05686211213469505
34 11083 0.025530565530061722
35 11083 0.07181145995855331
36 11083 0.04163854941725731
37 11083 0.04373173415660858
38 11083 0.04081166908144951
39 11083 0.04976740851998329
40 11083 0.11375392228364944
41 11083 0.046573713421821594
42 11083 0.03858010843396187
43 11083 0.09029308706521988
44 11083 0.09363042563199997
45 11083 0.06143760308623314
46 11083 0.05305173993110657
47 11083 0.05868847668170929
48 11083 0.07024115324020386
49 11083 0.1035415455698967
50 11083 0.06456518918275833
51 11083 0.022483298555016518
52 11083 0.04299911856651306
53 11083 0.06149837374687195
54 11083 0.043591082096099854
55 11083 0.04207293689250946
56 11083 0.07102236151695251
57 11083 0.10418740659952164
58 11083 0.22651083767414093
59 11083 0.3256891965866089
60 11083 0.311878502368927
61 11083 0.13774026930332184
62 11083 0.12178575247526169
63 11083 0.1207975372672081
64 11083 0.06810693442821503
65 11083 0.041249629110097885
66 11083 0.12047144770622253
67 11083 0.24517232179641724
68 11083 0.18481570482254028
69 11083 0.16414810717105865
70 11083 0.10042891651391983
71 11083 0.07708258926868439
72 11083 0.054328061640262604
73 11083 0.11953757703304291
74 11083 0.08420870453119278
75 11083 0.06848248839378357
76 11083 0.03575187548995018
77 11083 0.05116051807999611
78 11083 0.08434806019067764
79 11083 0.20086900889873505
80 11083 0.05225083604454994
81 11083 0.04171035438776016
82 11083 0.044169832020998
83 11083 0.02886398322880268
84 11083 0.09636611491441727
85 11083 0.32243335247039795
86 11083 0.021779876202344894
87 11083 0.06416885554790497
88 11083 0.0643012672662735
89 11083 0.09341377019882202
90 11083 0.1684519499540329
91 11083 0.10305289924144745
92 11083 0.19614966213703156
93 11083 0.0748630240559578
94 11083 0.015540610067546368
95 11083 0.0259010698646307
96 11083 0.07375877350568771
97 11083 0.16859012842178345
98 11083 0.04192114993929863
99 11083 0.04937680438160896
100 11083 0.032508399337530136
101 11083 0.08481233566999435
102 11083 0.12713339924812317
103 11083 0.06603428721427917
104 11083 0.09298399090766907
105 11083 0.12465810030698776
106 11083 0.07556875050067902
107 11083 0.07275290042161942
108 11083 0.0751563310623169
109 11083 0.05761846899986267
110 11083 0.11139331758022308
train - Global loss: 0.084793    Embedding norm: 1.0000   Triplets (all/active): 99.8/1500.2
Pos dist (min/mean/max): 0.4263/0.7815/1.1075   Neg dist (min/mean/max): 1.0963/1.4103/1.6537
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.02938006818294525
4 445 0.0
val - Global loss: 0.005876    Embedding norm: 1.0000   Triplets (all/active): 89.0/1.6
Pos dist (min/mean/max): 0.1533/0.3141/0.5116   Neg dist (min/mean/max): 1.0583/1.3620/1.5911
0 11083 0.07249297946691513
1 11083 0.06449086964130402
2 11083 0.0856243297457695
3 11083 0.07622375339269638
4 11083 0.07781914621591568
5 11083 0.07529149949550629
6 11083 0.05924630165100098
7 11083 0.02287045121192932
8 11083 0.03173398599028587
9 11083 0.12077832221984863
10 11083 0.04219703748822212
11 11083 0.05508066341280937
12 11083 0.07686548680067062
13 11083 0.09538103640079498
14 11083 0.0458114929497242
15 11083 0.05909955874085426
16 11083 0.04586290568113327
17 11083 0.05857456475496292
18 11083 0.034665510058403015
19 11083 0.06127752363681793
20 11083 0.039651259779930115
21 11083 0.0525643527507782
22 11083 0.08467639982700348
23 11083 0.06636330485343933
24 11083 0.09009317308664322
25 11083 0.05137297511100769
26 11083 0.07345863431692123
27 11083 0.04707731306552887
28 11083 0.027127951383590698
29 11083 0.10195068269968033
30 11083 0.06306539475917816
31 11083 0.06146182864904404
32 11083 0.03280780836939812
33 11083 0.07436979562044144
34 11083 0.009550744667649269
35 11083 0.0600569024682045
36 11083 0.05892264097929001
37 11083 0.047940731048583984
38 11083 0.08170732855796814
39 11083 0.07773789018392563
40 11083 0.0806090384721756
41 11083 0.05440925434231758
42 11083 0.04081878811120987
43 11083 0.06865610927343369
44 11083 0.08641769737005234
45 11083 0.07208251953125
46 11083 0.07655369490385056
47 11083 0.044798772782087326
48 11083 0.08962151408195496
49 11083 0.08374956995248795
50 11083 0.04840756580233574
51 11083 0.03229094296693802
52 11083 0.03605695813894272
53 11083 0.06564832478761673
54 11083 0.038539912551641464
55 11083 0.046851690858602524
56 11083 0.08092857897281647
57 11083 0.099155493080616
58 11083 0.19936352968215942
59 11083 0.34250882267951965
60 11083 0.30440717935562134
61 11083 0.0994621217250824
62 11083 0.11594883352518082
63 11083 0.11771508306264877
64 11083 0.07286065071821213
65 11083 0.04707895219326019
66 11083 0.10118056833744049
67 11083 0.22986702620983124
68 11083 0.18144942820072174
69 11083 0.16790378093719482
70 11083 0.13502132892608643
71 11083 0.11548638343811035
72 11083 0.15498313307762146
73 11083 0.13017043471336365
74 11083 0.06946943700313568
75 11083 0.04586827754974365
76 11083 0.032494887709617615
77 11083 0.05015227198600769
78 11083 0.05821923911571503
79 11083 0.17970408499240875
80 11083 0.07775752991437912
81 11083 0.052891526371240616
82 11083 0.029536064714193344
83 11083 0.03018338792026043
84 11083 0.11454135179519653
85 11083 0.25713083148002625
86 11083 0.0440627746284008
87 11083 0.024735480546951294
88 11083 0.024134645238518715
89 11083 0.04100779816508293
90 11083 0.17454825341701508
91 11083 0.08213966339826584
92 11083 0.2312864512205124
93 11083 0.027927465736865997
94 11083 0.056658145040273666
95 11083 0.03656875342130661
96 11083 0.09632241725921631
97 11083 0.18124617636203766
98 11083 0.039124228060245514
99 11083 0.06759067624807358
100 11083 0.02836582250893116
101 11083 0.07397438585758209
102 11083 0.09959255158901215
103 11083 0.06822691857814789
104 11083 0.09122280776500702
105 11083 0.10768619924783707
106 11083 0.08455569297075272
107 11083 0.08202799409627914
108 11083 0.0995887741446495
109 11083 0.071648009121418
110 11083 0.05935976654291153
train - Global loss: 0.082125    Embedding norm: 1.0000   Triplets (all/active): 99.8/1406.1
Pos dist (min/mean/max): 0.4238/0.7841/1.0974   Neg dist (min/mean/max): 1.1049/1.4115/1.6538
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.03553617000579834
4 445 0.0
val - Global loss: 0.007107    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.4
Pos dist (min/mean/max): 0.1535/0.3183/0.5688   Neg dist (min/mean/max): 1.1061/1.4016/1.6025
0 11083 0.07579990476369858
1 11083 0.04894404113292694
2 11083 0.050940003246068954
3 11083 0.08377043157815933
4 11083 0.07370906323194504
5 11083 0.06298136711120605
6 11083 0.04320887476205826
7 11083 0.0913042277097702
8 11083 0.023999858647584915
9 11083 0.11388232558965683
10 11083 0.018391413614153862
11 11083 0.0623524934053421
12 11083 0.07641109824180603
13 11083 0.055129267275333405
14 11083 0.015366741456091404
15 11083 0.15214450657367706
16 11083 0.056443870067596436
17 11083 0.03579956293106079
18 11083 0.04493965208530426
19 11083 0.039359595626592636
20 11083 0.0
21 11083 0.030025100335478783
22 11083 0.039041198790073395
23 11083 0.06147431209683418
24 11083 0.08167513459920883
25 11083 0.032654810696840286
26 11083 0.055265359580516815
27 11083 0.01859014667570591
28 11083 0.05080823227763176
29 11083 0.04431091621518135
30 11083 0.1007189005613327
31 11083 0.07478795200586319
32 11083 0.056179117411375046
33 11083 0.044307637959718704
34 11083 0.02932804822921753
35 11083 0.029516899958252907
36 11083 0.037964921444654465
37 11083 0.044889163225889206
38 11083 0.06707175821065903
39 11083 0.054077837616205215
40 11083 0.050783198326826096
41 11083 0.0687493234872818
42 11083 0.053697556257247925
43 11083 0.11284039914608002
44 11083 0.09695331007242203
45 11083 0.024225017055869102
46 11083 0.04974283277988434
47 11083 0.03369652107357979
48 11083 0.13435573875904083
49 11083 0.060927171260118484
50 11083 0.12442301213741302
51 11083 0.04755689576268196
52 11083 0.02219407819211483
53 11083 0.043453704565763474
54 11083 0.040952686220407486
55 11083 0.049097176641225815
56 11083 0.060617417097091675
57 11083 0.11833546310663223
58 11083 0.20715731382369995
59 11083 0.3536142408847809
60 11083 0.3080436885356903
61 11083 0.12629809975624084
62 11083 0.07570115476846695
63 11083 0.1075960099697113
64 11083 0.08438412845134735
65 11083 0.038898225873708725
66 11083 0.12940864264965057
67 11083 0.22767676413059235
68 11083 0.17902688682079315
69 11083 0.17919014394283295
70 11083 0.09874439239501953
71 11083 0.09789776802062988
72 11083 0.03420642018318176
73 11083 0.15071718394756317
74 11083 0.08256209641695023
75 11083 0.05275241658091545
76 11083 0.0923229306936264
77 11083 0.06150374934077263
78 11083 0.057020023465156555
79 11083 0.22652669250965118
80 11083 0.0517597459256649
81 11083 0.029913034290075302
82 11083 0.04064366593956947
83 11083 0.04418768361210823
84 11083 0.07477812469005585
85 11083 0.24807587265968323
86 11083 0.0308408010751009
87 11083 0.10771968215703964
88 11083 0.023634282872080803
89 11083 0.0436272919178009
90 11083 0.13953784108161926
91 11083 0.059709832072257996
92 11083 0.23264700174331665
93 11083 0.05825177580118179
94 11083 0.025063317269086838
95 11083 0.04746239259839058
96 11083 0.08758192509412766
97 11083 0.1461390107870102
98 11083 0.04091871902346611
99 11083 0.07136904448270798
100 11083 0.03923964872956276
101 11083 0.07336800545454025
102 11083 0.07244417071342468
103 11083 0.0999053493142128
104 11083 0.0994698628783226
105 11083 0.09859252721071243
106 11083 0.07607363909482956
107 11083 0.07629594951868057
108 11083 0.08130951225757599
109 11083 0.08486084640026093
110 11083 0.0493616946041584
train - Global loss: 0.079245    Embedding norm: 1.0000   Triplets (all/active): 99.8/1301.9
Pos dist (min/mean/max): 0.4354/0.7774/1.0986   Neg dist (min/mean/max): 1.1180/1.4117/1.6453
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.044034358114004135
4 445 0.0
val - Global loss: 0.008807    Embedding norm: 1.0000   Triplets (all/active): 89.0/21.4
Pos dist (min/mean/max): 0.1514/0.3116/0.5689   Neg dist (min/mean/max): 1.1443/1.4099/1.6156
0 11083 0.056486260145902634
1 11083 0.03547761216759682
2 11083 0.08494477719068527
3 11083 0.10174988955259323
4 11083 0.10520409792661667
5 11083 0.06851594895124435
6 11083 0.014262991957366467
7 11083 0.07730215042829514
8 11083 0.06770798563957214
9 11083 0.039088763296604156
10 11083 0.03015543334186077
11 11083 0.07950872927904129
12 11083 0.0514381043612957
13 11083 0.04929357022047043
14 11083 0.0068557411432266235
15 11083 0.04673409461975098
16 11083 0.011944862082600594
17 11083 0.035755399614572525
18 11083 0.069866843521595
19 11083 0.0773174986243248
20 11083 0.0395469106733799
21 11083 0.02128668501973152
22 11083 0.0677143931388855
23 11083 0.05961759015917778
24 11083 0.022312629967927933
25 11083 0.020711367949843407
26 11083 0.06520570069551468
27 11083 0.03755716606974602
28 11083 0.03249228000640869
29 11083 0.01712184026837349
30 11083 0.05058892071247101
31 11083 0.05551502853631973
32 11083 0.09463035315275192
33 11083 0.046683721244335175
34 11083 0.01603873074054718
35 11083 0.06341707706451416
36 11083 0.028991980478167534
37 11083 0.05352092906832695
38 11083 0.03668631613254547
39 11083 0.043235164135694504
40 11083 0.07610088586807251
41 11083 0.04662635922431946
42 11083 0.02667989395558834
43 11083 0.05347258970141411
44 11083 0.08570841699838638
45 11083 0.05024662986397743
46 11083 0.0649525597691536
47 11083 0.07281631976366043
48 11083 0.05836644023656845
49 11083 0.09246505051851273
50 11083 0.03660106658935547
51 11083 0.03571354225277901
52 11083 0.05911833420395851
53 11083 0.03206109628081322
54 11083 0.047660090029239655
55 11083 0.08473452180624008
56 11083 0.05930767580866814
57 11083 0.14702582359313965
58 11083 0.22709505259990692
59 11083 0.3219330906867981
60 11083 0.3142511248588562
61 11083 0.11795860528945923
62 11083 0.10016542673110962
63 11083 0.10880450904369354
64 11083 0.06603210419416428
65 11083 0.04302679002285004
66 11083 0.15715260803699493
67 11083 0.2257443070411682
68 11083 0.1799442172050476
69 11083 0.16605699062347412
70 11083 0.10968371480703354
71 11083 0.07589086145162582
72 11083 0.021319914609193802
73 11083 0.12467772513628006
74 11083 0.062182046473026276
75 11083 0.04755450785160065
76 11083 0.031152013689279556
77 11083 0.028312155976891518
78 11083 0.05474983528256416
79 11083 0.18320326507091522
80 11083 0.061654720455408096
81 11083 0.05251861363649368
82 11083 0.012056401930749416
83 11083 0.025388944894075394
84 11083 0.09290605038404465
85 11083 0.2716574966907501
86 11083 0.046105850487947464
87 11083 0.05681495741009712
88 11083 0.027022741734981537
89 11083 0.03758189454674721
90 11083 0.13952068984508514
91 11083 0.090966135263443
92 11083 0.24079683423042297
93 11083 0.029586872085928917
94 11083 0.04938730224967003
95 11083 0.02064240537583828
96 11083 0.08563873171806335
97 11083 0.11689191311597824
98 11083 0.09979120641946793
99 11083 0.033539582043886185
100 11083 0.02942725270986557
101 11083 0.09091098606586456
102 11083 0.07051996141672134
103 11083 0.06712212413549423
104 11083 0.1022234559059143
105 11083 0.10842842608690262
106 11083 0.024896569550037384
107 11083 0.07394905388355255
108 11083 0.0785057544708252
109 11083 0.054884374141693115
110 11083 0.06395790725946426
train - Global loss: 0.074183    Embedding norm: 1.0000   Triplets (all/active): 99.8/1190.4
Pos dist (min/mean/max): 0.4257/0.7648/1.0675   Neg dist (min/mean/max): 1.1104/1.4110/1.6461
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1484/0.3007/0.5061   Neg dist (min/mean/max): 1.1648/1.4079/1.6296
0 11083 0.04689532518386841
1 11083 0.056767046451568604
2 11083 0.059818558394908905
3 11083 0.02897942066192627
4 11083 0.0691910907626152
5 11083 0.08607702702283859
6 11083 0.02149730548262596
7 11083 0.05019145458936691
8 11083 0.024298833683133125
9 11083 0.035601403564214706
10 11083 0.039746105670928955
11 11083 0.05616749823093414
12 11083 0.0447908453643322
13 11083 0.053878895938396454
14 11083 0.05613419786095619
15 11083 0.05241783335804939
16 11083 0.029569372534751892
17 11083 0.03094504028558731
18 11083 0.07995886355638504
19 11083 0.09245860576629639
20 11083 0.03046545386314392
21 11083 0.041956864297389984
22 11083 0.04288797453045845
23 11083 0.027507023885846138
24 11083 0.05604340881109238
25 11083 0.03917417675256729
26 11083 0.02583204209804535
27 11083 0.057124003767967224
28 11083 0.04307107627391815
29 11083 0.0359097383916378
30 11083 0.0526592992246151
31 11083 0.03189896047115326
32 11083 0.038026731461286545
33 11083 0.06113012507557869
34 11083 0.03475767746567726
35 11083 0.030989235267043114
36 11083 0.036548323929309845
37 11083 0.025944814085960388
38 11083 0.031387221068143845
39 11083 0.05798787996172905
40 11083 0.05685950070619583
41 11083 0.0418039970099926
42 11083 0.02507607452571392
43 11083 0.11925853043794632
44 11083 0.06498020142316818
45 11083 0.022561844438314438
46 11083 0.09060601145029068
47 11083 0.04764101281762123
48 11083 0.020766178146004677
49 11083 0.037166424095630646
50 11083 0.01311253197491169
51 11083 0.0012963712215423584
52 11083 0.022671110928058624
53 11083 0.01388463657349348
54 11083 0.05684886872768402
55 11083 0.08111453801393509
56 11083 0.0636235922574997
57 11083 0.09416970610618591
58 11083 0.20709563791751862
59 11083 0.3060521185398102
60 11083 0.27410122752189636
61 11083 0.1258210688829422
62 11083 0.06498227268457413
63 11083 0.11193087697029114
64 11083 0.09147950261831284
65 11083 0.04797718673944473
66 11083 0.12635202705860138
67 11083 0.23005253076553345
68 11083 0.1708395630121231
69 11083 0.14509688317775726
70 11083 0.09373576194047928
71 11083 0.08590446412563324
72 11083 0.0216880664229393
73 11083 0.11854574084281921
74 11083 0.07933156192302704
75 11083 0.049822572618722916
76 11083 0.0395597480237484
77 11083 0.08497084677219391
78 11083 0.05894511193037033
79 11083 0.16140444576740265
80 11083 0.07311692833900452
81 11083 0.04572446644306183
82 11083 0.03202164173126221
83 11083 0.018580056726932526
84 11083 0.10002660751342773
85 11083 0.23494739830493927
86 11083 0.05055772140622139
87 11083 0.09204984456300735
88 11083 0.04199803248047829
89 11083 0.040115877985954285
90 11083 0.12267258018255234
91 11083 0.07805179804563522
92 11083 0.2061968594789505
93 11083 0.01787104271352291
94 11083 0.0619632713496685
95 11083 0.020918432623147964
96 11083 0.059577420353889465
97 11083 0.14394956827163696
98 11083 0.026302894577383995
99 11083 0.020425060763955116
100 11083 0.01813148893415928
101 11083 0.03443921357393265
102 11083 0.06355646252632141
103 11083 0.04479647055268288
104 11083 0.08267629891633987
105 11083 0.06202298030257225
106 11083 0.06487152725458145
107 11083 0.06401776522397995
108 11083 0.058668967336416245
109 11083 0.07112623751163483
110 11083 0.06965609639883041
train - Global loss: 0.067629    Embedding norm: 1.0000   Triplets (all/active): 99.8/1037.9
Pos dist (min/mean/max): 0.4132/0.7542/1.0473   Neg dist (min/mean/max): 1.1182/1.4109/1.6475
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1432/0.3047/0.5668   Neg dist (min/mean/max): 1.1551/1.4177/1.6203
0 11083 0.05326726660132408
1 11083 0.10217922925949097
2 11083 0.0310206301510334
3 11083 0.033169619739055634
4 11083 0.05309218540787697
5 11083 0.02453639730811119
6 11083 0.05722356215119362
7 11083 0.058247264474630356
8 11083 0.03812575340270996
9 11083 0.035550426691770554
10 11083 0.03770557790994644
11 11083 0.06821950525045395
12 11083 0.08248435705900192
13 11083 0.05332203954458237
14 11083 0.020614763721823692
15 11083 0.03353418409824371
16 11083 0.03499987721443176
17 11083 0.012058958411216736
18 11083 0.03637407720088959
19 11083 0.081531822681427
20 11083 0.02524847351014614
21 11083 0.04382086917757988
22 11083 0.059419915080070496
23 11083 0.06020965054631233
24 11083 0.02495894394814968
25 11083 0.024116702377796173
26 11083 0.03636617213487625
27 11083 0.01737668551504612
28 11083 0.02845379151403904
29 11083 0.0574110746383667
30 11083 0.03340580686926842
31 11083 0.06330568343400955
32 11083 0.01182156428694725
33 11083 0.027414795011281967
34 11083 0.007759973406791687
35 11083 0.07738955318927765
36 11083 0.028609778732061386
37 11083 0.0017516016960144043
38 11083 0.02160080522298813
39 11083 0.027469540014863014
40 11083 0.029431970790028572
41 11083 0.056027851998806
42 11083 0.032223500311374664
43 11083 0.04356083646416664
44 11083 0.05054038017988205
45 11083 0.026242155581712723
46 11083 0.0419161394238472
47 11083 0.024805858731269836
48 11083 0.03443204239010811
49 11083 0.06326546519994736
50 11083 0.029412759467959404
51 11083 0.038197170943021774
52 11083 0.05053335800766945
53 11083 0.03927312418818474
54 11083 0.042288780212402344
55 11083 0.0343504324555397
56 11083 0.058997757732868195
57 11083 0.08647340536117554
58 11083 0.1854289025068283
59 11083 0.2605135142803192
60 11083 0.2646717131137848
61 11083 0.1361476182937622
62 11083 0.0741664469242096
63 11083 0.10180159658193588
64 11083 0.08437200635671616
65 11083 0.05305232107639313
66 11083 0.10403430461883545
67 11083 0.1823395937681198
68 11083 0.144745334982872
69 11083 0.13308443129062653
70 11083 0.07103381305932999
71 11083 0.06540732085704803
72 11083 0.056239526718854904
73 11083 0.0881754457950592
74 11083 0.05457310006022453
75 11083 0.05454851686954498
76 11083 0.015867915004491806
77 11083 0.09664756804704666
78 11083 0.053779587149620056
79 11083 0.1670013964176178
80 11083 0.028491631150245667
81 11083 0.03132089227437973
82 11083 0.03408880531787872
83 11083 0.05571155250072479
84 11083 0.052855804562568665
85 11083 0.2739018499851227
86 11083 0.007403634022921324
87 11083 0.038002241402864456
88 11083 0.03200279921293259
89 11083 0.02583167515695095
90 11083 0.13882732391357422
91 11083 0.06623314321041107
92 11083 0.1853870451450348
93 11083 0.03979486972093582
94 11083 0.015339761972427368
95 11083 0.0
96 11083 0.04634103551506996
97 11083 0.08850786089897156
98 11083 0.03252200037240982
99 11083 0.023009365424513817
100 11083 0.03167986869812012
101 11083 0.043000977486371994
102 11083 0.062299225479364395
103 11083 0.033270977437496185
104 11083 0.08510967344045639
105 11083 0.06927639991044998
106 11083 0.02612782083451748
107 11083 0.04013034328818321
108 11083 0.06964258849620819
109 11083 0.05604087561368942
110 11083 0.08290798217058182
train - Global loss: 0.060089    Embedding norm: 1.0000   Triplets (all/active): 99.8/918.3
Pos dist (min/mean/max): 0.4192/0.7493/1.0267   Neg dist (min/mean/max): 1.1292/1.4109/1.6413
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1517/0.3029/0.5398   Neg dist (min/mean/max): 1.1915/1.4055/1.6208
0 11083 0.04216831177473068
1 11083 0.022750677540898323
2 11083 0.06964722275733948
3 11083 0.02521451562643051
4 11083 0.05544476583600044
5 11083 0.016285443678498268
6 11083 0.0
7 11083 0.0670805424451828
8 11083 0.0335230715572834
9 11083 0.01462353765964508
10 11083 0.06387501209974289
11 11083 0.01814289018511772
12 11083 0.03605404123663902
13 11083 0.036589253693819046
14 11083 0.0
15 11083 0.06612007319927216
16 11083 0.02650536224246025
17 11083 0.037781424820423126
18 11083 0.013846347108483315
19 11083 0.07483574002981186
20 11083 0.034230273216962814
21 11083 0.03337232023477554
22 11083 0.03167306259274483
23 11083 0.03245771676301956
24 11083 0.04845203831791878
25 11083 0.03148278594017029
26 11083 0.027700679376721382
27 11083 0.009915166534483433
28 11083 0.0
29 11083 0.04451252892613411
30 11083 0.031214799731969833
31 11083 0.05312633141875267
32 11083 0.03685181215405464
33 11083 0.030916092917323112
34 11083 0.04282534494996071
35 11083 0.018137942999601364
36 11083 0.021571272984147072
37 11083 0.014207705855369568
38 11083 0.0450688861310482
39 11083 0.05360044166445732
40 11083 0.041928671300411224
41 11083 0.04742074012756348
42 11083 0.02165660262107849
43 11083 0.05267229676246643
44 11083 0.07464022934436798
45 11083 0.0624934621155262
46 11083 0.029957229271531105
47 11083 0.03361046686768532
48 11083 0.045326706022024155
49 11083 0.029276087880134583
50 11083 0.0
51 11083 0.03174832835793495
52 11083 0.018413672223687172
53 11083 0.011282797902822495
54 11083 0.06259572505950928
55 11083 0.04907671734690666
56 11083 0.04796760156750679
57 11083 0.05543072521686554
58 11083 0.1444670557975769
59 11083 0.25335952639579773
60 11083 0.24343624711036682
61 11083 0.11605820059776306
62 11083 0.08536383509635925
63 11083 0.11360778659582138
64 11083 0.026796147227287292
65 11083 0.03579728305339813
66 11083 0.0744781494140625
67 11083 0.15188218653202057
68 11083 0.15418489277362823
69 11083 0.12459243834018707
70 11083 0.0730292946100235
71 11083 0.04939735308289528
72 11083 0.03533472120761871
73 11083 0.08068463206291199
74 11083 0.03980930522084236
75 11083 0.031381960958242416
76 11083 0.0322750024497509
77 11083 0.025940200313925743
78 11083 0.03702636435627937
79 11083 0.1424209624528885
80 11083 0.026962094008922577
81 11083 0.04159284755587578
82 11083 0.02756735123693943
83 11083 0.051241498440504074
84 11083 0.0536675862967968
85 11083 0.2195654660463333
86 11083 0.022746028378605843
87 11083 0.02132818102836609
88 11083 0.035141825675964355
89 11083 0.038157474249601364
90 11083 0.06941460072994232
91 11083 0.04238428547978401
92 11083 0.17619450390338898
93 11083 0.01427672803401947
94 11083 0.03396323695778847
95 11083 0.0
96 11083 0.07560162246227264
97 11083 0.0935049057006836
98 11083 0.02168513461947441
99 11083 0.020178144797682762
100 11083 0.009030818939208984
101 11083 0.019440004602074623
102 11083 0.06739016622304916
103 11083 0.03802108019590378
104 11083 0.05152187868952751
105 11083 0.07345003634691238
106 11083 0.018468763679265976
107 11083 0.052913155406713486
108 11083 0.06833755970001221
109 11083 0.05931982398033142
110 11083 0.04855184257030487
train - Global loss: 0.051714    Embedding norm: 1.0000   Triplets (all/active): 99.8/826.6
Pos dist (min/mean/max): 0.4214/0.7420/1.0132   Neg dist (min/mean/max): 1.1338/1.4112/1.6377
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1480/0.3079/0.5353   Neg dist (min/mean/max): 1.1565/1.4018/1.5964
0 11083 0.03998503461480141
1 11083 0.03284178674221039
2 11083 0.032359883189201355
3 11083 0.042096275836229324
4 11083 0.06542304903268814
5 11083 0.03387298062443733
6 11083 0.019946446642279625
7 11083 0.010191261768341064
8 11083 0.024533284828066826
9 11083 0.0
10 11083 0.013057522475719452
11 11083 0.034696292132139206
12 11083 0.07825818657875061
13 11083 0.0375053733587265
14 11083 0.05675709247589111
15 11083 0.11033240705728531
16 11083 0.016864461824297905
17 11083 0.010308410041034222
18 11083 0.03585165739059448
19 11083 0.028651762753725052
20 11083 0.0
21 11083 0.021406186744570732
22 11083 0.04525449126958847
23 11083 0.05480324849486351
24 11083 0.03098302334547043
25 11083 0.01287513505667448
26 11083 0.030368583276867867
27 11083 0.03220520541071892
28 11083 0.015373020432889462
29 11083 0.03555375337600708
30 11083 0.039728064090013504
31 11083 0.07953441143035889
32 11083 0.0
33 11083 0.03906947746872902
34 11083 0.0007911622524261475
35 11083 0.012435516342520714
36 11083 0.03390875086188316
37 11083 0.0
38 11083 0.03227674588561058
39 11083 0.047942936420440674
40 11083 0.02330942079424858
41 11083 0.01364379283040762
42 11083 0.025158697739243507
43 11083 0.040939461439847946
44 11083 0.02401704527437687
45 11083 0.016761718317866325
46 11083 0.04296618700027466
47 11083 0.03289391100406647
48 11083 0.04727407172322273
49 11083 0.021852772682905197
50 11083 0.033486686646938324
51 11083 0.027460498735308647
52 11083 0.01136845350265503
53 11083 0.022392529994249344
54 11083 0.050762325525283813
55 11083 0.03449174016714096
56 11083 0.03440473601222038
57 11083 0.05677170306444168
58 11083 0.15930527448654175
59 11083 0.23275013267993927
60 11083 0.23349298536777496
61 11083 0.09429199248552322
62 11083 0.02933652140200138
63 11083 0.08171921968460083
64 11083 0.06971817463636398
65 11083 0.03693235665559769
66 11083 0.08635494858026505
67 11083 0.17345421016216278
68 11083 0.14955566823482513
69 11083 0.1085529699921608
70 11083 0.08705612272024155
71 11083 0.05292339622974396
72 11083 0.04430486634373665
73 11083 0.07940597832202911
74 11083 0.04348231479525566
75 11083 0.021001921966671944
76 11083 0.020656859502196312
77 11083 0.031058544293045998
78 11083 0.03310638293623924
79 11083 0.14268045127391815
80 11083 0.02610834874212742
81 11083 0.0
82 11083 0.0276323314756155
83 11083 0.02592185139656067
84 11083 0.06423399597406387
85 11083 0.25249767303466797
86 11083 0.02014162391424179
87 11083 0.011616580188274384
88 11083 0.016856558620929718
89 11083 0.02829013764858246
90 11083 0.05632452666759491
91 11083 0.04898751899600029
92 11083 0.1752750426530838
93 11083 0.01344987004995346
94 11083 0.022094981744885445
95 11083 0.01631063036620617
96 11083 0.03169291466474533
97 11083 0.08918088674545288
98 11083 0.035092975944280624
99 11083 0.04049225151538849
100 11083 0.0
101 11083 0.040033236145973206
102 11083 0.05222636088728905
103 11083 0.03135894611477852
104 11083 0.04776687175035477
105 11083 0.04964218661189079
106 11083 0.024227693676948547
107 11083 0.041597213596105576
108 11083 0.0691734254360199
109 11083 0.05011485889554024
110 11083 0.028631199151277542
train - Global loss: 0.047713    Embedding norm: 1.0000   Triplets (all/active): 99.8/717.5
Pos dist (min/mean/max): 0.4223/0.7336/0.9949   Neg dist (min/mean/max): 1.1337/1.4118/1.6317
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1559/0.3105/0.5274   Neg dist (min/mean/max): 1.1793/1.4122/1.6280
0 11083 0.03688172250986099
1 11083 0.013384496793150902
2 11083 0.02540697529911995
3 11083 0.024329977110028267
4 11083 0.045997537672519684
5 11083 0.0
6 11083 0.03271663188934326
7 11083 0.03961661830544472
8 11083 0.020683977752923965
9 11083 0.008565694093704224
10 11083 0.03357594087719917
11 11083 0.033929493278265
12 11083 0.029544053599238396
13 11083 0.024789854884147644
14 11083 0.00141075998544693
15 11083 0.0349193811416626
16 11083 0.03928842768073082
17 11083 0.0
18 11083 0.019920138642191887
19 11083 0.04181763157248497
20 11083 0.0
21 11083 0.019990570843219757
22 11083 0.028634022921323776
23 11083 0.03815812990069389
24 11083 0.03639023378491402
25 11083 0.030372604727745056
26 11083 0.03783321753144264
27 11083 0.0
28 11083 0.033057622611522675
29 11083 0.0
30 11083 0.03381718322634697
31 11083 0.045080892741680145
32 11083 0.007260948419570923
33 11083 0.0939365103840828
34 11083 0.0483936071395874
35 11083 0.0387168750166893
36 11083 0.0
37 11083 0.0
38 11083 0.0312940888106823
39 11083 0.029460424557328224
40 11083 0.004516391549259424
41 11083 0.0
42 11083 0.02337387204170227
43 11083 0.0347018837928772
44 11083 0.04374495893716812
45 11083 0.05007912591099739
46 11083 0.04818973317742348
47 11083 0.0032332539558410645
48 11083 0.030340656638145447
49 11083 0.015530288219451904
50 11083 0.0
51 11083 0.0
52 11083 0.026279248297214508
53 11083 0.0
54 11083 0.029403431341052055
55 11083 0.020775336772203445
56 11083 0.028128018602728844
57 11083 0.060751017183065414
58 11083 0.13023070991039276
59 11083 0.24132035672664642
60 11083 0.20466378331184387
61 11083 0.0612986721098423
62 11083 0.03360137715935707
63 11083 0.08864867687225342
64 11083 0.03392942622303963
65 11083 0.019889438524842262
66 11083 0.07705295830965042
67 11083 0.15443763136863708
68 11083 0.10830437391996384
69 11083 0.1258990317583084
70 11083 0.0720515325665474
71 11083 0.03818861022591591
72 11083 0.021528322249650955
73 11083 0.06151953339576721
74 11083 0.04959845170378685
75 11083 0.09885042905807495
76 11083 0.027281180024147034
77 11083 0.01289060153067112
78 11083 0.06254994124174118
79 11083 0.13645817339420319
80 11083 0.022906264290213585
81 11083 0.014406105503439903
82 11083 0.030225969851017
83 11083 0.009165167808532715
84 11083 0.05008333921432495
85 11083 0.20376725494861603
86 11083 0.0
87 11083 0.025554312393069267
88 11083 0.0065522147342562675
89 11083 0.0
90 11083 0.041335511952638626
91 11083 0.044266775250434875
92 11083 0.15171261131763458
93 11083 0.0
94 11083 0.02503357268869877
95 11083 0.025680117309093475
96 11083 0.04281572997570038
97 11083 0.056995272636413574
98 11083 0.0
99 11083 0.035199716687202454
100 11083 0.0
101 11083 0.013179677538573742
102 11083 0.053470179438591
103 11083 0.020092181861400604
104 11083 0.056549038738012314
105 11083 0.06143863871693611
106 11083 0.02194235473871231
107 11083 0.011321130208671093
108 11083 0.03334745764732361
109 11083 0.034297142177820206
110 11083 0.028347574174404144
train - Global loss: 0.040163    Embedding norm: 1.0000   Triplets (all/active): 99.8/608.5
Pos dist (min/mean/max): 0.4197/0.7272/0.9798   Neg dist (min/mean/max): 1.1467/1.4121/1.6332
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.028477728366851807
4 445 0.0
val - Global loss: 0.005696    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.2
Pos dist (min/mean/max): 0.1519/0.3067/0.5387   Neg dist (min/mean/max): 1.1566/1.4055/1.6033
0 11083 0.03270541876554489
1 11083 0.013548575341701508
2 11083 0.009093135595321655
3 11083 0.026699230074882507
4 11083 0.06681840866804123
5 11083 0.01705164462327957
6 11083 0.0341031588613987
7 11083 0.012465797364711761
8 11083 0.01624717377126217
9 11083 0.0006192922592163086
10 11083 0.016888834536075592
11 11083 0.03029206022620201
12 11083 0.02997235767543316
13 11083 0.02290262095630169
14 11083 0.0
15 11083 0.014081954956054688
16 11083 0.0
17 11083 0.003946809098124504
18 11083 0.0
19 11083 0.0016439955215901136
20 11083 0.0293390154838562
21 11083 0.0
22 11083 0.019532829523086548
23 11083 0.013534367084503174
24 11083 0.013603190891444683
25 11083 0.048286546021699905
26 11083 0.03437797725200653
27 11083 0.0
28 11083 0.0031129794660955667
29 11083 0.05614054575562477
30 11083 0.028681444004178047
31 11083 0.008260001428425312
32 11083 0.02918989583849907
33 11083 0.05675475671887398
34 11083 0.0
35 11083 0.04602743685245514
36 11083 0.008121490478515625
37 11083 0.0
38 11083 0.04748038947582245
39 11083 0.02329833246767521
40 11083 0.025679737329483032
41 11083 0.0282561257481575
42 11083 0.0
43 11083 0.02029479295015335
44 11083 0.03835141658782959
45 11083 0.019991803914308548
46 11083 0.03254788741469383
47 11083 0.006504416465759277
48 11083 0.034078795462846756
49 11083 0.02691114880144596
50 11083 0.012821654789149761
51 11083 0.0
52 11083 0.034436922520399094
53 11083 0.022399645298719406
54 11083 0.021489068865776062
55 11083 0.04568791389465332
56 11083 0.0286196731030941
57 11083 0.04384268820285797
58 11083 0.15089833736419678
59 11083 0.22339163720607758
60 11083 0.22383074462413788
61 11083 0.07975056022405624
62 11083 0.05276510491967201
63 11083 0.060642097145318985
64 11083 0.022705944254994392
65 11083 0.026381665840744972
66 11083 0.08541245013475418
67 11083 0.12887321412563324
68 11083 0.1169336587190628
69 11083 0.11062425374984741
70 11083 0.06298073381185532
71 11083 0.03172256425023079
72 11083 0.029411200433969498
73 11083 0.06650779396295547
74 11083 0.0235297791659832
75 11083 0.017229042947292328
76 11083 0.0
77 11083 0.0
78 11083 0.029345577582716942
79 11083 0.1548335701227188
80 11083 0.00958263874053955
81 11083 0.022585498169064522
82 11083 0.044779226183891296
83 11083 0.0
84 11083 0.061786387115716934
85 11083 0.16714639961719513
86 11083 0.0
87 11083 0.0
88 11083 0.016014769673347473
89 11083 0.03125808760523796
90 11083 0.02255186252295971
91 11083 0.03759979456663132
92 11083 0.15618304908275604
93 11083 0.010531723499298096
94 11083 0.0
95 11083 0.0
96 11083 0.025183025747537613
97 11083 0.04730105772614479
98 11083 0.024283014237880707
99 11083 0.01937933824956417
100 11083 0.0
101 11083 0.0
102 11083 0.04411333426833153
103 11083 0.016748111695051193
104 11083 0.03137004375457764
105 11083 0.029049959033727646
106 11083 0.010917342267930508
107 11083 0.03485288470983505
108 11083 0.02618858963251114
109 11083 0.02189737744629383
110 11083 0.032736729830503464
train - Global loss: 0.035122    Embedding norm: 1.0000   Triplets (all/active): 99.8/531.4
Pos dist (min/mean/max): 0.4185/0.7209/0.9619   Neg dist (min/mean/max): 1.1514/1.4116/1.6300
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1547/0.3079/0.5278   Neg dist (min/mean/max): 1.1954/1.4137/1.5898
0 11083 0.02962547168135643
1 11083 0.01708192005753517
2 11083 0.05006043240427971
3 11083 0.025078024715185165
4 11083 0.03446295112371445
5 11083 0.025057952851057053
6 11083 0.0
7 11083 0.0
8 11083 0.006145000457763672
9 11083 0.013615867123007774
10 11083 0.0
11 11083 0.0
12 11083 0.03309130296111107
13 11083 0.011578939855098724
14 11083 0.01937071792781353
15 11083 0.017539769411087036
16 11083 0.004499912261962891
17 11083 0.00842982530593872
18 11083 0.02477903477847576
19 11083 0.04155769571661949
20 11083 0.0
21 11083 0.0
22 11083 0.0
23 11083 0.002541184425354004
24 11083 0.0
25 11083 0.02135986089706421
26 11083 0.0
27 11083 0.007601991295814514
28 11083 0.0
29 11083 0.0
30 11083 0.01771986298263073
31 11083 0.02466009370982647
32 11083 0.011415868997573853
33 11083 0.02488861232995987
34 11083 0.005607306957244873
35 11083 0.006122708320617676
36 11083 0.0
37 11083 0.0
38 11083 0.03207254409790039
39 11083 0.01547951903194189
40 11083 0.0
41 11083 0.0
42 11083 0.04206692427396774
43 11083 0.027078894898295403
44 11083 0.01316346786916256
45 11083 0.0
46 11083 0.03232472389936447
47 11083 0.0
48 11083 0.0
49 11083 0.0
50 11083 0.0
51 11083 0.0
52 11083 0.0
53 11083 0.0
54 11083 0.017865240573883057
55 11083 0.02379027009010315
56 11083 0.036456551402807236
57 11083 0.04884154349565506
58 11083 0.14855767786502838
59 11083 0.2233700156211853
60 11083 0.18949323892593384
61 11083 0.06924093514680862
62 11083 0.05747031420469284
63 11083 0.06533514708280563
64 11083 0.02781059965491295
65 11083 0.012335291132330894
66 11083 0.07253938168287277
67 11083 0.12585526704788208
68 11083 0.11661094427108765
69 11083 0.0973617285490036
70 11083 0.05857536569237709
71 11083 0.019460275769233704
72 11083 0.0
73 11083 0.046139538288116455
74 11083 0.021121874451637268
75 11083 0.004993021488189697
76 11083 0.0
77 11083 0.0040618181228637695
78 11083 0.03687423840165138
79 11083 0.1314646154642105
80 11083 0.011980831623077393
81 11083 0.0
82 11083 0.0
83 11083 0.022615864872932434
84 11083 0.03661280870437622
85 11083 0.18193572759628296
86 11083 0.0
87 11083 0.0
88 11083 0.006391763687133789
89 11083 0.0
90 11083 0.04168979451060295
91 11083 0.038937605917453766
92 11083 0.09801929444074631
93 11083 0.0
94 11083 0.011885414831340313
95 11083 0.006673038005828857
96 11083 0.03233964741230011
97 11083 0.05458256974816322
98 11083 0.0
99 11083 0.0
100 11083 0.0
101 11083 0.0
102 11083 0.013807318173348904
103 11083 0.0
104 11083 0.027423720806837082
105 11083 0.024779364466667175
106 11083 0.01978614553809166
107 11083 0.014530271291732788
108 11083 0.0
109 11083 0.01693626120686531
110 11083 0.01857895962893963
train - Global loss: 0.026858    Embedding norm: 1.0000   Triplets (all/active): 99.8/462.2
Pos dist (min/mean/max): 0.4146/0.7134/0.9443   Neg dist (min/mean/max): 1.1551/1.4121/1.6308
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1534/0.3059/0.5311   Neg dist (min/mean/max): 1.1595/1.4121/1.5876
0 11083 0.0
1 11083 0.013179263100028038
2 11083 0.007901281118392944
3 11083 0.005598694086074829
4 11083 0.030652225017547607
5 11083 0.0
6 11083 0.0
7 11083 0.00170820951461792
8 11083 0.005692154169082642
9 11083 0.0
10 11083 0.016861796379089355
11 11083 0.007117897272109985
12 11083 0.0
13 11083 0.0033267687540501356
14 11083 0.0
15 11083 0.0
16 11083 0.04059012234210968
17 11083 0.0
18 11083 0.0
19 11083 0.0014669299125671387
20 11083 0.0
21 11083 0.011759564280509949
22 11083 0.012225210666656494
23 11083 0.024087175726890564
24 11083 0.02214444987475872
25 11083 0.0
26 11083 0.006630063056945801
27 11083 0.0
28 11083 0.0
29 11083 0.0
30 11083 0.008245229721069336
31 11083 0.04009835794568062
32 11083 0.003860563039779663
33 11083 0.0
34 11083 0.015419885516166687
35 11083 0.011046849191188812
36 11083 0.0
37 11083 0.0
38 11083 0.0
39 11083 0.015399575233459473
40 11083 0.060514260083436966
41 11083 0.00839322805404663
42 11083 0.0
43 11083 0.020156750455498695
44 11083 0.016924738883972168
45 11083 0.0
46 11083 0.03615403175354004
47 11083 0.005308374762535095
48 11083 0.01744789630174637
49 11083 0.005582213401794434
50 11083 0.04366189241409302
51 11083 0.0
52 11083 0.0
53 11083 0.026385128498077393
54 11083 0.0
55 11083 0.0014975965023040771
56 11083 0.028814097866415977
57 11083 0.03115573339164257
58 11083 0.12559212744235992
59 11083 0.1832008808851242
60 11083 0.19766785204410553
61 11083 0.05111221224069595
62 11083 0.02428358793258667
63 11083 0.06700332462787628
64 11083 0.0027887055184692144
65 11083 0.0007858872413635254
66 11083 0.03917333111166954
67 11083 0.12843087315559387
68 11083 0.10579119622707367
69 11083 0.09411987662315369
70 11083 0.06740245223045349
71 11083 0.025979163125157356
72 11083 0.0
73 11083 0.05036488547921181
74 11083 0.05821724608540535
75 11083 0.021123018115758896
76 11083 0.0
77 11083 0.0
78 11083 0.03061605431139469
79 11083 0.11959356814622879
80 11083 0.0
81 11083 0.0
82 11083 0.0020222081802785397
83 11083 0.0
84 11083 0.04270445182919502
85 11083 0.20293503999710083
86 11083 0.0045261383056640625
87 11083 0.0
88 11083 0.007439032196998596
89 11083 0.013605467975139618
90 11083 0.01894519105553627
91 11083 0.030781425535678864
92 11083 0.10419881343841553
93 11083 0.030379176139831543
94 11083 0.0
95 11083 0.020536184310913086
96 11083 0.024808570742607117
97 11083 0.03408012539148331
98 11083 0.0
99 11083 0.0016589760780334473
100 11083 0.0033517777919769287
101 11083 0.021757502108812332
102 11083 0.02777940034866333
103 11083 0.006668067071586847
104 11083 0.028790172189474106
105 11083 0.02631763555109501
106 11083 0.0
107 11083 0.012727162800729275
108 11083 0.0272616408765316
109 11083 0.014216816052794456
110 11083 0.024352168664336205
train - Global loss: 0.024613    Embedding norm: 1.0000   Triplets (all/active): 99.8/430.0
Pos dist (min/mean/max): 0.4171/0.7103/0.9379   Neg dist (min/mean/max): 1.1546/1.4115/1.6269
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1566/0.3053/0.5315   Neg dist (min/mean/max): 1.1970/1.4097/1.6009
0 11083 0.03174930438399315
1 11083 0.0144575834274292
2 11083 0.0
3 11083 0.007148191332817078
4 11083 0.010470117442309856
5 11083 0.0
6 11083 0.0
7 11083 0.0
8 11083 0.0
9 11083 0.0
10 11083 0.0
11 11083 0.0
12 11083 0.006893515586853027
13 11083 0.0
14 11083 0.0
15 11083 0.021973514929413795
16 11083 0.0
17 11083 0.02116529643535614
18 11083 0.0
19 11083 0.0
20 11083 0.0
21 11083 0.0
22 11083 0.03520985692739487
23 11083 0.021721120923757553
24 11083 0.0
25 11083 0.0
26 11083 0.033192768692970276
27 11083 0.0
28 11083 0.0035296082496643066
29 11083 0.02218903973698616
30 11083 0.007705569267272949
31 11083 0.0
32 11083 0.0
33 11083 0.0
34 11083 0.0
35 11083 0.0
36 11083 0.005810171365737915
37 11083 0.021785438060760498
38 11083 0.006575733423233032
39 11083 0.09420852363109589
40 11083 0.02780710719525814
41 11083 0.0
42 11083 0.0263386070728302
43 11083 0.03431396931409836
44 11083 0.001960054039955139
45 11083 0.0
46 11083 0.04355887323617935
47 11083 0.0
48 11083 0.006854236125946045
49 11083 0.0
50 11083 0.0
51 11083 0.0
52 11083 0.0
53 11083 0.0
54 11083 0.0
55 11083 0.011087874881923199
56 11083 0.008506751619279385
57 11083 0.02072904445230961
58 11083 0.1266135722398758
59 11083 0.20105572044849396
60 11083 0.19510921835899353
61 11083 0.029236987233161926
62 11083 0.1119886040687561
63 11083 0.05386529117822647
64 11083 0.018358934670686722
65 11083 0.0
66 11083 0.05216722935438156
67 11083 0.11820600181818008
68 11083 0.10097087919712067
69 11083 0.10114165395498276
70 11083 0.06071177497506142
71 11083 0.008083606138825417
72 11083 0.02285522222518921
73 11083 0.026980582624673843
74 11083 0.02476799488067627
75 11083 0.0
76 11083 0.0
77 11083 0.0
78 11083 0.0
79 11083 0.11107742786407471
80 11083 0.006130516529083252
81 11083 0.0013858675956726074
82 11083 0.0
83 11083 0.0
84 11083 0.020334389060735703
85 11083 0.1908808946609497
86 11083 0.017289549112319946
87 11083 0.007953113876283169
88 11083 0.021110912784934044
89 11083 0.0
90 11083 0.019797133281826973
91 11083 0.026303010061383247
92 11083 0.0997847244143486
93 11083 0.0
94 11083 0.0
95 11083 0.01485493779182434
96 11083 0.025739436969161034
97 11083 0.020996907725930214
98 11083 0.0
99 11083 0.0
100 11083 0.020255645737051964
101 11083 0.02049165405333042
102 11083 0.019849078729748726
103 11083 0.0
104 11083 0.02729276567697525
105 11083 0.028409095481038094
106 11083 0.0
107 11083 0.012391646392643452
108 11083 0.01859195902943611
109 11083 0.023741941899061203
110 11083 0.017970144748687744
train - Global loss: 0.023168    Embedding norm: 1.0000   Triplets (all/active): 99.8/386.8
Pos dist (min/mean/max): 0.4158/0.7091/0.9350   Neg dist (min/mean/max): 1.1600/1.4123/1.6217
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1562/0.3064/0.5353   Neg dist (min/mean/max): 1.1829/1.4100/1.6076
0 11083 0.0
1 11083 0.023904068395495415
2 11083 0.0
3 11083 0.0027356743812561035
4 11083 0.026744352653622627
5 11083 0.0
6 11083 0.0
7 11083 0.0
8 11083 0.0
9 11083 0.0
10 11083 0.0
11 11083 0.0
12 11083 0.04841998592019081
13 11083 0.0
14 11083 0.0
15 11083 0.0
16 11083 0.0
17 11083 0.0
18 11083 0.0
19 11083 0.0
20 11083 0.0
21 11083 0.0
22 11083 0.0
23 11083 0.010220468044281006
24 11083 0.0
25 11083 0.0
26 11083 0.002027571201324463
27 11083 0.0
28 11083 0.0
29 11083 0.01344401203095913
30 11083 0.02464785985648632
31 11083 0.018847286701202393
32 11083 0.0043891072273254395
33 11083 0.007298946380615234
34 11083 0.0
35 11083 0.010810951702296734
36 11083 0.0
37 11083 0.0
38 11083 0.0
39 11083 0.01686181128025055
40 11083 0.007710852660238743
41 11083 0.0
42 11083 0.0
43 11083 0.014206469058990479
44 11083 0.013035220094025135
45 11083 0.0
46 11083 0.008155626244843006
47 11083 0.0
48 11083 0.0
49 11083 0.0
50 11083 0.029218971729278564
51 11083 0.0
52 11083 0.0
53 11083 0.006536707282066345
54 11083 0.0
55 11083 0.0
56 11083 0.03108755685389042
57 11083 0.040481410920619965
58 11083 0.12269952148199081
59 11083 0.1884015053510666
60 11083 0.1653614342212677
61 11083 0.04593423008918762
62 11083 0.020594852045178413
63 11083 0.049558475613594055
64 11083 0.019854076206684113
65 11083 0.011651402339339256
66 11083 0.07854411005973816
67 11083 0.11576805263757706
68 11083 0.11484222114086151
69 11083 0.08275201171636581
70 11083 0.04614574462175369
71 11083 0.011856019496917725
72 11083 0.0
73 11083 0.04814876988530159
74 11083 0.023244287818670273
75 11083 0.022853657603263855
76 11083 0.0
77 11083 0.0
78 11083 0.0
79 11083 0.11532929539680481
80 11083 0.0
81 11083 0.0
82 11083 0.0
83 11083 0.0
84 11083 0.030775880441069603
85 11083 0.14655429124832153
86 11083 0.0
87 11083 0.0
88 11083 0.0
89 11083 0.0
90 11083 0.004950582981109619
91 11083 0.029093777760863304
92 11083 0.0933365523815155
93 11083 0.0
94 11083 0.0
95 11083 0.014201179146766663
96 11083 0.030058888718485832
97 11083 0.03998052328824997
98 11083 0.006862111389636993
99 11083 0.02311420440673828
100 11083 0.0
101 11083 0.026360422372817993
102 11083 0.06885742396116257
103 11083 0.017057769000530243
104 11083 0.020942164584994316
105 11083 0.01734979636967182
106 11083 0.0
107 11083 0.0
108 11083 0.02061806246638298
109 11083 0.023738322779536247
110 11083 0.008891543373465538
train - Global loss: 0.020424    Embedding norm: 1.0000   Triplets (all/active): 99.8/371.0
Pos dist (min/mean/max): 0.4154/0.7070/0.9267   Neg dist (min/mean/max): 1.1679/1.4116/1.6243
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1561/0.3055/0.5341   Neg dist (min/mean/max): 1.2189/1.4118/1.5982
Training completed.
  0%|                                                   | 0/24 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 502, in do_train
    global_stats = evaluator_test_set.evaluate(model)
  File "/code/RLoc/eval/evaluate.py", line 1469, in evaluate
    query_embeddings, map_embeddings, query_positions, map_positions = self.compute_embeddings(model)
  File "/code/RLoc/eval/evaluate.py", line 1498, in compute_embeddings
    for query, maps, query_pos, map_pos in tqdm.tqdm(self.test_loader):
ValueError: not enough values to unpack (expected 4, got 2)
