  0%|                                                                   | 0/80 [00:00<?, ?it/s]
0 25113 0.31605932116508484
1 25113 0.3189687132835388
2 25113 0.303364634513855
3 25113 0.2962007224559784
4 25113 0.28302404284477234
5 25113 0.3016001880168915
6 25113 0.2980734407901764
7 25113 0.2822790741920471
8 25113 0.2858782410621643
9 25113 0.2912052869796753
10 25113 0.2768446207046509
11 25113 0.26088759303092957
12 25113 0.18177101016044617
13 25113 0.32861170172691345
14 25113 0.3087176978588104
15 25113 0.303524374961853
16 25113 0.22989732027053833
17 25113 0.18800349533557892
18 25113 0.4555733799934387
19 25113 0.3212830126285553
20 25113 0.3657715320587158
21 25113 0.35378625988960266
22 25113 0.33238935470581055
23 25113 0.3274683356285095
24 25113 0.29081010818481445
25 25113 0.2933591604232788
26 25113 0.27150869369506836
27 25113 0.2795405387878418
28 25113 0.276580274105072
29 25113 0.2968500256538391
30 25113 0.3071124255657196
31 25113 0.30480197072029114
32 25113 0.2944825291633606
33 25113 0.28801071643829346
34 25113 0.2870391607284546
35 25113 0.3018576502799988
36 25113 0.2858666777610779
37 25113 0.28567373752593994
38 25113 0.28205573558807373
39 25113 0.24691563844680786
40 25113 0.22519567608833313
41 25113 0.2508307695388794
42 25113 0.2735748291015625
43 25113 0.2368801236152649
44 25113 0.23959876596927643
45 25113 0.211979940533638
46 25113 0.21018967032432556
47 25113 0.19458048045635223
48 25113 0.19632844626903534
49 25113 0.1783803254365921
50 25113 0.15977253019809723
51 25113 0.27019837498664856
52 25113 0.4457678198814392
53 25113 0.3772326409816742
54 25113 0.30986517667770386
55 25113 0.29453539848327637
56 25113 0.396767258644104
57 25113 0.3293798565864563
58 25113 0.346871554851532
59 25113 0.31370478868484497
60 25113 0.2928876280784607
61 25113 0.28322988748550415
62 25113 0.2877764105796814
63 25113 0.3377537429332733
64 25113 0.3254837989807129
65 25113 0.2918080687522888
66 25113 0.2804793417453766
67 25113 0.2996247410774231
68 25113 0.3165859878063202
69 25113 0.3108973801136017
70 25113 0.3235524296760559
71 25113 0.28332099318504333
72 25113 0.2792964577674866
73 25113 0.2992420792579651
74 25113 0.3106550872325897
75 25113 0.28338301181793213
76 25113 0.27369850873947144
77 25113 0.27696162462234497
78 25113 0.29349052906036377
79 25113 0.29508814215660095
80 25113 0.31416773796081543
81 25113 0.29442930221557617
82 25113 0.28318703174591064
83 25113 0.30351722240448
84 25113 0.27416273951530457
85 25113 0.2830773591995239
86 25113 0.29049861431121826
87 25113 0.28929221630096436
88 25113 0.2996269464492798
89 25113 0.27965694665908813
90 25113 0.2615398168563843
91 25113 0.22110554575920105
92 25113 0.24476344883441925
93 25113 0.3183861970901489
94 25113 0.24280354380607605
95 25113 0.28283020853996277
96 25113 0.266516774892807
97 25113 0.20769812166690826
98 25113 0.14402706921100616
99 25113 0.0970754623413086
100 25113 0.152374729514122
101 25113 0.14603498578071594
102 25113 0.07890354841947556
103 25113 0.023091336712241173
104 25113 0.2908385992050171
105 25113 0.22904632985591888
106 25113 0.24520480632781982
107 25113 0.22625815868377686
108 25113 0.279262900352478
109 25113 0.2369961142539978
110 25113 0.17666617035865784
111 25113 0.300245463848114
112 25113 0.262996643781662
113 25113 0.3254045248031616
114 25113 0.38908302783966064
115 25113 0.2859603464603424
116 25113 0.34131112694740295
117 25113 0.22215379774570465
118 25113 0.19152601063251495
119 25113 0.2534000277519226
120 25113 0.30404821038246155
121 25113 0.2756604254245758
122 25113 0.23637554049491882
123 25113 0.2492738962173462
124 25113 0.16453714668750763
125 25113 0.19668522477149963
126 25113 0.14501173794269562
127 25113 0.2525246739387512
128 25113 0.3862214684486389
129 25113 0.22081312537193298
130 25113 0.2393748015165329
131 25113 0.1932307481765747
132 25113 0.11700266599655151
133 25113 0.22214031219482422
134 25113 0.23510798811912537
135 25113 0.20298482477664948
136 25113 0.13685230910778046
137 25113 0.1996171772480011
138 25113 0.17131386697292328
139 25113 0.3082072138786316
140 25113 0.16026850044727325
141 25113 0.2267778217792511
142 25113 0.29519122838974
143 25113 0.2135438323020935
144 25113 0.2893138825893402
145 25113 0.19762194156646729
146 25113 0.22117561101913452
147 25113 0.22696729004383087
148 25113 0.1963808536529541
149 25113 0.15224148333072662
150 25113 0.1273302286863327
151 25113 0.2693449854850769
152 25113 0.17782020568847656
153 25113 0.19665943086147308
154 25113 0.25411880016326904
155 25113 0.18935774266719818
156 25113 0.32670044898986816
157 25113 0.3031933009624481
158 25113 0.34995004534721375
159 25113 0.28071287274360657
160 25113 0.27389225363731384
161 25113 0.2608986496925354
162 25113 0.2014259696006775
163 25113 0.18451495468616486
164 25113 0.29595041275024414
165 25113 0.32203686237335205
166 25113 0.2631075382232666
167 25113 0.3754231929779053
168 25113 0.12341269850730896
169 25113 0.13142675161361694
170 25113 0.09910266846418381
171 25113 0.4587906301021576
172 25113 0.32121825218200684
173 25113 0.2609037458896637
174 25113 0.4699859321117401
175 25113 0.3083261251449585
176 25113 0.3030339479446411
177 25113 0.3287186622619629
178 25113 0.25912773609161377
179 25113 0.30570411682128906
180 25113 0.22900182008743286
181 25113 0.21049228310585022
182 25113 0.26258739829063416
183 25113 0.30305540561676025
184 25113 0.20183372497558594
185 25113 0.17239540815353394
186 25113 0.1340419054031372
187 25113 0.23751835525035858
188 25113 0.2395578771829605
189 25113 0.2107268124818802
190 25113 0.23887281119823456
191 25113 0.18109294772148132
192 25113 0.29793334007263184
193 25113 0.27129271626472473
194 25113 0.3624856173992157
195 25113 0.25131797790527344
196 25113 0.1747758984565735
train - Global loss: 0.262453    Embedding norm: 1.0000   Triplets (all/active): 127.5/15386.4
Pos dist (min/mean/max): 0.2518/0.3974/0.6050   Neg dist (min/mean/max): 0.3083/0.6093/0.9305
0 1011 0.3062780499458313
1 1011 0.2617880403995514
2 1011 0.24389459192752838
3 1011 0.278097540140152
4 1011 0.43169841170310974
5 1011 0.2536497712135315
6 1011 0.33096203207969666
7 1011 0.7436313629150391
val - Global loss: 0.356250    Embedding norm: 1.0000   Triplets (all/active): 126.4/15264.5
Pos dist (min/mean/max): 0.2414/0.5956/0.9608   Neg dist (min/mean/max): 0.3327/0.8314/1.3664
0 25113 0.12047352641820908
1 25113 0.2723183035850525
2 25113 0.1578148603439331
3 25113 0.19699569046497345
4 25113 0.12220238894224167
5 25113 0.26669108867645264
6 25113 0.241746723651886
7 25113 0.19821637868881226
8 25113 0.24323594570159912
9 25113 0.09428805857896805
10 25113 0.2679237127304077
11 25113 0.19319592416286469
12 25113 0.17538802325725555
13 25113 0.302718847990036
14 25113 0.12402572482824326
15 25113 0.06638485938310623
16 25113 0.029437679797410965
17 25113 0.24214302003383636
18 25113 0.46176737546920776
19 25113 0.29984617233276367
20 25113 0.22804789245128632
21 25113 0.20052145421504974
22 25113 0.1129143014550209
23 25113 0.33209213614463806
24 25113 0.08965443819761276
25 25113 0.40864720940589905
26 25113 0.24569982290267944
27 25113 0.21518567204475403
28 25113 0.3017958402633667
29 25113 0.32336658239364624
30 25113 0.4086313545703888
31 25113 0.33390817046165466
32 25113 0.018875446170568466
33 25113 0.2011869251728058
34 25113 0.0948229506611824
35 25113 0.10360404849052429
36 25113 0.020440682768821716
37 25113 0.0
38 25113 0.07129071652889252
39 25113 0.102693572640419
40 25113 0.05139089375734329
41 25113 0.0
42 25113 0.17343609035015106
43 25113 0.11986304074525833
44 25113 0.17814913392066956
45 25113 0.4196619987487793
46 25113 0.028485462069511414
47 25113 0.07662235200405121
48 25113 0.3756314218044281
49 25113 0.232744500041008
50 25113 0.31192541122436523
51 25113 0.16490009427070618
52 25113 0.13900229334831238
53 25113 0.5348496437072754
54 25113 0.02769601345062256
55 25113 0.10030961781740189
56 25113 0.6290368437767029
57 25113 0.30209770798683167
58 25113 0.23846659064292908
59 25113 0.1383899450302124
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.4295232892036438
64 25113 0.43834081292152405
65 25113 0.2984347343444824
66 25113 0.45569637417793274
67 25113 0.36149245500564575
68 25113 0.33377495408058167
69 25113 0.3941165506839752
70 25113 0.40615344047546387
71 25113 0.28096410632133484
72 25113 0.16702528297901154
73 25113 0.14606492221355438
74 25113 0.204786479473114
75 25113 0.2825828194618225
76 25113 0.17925262451171875
77 25113 0.23472824692726135
78 25113 0.1151769831776619
79 25113 0.037638213485479355
80 25113 0.02734796702861786
81 25113 0.0
82 25113 0.22645527124404907
83 25113 0.6367274522781372
84 25113 0.1813676357269287
85 25113 0.07718563079833984
86 25113 0.0
87 25113 0.22002854943275452
88 25113 0.2809658646583557
89 25113 0.351571649312973
90 25113 0.20782959461212158
91 25113 0.20505964756011963
92 25113 0.19414451718330383
93 25113 0.31306523084640503
94 25113 0.27137303352355957
95 25113 0.2728794813156128
96 25113 0.20488998293876648
97 25113 0.27553194761276245
98 25113 0.13913561403751373
99 25113 0.09553439170122147
100 25113 0.14736582338809967
101 25113 0.17383119463920593
102 25113 0.14853543043136597
103 25113 0.013836027123034
104 25113 0.3038424849510193
105 25113 0.10138450562953949
106 25113 0.13024133443832397
107 25113 0.09217604994773865
108 25113 0.047990135848522186
109 25113 0.18737643957138062
110 25113 0.15099981427192688
111 25113 0.30125120282173157
112 25113 0.03075467422604561
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.5151321291923523
117 25113 0.16566850244998932
118 25113 0.05405648797750473
119 25113 0.043289344757795334
120 25113 0.0
121 25113 0.3198755085468292
122 25113 0.027171852067112923
123 25113 0.2589386999607086
124 25113 0.4076441526412964
125 25113 0.21937675774097443
126 25113 0.15386343002319336
127 25113 0.3807653784751892
128 25113 0.3427281379699707
129 25113 0.08644983172416687
130 25113 0.12133987247943878
131 25113 0.0637480616569519
132 25113 0.0269403625279665
133 25113 0.0
134 25113 0.08089509606361389
135 25113 0.0
136 25113 0.0
137 25113 0.33106938004493713
138 25113 0.20475728809833527
139 25113 0.5684263110160828
140 25113 0.0
141 25113 0.042290110141038895
142 25113 0.004725217819213867
143 25113 0.012235435657203197
144 25113 0.02031884156167507
145 25113 0.0
146 25113 0.0
147 25113 0.13508549332618713
148 25113 0.009249508380889893
149 25113 0.0
150 25113 0.016790132969617844
151 25113 0.45537132024765015
152 25113 0.20126311480998993
153 25113 0.14954057335853577
154 25113 0.21916496753692627
155 25113 0.10362660139799118
156 25113 0.28169307112693787
157 25113 0.17320869863033295
158 25113 0.2348955273628235
159 25113 0.014799684286117554
160 25113 0.0
161 25113 0.0753508135676384
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.3394775092601776
166 25113 0.05600852146744728
167 25113 0.5102606415748596
168 25113 0.05595991387963295
169 25113 0.016890553757548332
170 25113 0.01318920124322176
171 25113 0.5758612751960754
172 25113 0.2426450252532959
173 25113 0.38789457082748413
174 25113 0.20049571990966797
175 25113 0.4485936164855957
176 25113 0.2796630561351776
177 25113 0.3213866055011749
178 25113 0.03108941949903965
179 25113 0.15878961980342865
180 25113 0.02338040992617607
181 25113 0.0
182 25113 0.0
183 25113 0.22975580394268036
184 25113 0.1286691129207611
185 25113 0.06272580474615097
186 25113 0.0
187 25113 0.3180946111679077
188 25113 0.08064344525337219
189 25113 0.07137838006019592
190 25113 0.12037725001573563
191 25113 0.08618876338005066
192 25113 0.25397276878356934
193 25113 0.07455973327159882
194 25113 0.2187546044588089
195 25113 0.039056021720170975
196 25113 0.06736954301595688
train - Global loss: 0.176874    Embedding norm: 1.0000   Triplets (all/active): 127.5/8965.2
Pos dist (min/mean/max): 0.2478/0.4526/0.7191   Neg dist (min/mean/max): 0.5410/0.9125/1.2852
0 1011 0.31215983629226685
1 1011 0.2294328361749649
2 1011 0.33337002992630005
3 1011 0.2688983082771301
4 1011 0.32724377512931824
5 1011 0.2921631336212158
6 1011 0.2845260500907898
7 1011 0.465838760137558
val - Global loss: 0.314204    Embedding norm: 1.0000   Triplets (all/active): 126.4/15975.4
Pos dist (min/mean/max): 0.1596/0.3236/0.5792   Neg dist (min/mean/max): 0.1474/0.5170/1.0259
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.024837590754032135
4 25113 0.0
5 25113 0.014891043305397034
6 25113 0.0
7 25113 0.1920005977153778
8 25113 0.4859396517276764
9 25113 0.0
10 25113 0.07848890870809555
11 25113 0.1298769861459732
12 25113 0.3061339259147644
13 25113 0.16462410986423492
14 25113 0.05900275707244873
15 25113 0.0
16 25113 0.08330784738063812
17 25113 0.05202388018369675
18 25113 0.4579508602619171
19 25113 0.16002003848552704
20 25113 0.16113270819187164
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.6062837243080139
26 25113 0.2283187210559845
27 25113 0.08785547316074371
28 25113 0.2698122262954712
29 25113 0.0391051284968853
30 25113 0.2959560751914978
31 25113 0.2846463620662689
32 25113 0.0
33 25113 0.07632435113191605
34 25113 0.015967369079589844
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.45953458547592163
43 25113 0.09788774698972702
44 25113 0.047322701662778854
45 25113 0.1785915344953537
46 25113 0.029929153621196747
47 25113 0.07333002984523773
48 25113 0.24873776733875275
49 25113 0.20851001143455505
50 25113 0.2664107084274292
51 25113 0.024846384301781654
52 25113 0.04828011244535446
53 25113 0.48967069387435913
54 25113 0.028533894568681717
55 25113 0.040107935667037964
56 25113 0.360276997089386
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.2700863480567932
64 25113 0.1300617903470993
65 25113 0.021952640265226364
66 25113 0.21058933436870575
67 25113 0.10223346203565598
68 25113 0.08995916694402695
69 25113 0.04115060344338417
70 25113 0.606881856918335
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.05332689359784126
76 25113 0.0
77 25113 0.01920222118496895
78 25113 0.024434201419353485
79 25113 0.003345191478729248
80 25113 0.0
81 25113 0.07774321734905243
82 25113 0.04779485985636711
83 25113 0.6937320828437805
84 25113 0.04112793877720833
85 25113 0.0
86 25113 0.03859682008624077
87 25113 0.4132748544216156
88 25113 0.5389129519462585
89 25113 0.47200292348861694
90 25113 0.2026737779378891
91 25113 0.23257319629192352
92 25113 0.24332621693611145
93 25113 0.27872663736343384
94 25113 0.25049397349357605
95 25113 0.2667161524295807
96 25113 0.1385185569524765
97 25113 0.15527372062206268
98 25113 0.10999461263418198
99 25113 0.07404851168394089
100 25113 0.16386651992797852
101 25113 0.05100994557142258
102 25113 0.06267549842596054
103 25113 0.0
104 25113 0.38363271951675415
105 25113 0.0055897533893585205
106 25113 0.044695641845464706
107 25113 0.0
108 25113 0.0
109 25113 0.06011778488755226
110 25113 0.02668331377208233
111 25113 0.3733687102794647
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.4630986452102661
117 25113 0.13798882067203522
118 25113 0.09309696406126022
119 25113 0.14345400035381317
120 25113 0.015114456415176392
121 25113 0.3020443022251129
122 25113 0.0
123 25113 0.36728864908218384
124 25113 0.3435973823070526
125 25113 0.08390837162733078
126 25113 0.030581939965486526
127 25113 0.0951126217842102
128 25113 0.11538175493478775
129 25113 0.023959379643201828
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.12296269834041595
138 25113 0.04242271929979324
139 25113 0.2624548375606537
140 25113 0.0
141 25113 0.027506491169333458
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.2728646695613861
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.3601103723049164
152 25113 0.173044353723526
153 25113 0.07069399207830429
154 25113 0.10394100844860077
155 25113 0.0
156 25113 0.1237168088555336
157 25113 0.0
158 25113 0.1595156192779541
159 25113 0.016486601904034615
160 25113 0.10246653854846954
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.14236761629581451
165 25113 0.037624601274728775
166 25113 0.007984340190887451
167 25113 0.09550905972719193
168 25113 0.10366049408912659
169 25113 0.0
170 25113 0.0
171 25113 0.7340630292892456
172 25113 0.017856255173683167
173 25113 0.1932966113090515
174 25113 0.0
175 25113 0.3550083637237549
176 25113 0.21722182631492615
177 25113 0.2067415565252304
178 25113 0.0
179 25113 0.049903206527233124
180 25113 0.09075968712568283
181 25113 0.0
182 25113 0.01620793342590332
183 25113 0.030295414850115776
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.10227776318788528
188 25113 0.056362126022577286
189 25113 0.010232388973236084
190 25113 0.7087180614471436
191 25113 0.0
192 25113 0.04437611997127533
193 25113 0.0
194 25113 0.18608225882053375
195 25113 0.02795439027249813
196 25113 0.18940559029579163
train - Global loss: 0.109511    Embedding norm: 1.0000   Triplets (all/active): 127.5/4569.9
Pos dist (min/mean/max): 0.2054/0.3944/0.6027   Neg dist (min/mean/max): 0.7190/1.0932/1.4849
0 1011 0.4480975270271301
1 1011 0.28744474053382874
2 1011 0.37336504459381104
3 1011 0.3170149624347687
4 1011 0.3409484624862671
5 1011 0.4611568748950958
6 1011 0.2781713902950287
7 1011 0.5751166939735413
val - Global loss: 0.385164    Embedding norm: 1.0000   Triplets (all/active): 126.4/15840.5
Pos dist (min/mean/max): 0.1274/0.3781/0.8179   Neg dist (min/mean/max): 0.1382/0.5660/1.3543
0 25113 0.0
1 25113 0.07309431582689285
2 25113 0.05407386273145676
3 25113 0.09083659201860428
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.1302904188632965
14 25113 0.033268339931964874
15 25113 0.0
16 25113 0.0
17 25113 0.1418580263853073
18 25113 0.5966609716415405
19 25113 0.06781116127967834
20 25113 0.0
21 25113 0.023311901837587357
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.5843186974525452
26 25113 0.13479937613010406
27 25113 0.05925081670284271
28 25113 0.2559314966201782
29 25113 0.0908016487956047
30 25113 0.17396211624145508
31 25113 0.05645584687590599
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.08302959054708481
43 25113 0.0
44 25113 0.0
45 25113 0.036272045224905014
46 25113 0.0
47 25113 0.07095062732696533
48 25113 0.12207244336605072
49 25113 0.10585634410381317
50 25113 0.06703035533428192
51 25113 0.0
52 25113 0.0
53 25113 0.8487285375595093
54 25113 0.0
55 25113 0.1825416535139084
56 25113 0.6916338205337524
57 25113 0.07071929425001144
58 25113 0.03769475594162941
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.3746928870677948
64 25113 0.07387552410364151
65 25113 0.0
66 25113 0.033869463950395584
67 25113 0.06314127147197723
68 25113 0.3008224070072174
69 25113 0.14691035449504852
70 25113 0.34172916412353516
71 25113 0.16434091329574585
72 25113 0.12737184762954712
73 25113 0.0781145840883255
74 25113 0.0739269033074379
75 25113 0.0636911392211914
76 25113 0.022513650357723236
77 25113 0.31128984689712524
78 25113 0.055707138031721115
79 25113 0.0
80 25113 0.06232709065079689
81 25113 0.0
82 25113 0.0
83 25113 0.1684207171201706
84 25113 0.013157909736037254
85 25113 0.0037436336278915405
86 25113 0.0
87 25113 0.5094212889671326
88 25113 0.6493173241615295
89 25113 0.612272322177887
90 25113 0.02617025561630726
91 25113 0.1957758367061615
92 25113 0.08332034200429916
93 25113 0.18637271225452423
94 25113 0.03412425518035889
95 25113 0.10003729909658432
96 25113 0.0
97 25113 0.09930755198001862
98 25113 0.0
99 25113 0.004811468068510294
100 25113 0.0
101 25113 0.07087943702936172
102 25113 0.0
103 25113 0.0
104 25113 0.0835893526673317
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.5091205835342407
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.4318866431713104
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.3735341429710388
122 25113 0.4425980746746063
123 25113 0.22842462360858917
124 25113 0.01310477964580059
125 25113 0.008905954658985138
126 25113 0.009925155900418758
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.06923848390579224
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.38444533944129944
138 25113 0.09439406543970108
139 25113 0.4759186804294586
140 25113 0.0
141 25113 0.0
142 25113 0.09003891795873642
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.10252050310373306
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.2324320524930954
152 25113 0.0522860586643219
153 25113 0.17150983214378357
154 25113 0.0
155 25113 0.0
156 25113 0.02150212600827217
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.09809613227844238
162 25113 0.037278298288583755
163 25113 0.03716309741139412
164 25113 0.0
165 25113 0.026737451553344727
166 25113 0.0
167 25113 0.0
168 25113 0.3624483048915863
169 25113 0.0
170 25113 0.0
171 25113 0.7529007196426392
172 25113 0.032447390258312225
173 25113 0.07809948921203613
174 25113 0.0
175 25113 0.22261285781860352
176 25113 0.16498011350631714
177 25113 0.09278904646635056
178 25113 0.0
179 25113 0.08602457493543625
180 25113 0.06605753302574158
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.13605248928070068
189 25113 0.0
190 25113 0.08084801584482193
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.2361757606267929
train - Global loss: 0.082441    Embedding norm: 1.0000   Triplets (all/active): 127.5/3046.1
Pos dist (min/mean/max): 0.1663/0.3016/0.4476   Neg dist (min/mean/max): 0.7522/1.1333/1.4787
0 1011 0.34445858001708984
1 1011 0.31815868616104126
2 1011 0.32374510169029236
3 1011 0.32819148898124695
4 1011 0.34465619921684265
5 1011 0.3533588647842407
6 1011 0.3262333273887634
7 1011 0.39453965425491333
val - Global loss: 0.341668    Embedding norm: 1.0000   Triplets (all/active): 126.4/15989.1
Pos dist (min/mean/max): 0.0577/0.1380/0.2671   Neg dist (min/mean/max): 0.0548/0.1769/0.3987
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.3875005543231964
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0785062313079834
13 25113 0.017555996775627136
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.3418341279029846
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.2581624388694763
26 25113 0.0
27 25113 0.0
28 25113 0.006705401930958033
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.04596328362822533
49 25113 0.009561989456415176
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.8432667255401611
54 25113 0.0
55 25113 0.18979386985301971
56 25113 0.7576589584350586
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.2777707874774933
64 25113 0.11255325376987457
65 25113 0.11052780598402023
66 25113 0.3554403483867645
67 25113 0.14701810479164124
68 25113 0.0624612495303154
69 25113 0.12981532514095306
70 25113 0.6771728992462158
71 25113 0.0
72 25113 0.0
73 25113 0.010385839268565178
74 25113 0.018929805606603622
75 25113 0.0
76 25113 0.08126936107873917
77 25113 0.019840184599161148
78 25113 0.010786771774291992
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.013470606878399849
83 25113 0.17768581211566925
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.7104212641716003
88 25113 0.8456301093101501
89 25113 0.8154997229576111
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.24305754899978638
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0904545709490776
100 25113 0.027157802134752274
101 25113 0.044618722051382065
102 25113 0.0
103 25113 0.0
104 25113 0.016229594126343727
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.2170313447713852
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.09212885797023773
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.09392832964658737
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.04492794722318649
129 25113 0.1228037178516388
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.015597710385918617
135 25113 0.0
136 25113 0.0
137 25113 0.0098390132188797
138 25113 0.0
139 25113 0.056283075362443924
140 25113 0.0
141 25113 0.0
142 25113 0.0
143 25113 0.01041853055357933
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.04928023740649223
148 25113 0.0
149 25113 0.11528531461954117
150 25113 0.0
151 25113 0.0
152 25113 0.0
153 25113 0.0
154 25113 0.0
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.09993325173854828
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.8591481447219849
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.10531910508871078
176 25113 0.0
177 25113 0.0861205905675888
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.0
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.09722211956977844
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.29862233996391296
train - Global loss: 0.052328    Embedding norm: 1.0000   Triplets (all/active): 127.5/1444.4
Pos dist (min/mean/max): 0.1122/0.2247/0.3258   Neg dist (min/mean/max): 0.8190/1.2454/1.6201
0 1011 0.3193858861923218
1 1011 0.3156300187110901
2 1011 0.32427501678466797
3 1011 0.3212399184703827
4 1011 0.3260467052459717
5 1011 0.32900506258010864
6 1011 0.31515827775001526
7 1011 0.3481915295124054
val - Global loss: 0.324867    Embedding norm: 1.0000   Triplets (all/active): 126.4/15989.1
Pos dist (min/mean/max): 0.0196/0.0634/0.1478   Neg dist (min/mean/max): 0.0210/0.0865/0.2378
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.52034592628479
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.10307427495718002
18 25113 0.2565377950668335
19 25113 0.1125001460313797
20 25113 0.12148961424827576
21 25113 0.13511653244495392
22 25113 0.07161231338977814
23 25113 0.05322830379009247
24 25113 0.03371477499604225
25 25113 0.23797835409641266
26 25113 0.03984292596578598
27 25113 0.0
28 25113 0.021332522854208946
29 25113 0.01138825248926878
30 25113 0.08266635984182358
31 25113 0.04850960895419121
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0551663339138031
43 25113 0.0
44 25113 0.0
45 25113 0.12831555306911469
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.021704431623220444
51 25113 0.03601980209350586
52 25113 0.12623372673988342
53 25113 0.5205762386322021
54 25113 0.0
55 25113 0.0
56 25113 0.17169927060604095
57 25113 0.016458755359053612
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.12777841091156006
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.05658770352602005
69 25113 0.13932442665100098
70 25113 0.7582981586456299
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.807721734046936
88 25113 0.8862680792808533
89 25113 0.8024592399597168
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.10321712493896484
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.04440203309059143
98 25113 0.0
99 25113 0.0
100 25113 0.016014322638511658
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.049805738031864166
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.15790420770645142
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.012507488951086998
117 25113 0.0
118 25113 0.0
119 25113 0.016429323703050613
120 25113 0.0
121 25113 0.03522935509681702
122 25113 0.0
123 25113 0.08286622166633606
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.02091199904680252
128 25113 0.28101488947868347
129 25113 0.21276549994945526
130 25113 0.2019207626581192
131 25113 0.12164276838302612
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.017026718705892563
138 25113 0.0
139 25113 0.0330246165394783
140 25113 0.0
141 25113 0.0
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.1511770784854889
148 25113 0.0
149 25113 0.020074160769581795
150 25113 0.05613233894109726
151 25113 0.06928849965333939
152 25113 0.0
153 25113 0.0
154 25113 0.0
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0483735129237175
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.019037514925003052
169 25113 0.0
170 25113 0.0
171 25113 0.620611846446991
172 25113 0.0
173 25113 0.009715761058032513
174 25113 0.007727295160293579
175 25113 0.13090285658836365
176 25113 0.11555859446525574
177 25113 0.16203883290290833
178 25113 0.0
179 25113 0.0
180 25113 0.0
181 25113 0.0
182 25113 0.0
183 25113 0.01783425733447075
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.0
train - Global loss: 0.047407    Embedding norm: 1.0000   Triplets (all/active): 127.5/1617.7
Pos dist (min/mean/max): 0.0876/0.1831/0.2727   Neg dist (min/mean/max): 0.8091/1.1781/1.5089
0 1011 0.3170347213745117
1 1011 0.30238884687423706
2 1011 0.3015490174293518
3 1011 0.31962138414382935
4 1011 0.3238474726676941
5 1011 0.3181253969669342
6 1011 0.3069085478782654
7 1011 0.3425670266151428
val - Global loss: 0.316505    Embedding norm: 1.0000   Triplets (all/active): 126.4/15989.1
Pos dist (min/mean/max): 0.0227/0.0604/0.1274   Neg dist (min/mean/max): 0.0206/0.0830/0.1788
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.3409486711025238
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0065372842364013195
18 25113 0.10030246526002884
19 25113 0.0
20 25113 0.13279089331626892
21 25113 0.13119865953922272
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.41024717688560486
26 25113 0.0
27 25113 0.0
28 25113 0.12184061110019684
29 25113 0.12437146157026291
30 25113 0.0
31 25113 0.02197343111038208
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.15074121952056885
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.013452723622322083
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.05101753771305084
53 25113 0.7796052694320679
54 25113 0.0
55 25113 0.0
56 25113 0.497958779335022
57 25113 0.08558295667171478
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.17607559263706207
64 25113 0.0
65 25113 0.0425235889852047
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.003658115863800049
70 25113 0.7997193336486816
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.04279257357120514
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.08427534997463226
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.8787739276885986
88 25113 0.9754728674888611
89 25113 0.9162283539772034
90 25113 0.0
91 25113 0.0
92 25113 0.03056202456355095
93 25113 0.0
94 25113 0.0
95 25113 0.11385136097669601
96 25113 0.0
97 25113 0.06456135213375092
98 25113 0.00012558698654174805
99 25113 0.05824657157063484
100 25113 0.09691555798053741
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.10700857639312744
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.2799164056777954
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.05326072499155998
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.023289531469345093
121 25113 0.07519951462745667
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.013839058578014374
137 25113 0.0
138 25113 0.0
139 25113 0.1111086830496788
140 25113 0.0
141 25113 0.0
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.020987695083022118
152 25113 0.0
153 25113 0.0
154 25113 0.1341671645641327
155 25113 0.0
156 25113 0.017983661964535713
157 25113 0.0
158 25113 0.035040006041526794
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.013854622840881348
169 25113 0.0
170 25113 0.0
171 25113 0.9247940182685852
172 25113 0.0
173 25113 0.2665589153766632
174 25113 0.0
175 25113 0.21669690310955048
176 25113 0.0
177 25113 0.0704263374209404
178 25113 0.0
179 25113 0.11717769503593445
180 25113 0.01880660094320774
181 25113 0.0
182 25113 0.0
183 25113 0.028048766776919365
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.0
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.0
train - Global loss: 0.049647    Embedding norm: 1.0000   Triplets (all/active): 127.5/1229.0
Pos dist (min/mean/max): 0.1282/0.2760/0.4065   Neg dist (min/mean/max): 0.9508/1.3804/1.7073
0 1011 0.3295762836933136
1 1011 0.3080669939517975
2 1011 0.3050065338611603
3 1011 0.3189883828163147
4 1011 0.33318889141082764
5 1011 0.3236148953437805
6 1011 0.31700506806373596
7 1011 0.341067373752594
val - Global loss: 0.322064    Embedding norm: 1.0000   Triplets (all/active): 126.4/15989.1
Pos dist (min/mean/max): 0.0249/0.0723/0.1417   Neg dist (min/mean/max): 0.0264/0.0943/0.1965
0 25113 0.0
1 25113 0.08464028686285019
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.13816815614700317
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.008038041181862354
23 25113 0.0
24 25113 0.0
25 25113 0.14846350252628326
26 25113 0.0
27 25113 0.15275031328201294
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.11171276122331619
43 25113 0.0
44 25113 0.02471495047211647
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 1.0305578708648682
54 25113 0.0
55 25113 0.21485544741153717
56 25113 0.47468703985214233
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.18128487467765808
63 25113 0.08891872316598892
64 25113 0.06395617872476578
65 25113 0.08782995492219925
66 25113 0.08156701922416687
67 25113 0.04763311520218849
68 25113 0.07834619283676147
69 25113 0.042183179408311844
70 25113 0.42945730686187744
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.049481019377708435
77 25113 0.05680917203426361
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.08588910102844238
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.609860897064209
88 25113 0.6990728974342346
89 25113 0.694301187992096
90 25113 0.0
91 25113 0.0
92 25113 0.050311245024204254
93 25113 0.04879919812083244
94 25113 0.0
95 25113 0.006464466452598572
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.11465396732091904
111 25113 0.010387718677520752
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.04956759884953499
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
126 25113 0.0
127 25113 0.0
128 25113 0.0
129 25113 0.0
130 25113 0.0
131 25113 0.0
132 25113 0.0
133 25113 0.0
134 25113 0.0
135 25113 0.0
136 25113 0.0
137 25113 0.0
138 25113 0.0
139 25113 0.0
140 25113 0.0
141 25113 0.0
142 25113 0.0
143 25113 0.0
144 25113 0.0
145 25113 0.0
146 25113 0.0
147 25113 0.0
148 25113 0.0
149 25113 0.0
150 25113 0.0
151 25113 0.0
152 25113 0.0
153 25113 0.0
154 25113 0.0
155 25113 0.0
156 25113 0.0
157 25113 0.0
158 25113 0.0
159 25113 0.0
160 25113 0.0
161 25113 0.0
162 25113 0.0
163 25113 0.0
164 25113 0.0
165 25113 0.0
166 25113 0.0
167 25113 0.0
168 25113 0.0
169 25113 0.0
170 25113 0.0
171 25113 0.7493312954902649
172 25113 0.0
173 25113 0.0
174 25113 0.0
175 25113 0.11682054400444031
176 25113 0.012589812278747559
177 25113 0.0
178 25113 0.0
179 25113 0.0
180 25113 0.05203038826584816
181 25113 0.0
182 25113 0.04117589443922043
183 25113 0.0151502201333642
184 25113 0.0
185 25113 0.0
186 25113 0.0
187 25113 0.0
188 25113 0.0
189 25113 0.0
190 25113 0.0
191 25113 0.0
192 25113 0.026709983125329018
193 25113 0.0
194 25113 0.0
195 25113 0.0
196 25113 0.0
train - Global loss: 0.035427    Embedding norm: 1.0000   Triplets (all/active): 127.5/1121.4
Pos dist (min/mean/max): 0.1015/0.1966/0.2950   Neg dist (min/mean/max): 0.8666/1.2732/1.5869
0 1011 0.3509639501571655
1 1011 0.3362269997596741
2 1011 0.3239789307117462
3 1011 0.31708478927612305
4 1011 0.356941282749176
5 1011 0.369126558303833
6 1011 0.33039265871047974
7 1011 0.3977032005786896
val - Global loss: 0.347802    Embedding norm: 1.0000   Triplets (all/active): 126.4/15983.2
Pos dist (min/mean/max): 0.0672/0.1784/0.3817   Neg dist (min/mean/max): 0.0653/0.2456/0.6338
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0964277982711792
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 405, in do_train
    loss.backward()
  File "/usr/local/lib/python3.9/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
