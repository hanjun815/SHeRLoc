  0%|                                                    | 0/80 [00:00<?, ?it/s]
0 25113 0.4569624960422516
1 25113 0.5573869943618774
2 25113 0.3891601860523224
3 25113 0.5482367277145386
4 25113 0.4749363362789154
5 25113 0.4519702196121216
6 25113 0.48972246050834656
7 25113 0.3988255262374878
8 25113 0.34290021657943726
9 25113 0.48624730110168457
10 25113 0.5336901545524597
11 25113 0.43909183144569397
12 25113 0.4437102675437927
13 25113 0.4461561143398285
14 25113 0.4162850081920624
15 25113 0.43384334444999695
16 25113 0.36721816658973694
17 25113 0.36034050583839417
18 25113 0.3085135221481323
19 25113 0.2468717396259308
20 25113 0.27832239866256714
21 25113 0.30899578332901
22 25113 0.31336700916290283
23 25113 0.26653802394866943
24 25113 0.3604491949081421
25 25113 0.27567118406295776
26 25113 0.2838985323905945
27 25113 0.30537930130958557
28 25113 0.26584750413894653
29 25113 0.33633482456207275
30 25113 0.2973196804523468
31 25113 0.25153854489326477
32 25113 0.34998220205307007
33 25113 0.24294918775558472
34 25113 0.30574530363082886
35 25113 0.2742094397544861
36 25113 0.3119785189628601
37 25113 0.3625651001930237
38 25113 0.29125580191612244
39 25113 0.27615174651145935
40 25113 0.2874663770198822
41 25113 0.283577561378479
42 25113 0.29267340898513794
43 25113 0.2290150374174118
44 25113 0.2669098973274231
45 25113 0.32679983973503113
46 25113 0.29814496636390686
47 25113 0.3047097325325012
48 25113 0.36172184348106384
49 25113 0.3771170675754547
50 25113 0.28885844349861145
51 25113 0.21160462498664856
52 25113 0.26790550351142883
53 25113 0.31730973720550537
54 25113 0.27890312671661377
55 25113 0.3388098180294037
56 25113 0.29314300417900085
57 25113 0.26009926199913025
58 25113 0.29026588797569275
59 25113 0.266360878944397
60 25113 0.20950910449028015
61 25113 0.2870245575904846
62 25113 0.2890686094760895
63 25113 0.2210123986005783
64 25113 0.2764759361743927
65 25113 0.2724035084247589
66 25113 0.17946304380893707
67 25113 0.38550275564193726
68 25113 0.32409200072288513
69 25113 0.3129097521305084
70 25113 0.3384290635585785
71 25113 0.4120232164859772
72 25113 0.24582697451114655
73 25113 0.20610415935516357
74 25113 0.3060266077518463
75 25113 0.2680482864379883
76 25113 0.3532222509384155
77 25113 0.3860756456851959
78 25113 0.2399640828371048
79 25113 0.26503461599349976
80 25113 0.2417871206998825
81 25113 0.20006315410137177
82 25113 0.20056912302970886
83 25113 0.22701692581176758
84 25113 0.2302907109260559
85 25113 0.2538699805736542
86 25113 0.2076917290687561
87 25113 0.21136103570461273
88 25113 0.29978764057159424
89 25113 0.3361157476902008
90 25113 0.22829172015190125
91 25113 0.19253234565258026
92 25113 0.22397692501544952
93 25113 0.32828760147094727
94 25113 0.30171850323677063
95 25113 0.19664892554283142
96 25113 0.2404724508523941
97 25113 0.198732390999794
98 25113 0.2479645013809204
99 25113 0.3944489359855652
100 25113 0.2932378947734833
101 25113 0.30100300908088684
102 25113 0.221745565533638
103 25113 0.2320716232061386
104 25113 0.19929221272468567
105 25113 0.33118757605552673
106 25113 0.37244758009910583
107 25113 0.304301381111145
108 25113 0.3135773241519928
109 25113 0.36888477206230164
110 25113 0.2954753637313843
111 25113 0.34763261675834656
112 25113 0.14513768255710602
113 25113 0.19878432154655457
114 25113 0.16390903294086456
115 25113 0.18403029441833496
116 25113 0.35202649235725403
117 25113 0.26982635259628296
118 25113 0.2667342722415924
119 25113 0.2963143289089203
120 25113 0.20307078957557678
121 25113 0.22143018245697021
122 25113 0.3258717358112335
123 25113 0.32174989581108093
124 25113 0.1973944455385208
125 25113 0.3627544045448303
train - Global loss: 0.303347    Embedding norm: 1.0000   Triplets (all/active): 199.3/31186.6
Pos dist (min/mean/max): 0.6198/1.0756/1.5455   Neg dist (min/mean/max): 0.7826/1.4030/1.8145
0 1011 0.2938202917575836
1 1011 0.2621399462223053
2 1011 0.28961682319641113
3 1011 0.28257739543914795
4 1011 0.3697200417518616
5 1011 0.24123919010162354
val - Global loss: 0.289852    Embedding norm: 1.0000   Triplets (all/active): 168.5/25120.3
Pos dist (min/mean/max): 0.4536/0.7973/1.1570   Neg dist (min/mean/max): 0.3699/1.0876/1.6560
0 25113 0.23219028115272522
1 25113 0.2835768461227417
2 25113 0.21477365493774414
3 25113 0.28338512778282166
4 25113 0.33726078271865845
5 25113 0.29727742075920105
6 25113 0.30053776502609253
7 25113 0.2912956476211548
8 25113 0.3058628737926483
9 25113 0.23646050691604614
10 25113 0.1972653567790985
11 25113 0.2665088176727295
12 25113 0.32798004150390625
13 25113 0.3107186257839203
14 25113 0.25979530811309814
15 25113 0.2143227905035019
16 25113 0.310268759727478
17 25113 0.3383336067199707
18 25113 0.2200286090373993
19 25113 0.18772266805171967
20 25113 0.21871235966682434
21 25113 0.2510928809642792
22 25113 0.21671554446220398
23 25113 0.22625216841697693
24 25113 0.20572443306446075
25 25113 0.3152469992637634
26 25113 0.19756290316581726
27 25113 0.24886567890644073
28 25113 0.16964730620384216
29 25113 0.24465562403202057
30 25113 0.2539716958999634
31 25113 0.18907815217971802
32 25113 0.32500940561294556
33 25113 0.21435226500034332
34 25113 0.2738143801689148
35 25113 0.25384485721588135
36 25113 0.26363083720207214
37 25113 0.2863203287124634
38 25113 0.2101212739944458
39 25113 0.25443029403686523
40 25113 0.2597215175628662
41 25113 0.21621882915496826
42 25113 0.16621826589107513
43 25113 0.16099436581134796
44 25113 0.2043614685535431
45 25113 0.21213199198246002
46 25113 0.19363217055797577
47 25113 0.20602039992809296
48 25113 0.28399741649627686
49 25113 0.2402331680059433
50 25113 0.20631547272205353
51 25113 0.20225530862808228
52 25113 0.20629584789276123
53 25113 0.22612206637859344
54 25113 0.16901756823062897
55 25113 0.26676255464553833
56 25113 0.22073815762996674
57 25113 0.2182464599609375
58 25113 0.16361337900161743
59 25113 0.17168939113616943
60 25113 0.13219794631004333
61 25113 0.1910335272550583
62 25113 0.1958187222480774
63 25113 0.20193660259246826
64 25113 0.2501027286052704
65 25113 0.1437547355890274
66 25113 0.14930464327335358
67 25113 0.19247089326381683
68 25113 0.23789717257022858
69 25113 0.22097890079021454
70 25113 0.19887730479240417
71 25113 0.25611355900764465
72 25113 0.16830305755138397
73 25113 0.1481001228094101
74 25113 0.3136278986930847
75 25113 0.22313538193702698
76 25113 0.20921292901039124
77 25113 0.28046557307243347
78 25113 0.21676236391067505
79 25113 0.21628984808921814
80 25113 0.18137209117412567
81 25113 0.12088918685913086
82 25113 0.18362167477607727
83 25113 0.19739793241024017
84 25113 0.20657485723495483
85 25113 0.18704698979854584
86 25113 0.12111660838127136
87 25113 0.12262936681509018
88 25113 0.18982835114002228
89 25113 0.23261095583438873
90 25113 0.18629930913448334
91 25113 0.1469898670911789
92 25113 0.17082655429840088
93 25113 0.24840758740901947
94 25113 0.18552665412425995
95 25113 0.1320486068725586
96 25113 0.14155207574367523
97 25113 0.21101896464824677
98 25113 0.1745096743106842
99 25113 0.24766001105308533
100 25113 0.276917040348053
101 25113 0.2915395498275757
102 25113 0.21768996119499207
103 25113 0.16658778488636017
104 25113 0.1628284603357315
105 25113 0.22694848477840424
106 25113 0.2529814839363098
107 25113 0.1814945638179779
108 25113 0.1845729649066925
109 25113 0.31760168075561523
110 25113 0.18380773067474365
111 25113 0.21435336768627167
112 25113 0.10191326588392258
113 25113 0.2248782217502594
114 25113 0.1232149675488472
115 25113 0.15209750831127167
116 25113 0.24037271738052368
117 25113 0.20455700159072876
118 25113 0.17340290546417236
119 25113 0.23002617061138153
120 25113 0.16103212535381317
121 25113 0.1457737386226654
122 25113 0.1801294982433319
123 25113 0.18717136979103088
124 25113 0.14208802580833435
125 25113 0.241524800658226
train - Global loss: 0.217056    Embedding norm: 1.0000   Triplets (all/active): 199.3/25239.1
Pos dist (min/mean/max): 0.5497/0.9616/1.4113   Neg dist (min/mean/max): 0.8062/1.4045/1.8019
0 1011 0.23994767665863037
1 1011 0.22706745564937592
2 1011 0.256101131439209
3 1011 0.26852431893348694
4 1011 0.2765088677406311
5 1011 0.22077414393424988
val - Global loss: 0.248154    Embedding norm: 1.0000   Triplets (all/active): 168.5/24666.0
Pos dist (min/mean/max): 0.5166/0.8198/1.1635   Neg dist (min/mean/max): 0.4284/1.1832/1.6783
0 25113 0.2240380048751831
1 25113 0.23454755544662476
2 25113 0.15510687232017517
3 25113 0.22548764944076538
4 25113 0.33291634917259216
5 25113 0.21017232537269592
6 25113 0.2130936086177826
7 25113 0.23764730989933014
8 25113 0.20553496479988098
9 25113 0.17673106491565704
10 25113 0.1837744414806366
11 25113 0.18106774985790253
12 25113 0.24793636798858643
13 25113 0.19123904407024384
14 25113 0.21038979291915894
15 25113 0.18306933343410492
16 25113 0.29396507143974304
17 25113 0.22415593266487122
18 25113 0.166329026222229
19 25113 0.12955863773822784
20 25113 0.17953906953334808
21 25113 0.16419725120067596
22 25113 0.2383488267660141
23 25113 0.1608601063489914
24 25113 0.20199497044086456
25 25113 0.22414083778858185
26 25113 0.15795058012008667
27 25113 0.16322065889835358
28 25113 0.1784241795539856
29 25113 0.21432216465473175
30 25113 0.15582209825515747
31 25113 0.13571715354919434
32 25113 0.2169734537601471
33 25113 0.16906845569610596
34 25113 0.1857253760099411
35 25113 0.15941715240478516
36 25113 0.2311890572309494
37 25113 0.1639791578054428
38 25113 0.23571506142616272
39 25113 0.2049502581357956
40 25113 0.21089152991771698
41 25113 0.20534011721611023
42 25113 0.2015509307384491
43 25113 0.11751928180456161
44 25113 0.16804903745651245
45 25113 0.17007803916931152
46 25113 0.1543864905834198
47 25113 0.15031547844409943
48 25113 0.21012479066848755
49 25113 0.18516214191913605
50 25113 0.20622113347053528
51 25113 0.18616624176502228
52 25113 0.2072301208972931
53 25113 0.24462847411632538
54 25113 0.12841688096523285
55 25113 0.21522459387779236
56 25113 0.14482145011425018
57 25113 0.19233942031860352
58 25113 0.14005179703235626
59 25113 0.1255466789007187
60 25113 0.12188427895307541
61 25113 0.13594014942646027
62 25113 0.1776912659406662
63 25113 0.2122398465871811
64 25113 0.18061493337154388
65 25113 0.115562304854393
66 25113 0.13381832838058472
67 25113 0.16578979790210724
68 25113 0.18526524305343628
69 25113 0.17660552263259888
70 25113 0.1493322253227234
71 25113 0.24213026463985443
72 25113 0.15467825531959534
73 25113 0.1354716718196869
74 25113 0.18462471663951874
75 25113 0.15063032507896423
76 25113 0.16527661681175232
77 25113 0.24220387637615204
78 25113 0.1805652529001236
79 25113 0.15409143269062042
80 25113 0.12771658599376678
81 25113 0.11203736811876297
82 25113 0.12987427413463593
83 25113 0.1716148555278778
84 25113 0.18166300654411316
85 25113 0.22021141648292542
86 25113 0.09902255237102509
87 25113 0.08611275255680084
88 25113 0.14696970582008362
89 25113 0.17473669350147247
90 25113 0.13671165704727173
91 25113 0.12090165913105011
92 25113 0.13742084801197052
93 25113 0.19621524214744568
94 25113 0.15811501443386078
95 25113 0.1097438782453537
96 25113 0.1276867538690567
97 25113 0.1571791023015976
98 25113 0.15233604609966278
99 25113 0.22826260328292847
100 25113 0.21249078214168549
101 25113 0.1477862000465393
102 25113 0.15293854475021362
103 25113 0.1706462800502777
104 25113 0.11365161836147308
105 25113 0.13304562866687775
106 25113 0.22171933948993683
107 25113 0.11525487154722214
108 25113 0.13477835059165955
109 25113 0.2359733283519745
110 25113 0.17463934421539307
111 25113 0.1544775515794754
112 25113 0.0886903703212738
113 25113 0.12861543893814087
114 25113 0.1318574696779251
115 25113 0.11330998688936234
116 25113 0.19158558547496796
117 25113 0.15657229721546173
118 25113 0.13644014298915863
119 25113 0.17982901632785797
120 25113 0.1508704125881195
121 25113 0.1157965362071991
122 25113 0.17249000072479248
123 25113 0.12825597822666168
124 25113 0.09910959750413895
125 25113 0.16240470111370087
train - Global loss: 0.172973    Embedding norm: 1.0000   Triplets (all/active): 199.3/20499.8
Pos dist (min/mean/max): 0.5171/0.9041/1.3254   Neg dist (min/mean/max): 0.8459/1.4058/1.7896
0 1011 0.1869206577539444
1 1011 0.2079499214887619
2 1011 0.2624131739139557
3 1011 0.2042512148618698
4 1011 0.3483039438724518
5 1011 0.1421251893043518
val - Global loss: 0.225327    Embedding norm: 1.0000   Triplets (all/active): 168.5/22283.0
Pos dist (min/mean/max): 0.4220/0.7434/1.1125   Neg dist (min/mean/max): 0.4260/1.1512/1.6346
0 25113 0.15647941827774048
1 25113 0.1551339477300644
2 25113 0.13974414765834808
3 25113 0.16716136038303375
4 25113 0.2882479131221771
5 25113 0.19923900067806244
6 25113 0.15812326967716217
7 25113 0.2147221565246582
8 25113 0.18479232490062714
9 25113 0.13549862802028656
10 25113 0.15219727158546448
11 25113 0.13493935763835907
12 25113 0.17976680397987366
13 25113 0.13562825322151184
14 25113 0.1619136482477188
15 25113 0.11152457445859909
16 25113 0.20073635876178741
17 25113 0.1715616136789322
18 25113 0.1494312733411789
19 25113 0.09025919437408447
20 25113 0.11955805122852325
21 25113 0.14020155370235443
22 25113 0.17106285691261292
23 25113 0.1276875138282776
24 25113 0.20693913102149963
25 25113 0.1543523222208023
26 25113 0.1090163141489029
27 25113 0.17529025673866272
28 25113 0.16009558737277985
29 25113 0.19512686133384705
30 25113 0.16757549345493317
31 25113 0.10171240568161011
32 25113 0.2009543627500534
33 25113 0.16638900339603424
34 25113 0.16967147588729858
35 25113 0.1440918892621994
36 25113 0.17596451938152313
37 25113 0.13084359467029572
38 25113 0.19490085542201996
39 25113 0.16392052173614502
40 25113 0.17173463106155396
41 25113 0.15240463614463806
42 25113 0.14398494362831116
43 25113 0.1289638727903366
44 25113 0.12532983720302582
45 25113 0.15765640139579773
46 25113 0.14412297308444977
47 25113 0.1099616289138794
48 25113 0.16939710080623627
49 25113 0.17124374210834503
50 25113 0.14831425249576569
51 25113 0.11426547169685364
52 25113 0.14932622015476227
53 25113 0.19547906517982483
54 25113 0.10686229169368744
55 25113 0.16881142556667328
56 25113 0.13667814433574677
57 25113 0.1446426659822464
58 25113 0.12106174975633621
59 25113 0.10857413709163666
60 25113 0.10126961022615433
61 25113 0.12186962366104126
62 25113 0.14758910238742828
63 25113 0.19004115462303162
64 25113 0.15738718211650848
65 25113 0.11708783358335495
66 25113 0.10402893275022507
67 25113 0.14569862186908722
68 25113 0.16397620737552643
69 25113 0.13154259324073792
70 25113 0.15515653789043427
71 25113 0.22307316958904266
72 25113 0.12276460975408554
73 25113 0.11053391546010971
74 25113 0.15384887158870697
75 25113 0.15054254233837128
76 25113 0.12597551941871643
77 25113 0.1815171241760254
78 25113 0.13705794513225555
79 25113 0.11319278925657272
80 25113 0.1199762150645256
81 25113 0.11786440014839172
82 25113 0.11455751210451126
83 25113 0.13672740757465363
84 25113 0.11594858020544052
85 25113 0.17367243766784668
86 25113 0.11594096571207047
87 25113 0.07068730890750885
88 25113 0.11785206943750381
89 25113 0.1564149707555771
90 25113 0.1044645607471466
91 25113 0.1051592230796814
92 25113 0.12678518891334534
93 25113 0.19712094962596893
94 25113 0.11478698998689651
95 25113 0.0968003198504448
96 25113 0.10241950303316116
97 25113 0.15113896131515503
98 25113 0.14059798419475555
99 25113 0.19834814965724945
100 25113 0.18664655089378357
101 25113 0.14494001865386963
102 25113 0.10718008130788803
103 25113 0.12927116453647614
104 25113 0.11409536004066467
105 25113 0.11705952137708664
106 25113 0.16368047893047333
107 25113 0.10547852516174316
108 25113 0.09857483208179474
109 25113 0.19201914966106415
110 25113 0.12635956704616547
111 25113 0.12592799961566925
112 25113 0.07428455352783203
113 25113 0.10378651320934296
114 25113 0.11347933858633041
115 25113 0.09584999829530716
116 25113 0.20591945946216583
117 25113 0.18622595071792603
118 25113 0.12955249845981598
119 25113 0.14108042418956757
120 25113 0.11114227026700974
121 25113 0.0800991877913475
122 25113 0.14737357199192047
123 25113 0.12844686210155487
124 25113 0.09661948680877686
125 25113 0.15785180032253265
train - Global loss: 0.144013    Embedding norm: 1.0000   Triplets (all/active): 199.3/16226.4
Pos dist (min/mean/max): 0.5134/0.8606/1.2651   Neg dist (min/mean/max): 0.8757/1.4059/1.7773
0 1011 0.22092659771442413
1 1011 0.1800273209810257
2 1011 0.2343704253435135
3 1011 0.21648062765598297
4 1011 0.26827162504196167
5 1011 0.18657782673835754
val - Global loss: 0.217776    Embedding norm: 1.0000   Triplets (all/active): 168.5/20234.7
Pos dist (min/mean/max): 0.5977/0.8603/1.1313   Neg dist (min/mean/max): 0.5731/1.2619/1.6896
0 25113 0.13693015277385712
1 25113 0.15248028934001923
2 25113 0.13392353057861328
3 25113 0.13710105419158936
4 25113 0.22581976652145386
5 25113 0.14272242784500122
6 25113 0.1552867591381073
7 25113 0.1697721779346466
8 25113 0.17635051906108856
9 25113 0.10887829959392548
10 25113 0.1283024251461029
11 25113 0.11681599169969559
12 25113 0.1576700657606125
13 25113 0.1002858579158783
14 25113 0.17159655690193176
15 25113 0.09854365140199661
16 25113 0.15530060231685638
17 25113 0.146445170044899
18 25113 0.12238998711109161
19 25113 0.11342734843492508
20 25113 0.11489258706569672
21 25113 0.12611602246761322
22 25113 0.15718309581279755
23 25113 0.13336263597011566
24 25113 0.14800359308719635
25 25113 0.13793107867240906
26 25113 0.09170345216989517
27 25113 0.1289503574371338
28 25113 0.09065143018960953
29 25113 0.17448125779628754
30 25113 0.12701278924942017
31 25113 0.12157843261957169
32 25113 0.19078953564167023
33 25113 0.12574642896652222
34 25113 0.17433471977710724
35 25113 0.11554081737995148
36 25113 0.12048227339982986
37 25113 0.09095072746276855
38 25113 0.14043192565441132
39 25113 0.15018442273139954
40 25113 0.13575948774814606
41 25113 0.1390579491853714
42 25113 0.14443780481815338
43 25113 0.0881590023636818
44 25113 0.11329305171966553
45 25113 0.11452411115169525
46 25113 0.11177720874547958
47 25113 0.10297663509845734
48 25113 0.13571195304393768
49 25113 0.12737636268138885
50 25113 0.14221307635307312
51 25113 0.09535609930753708
52 25113 0.10544528812170029
53 25113 0.16612716019153595
54 25113 0.07805728167295456
55 25113 0.13094168901443481
56 25113 0.13231293857097626
57 25113 0.13598284125328064
58 25113 0.09703082591295242
59 25113 0.09973710775375366
60 25113 0.10728782415390015
61 25113 0.07546205818653107
62 25113 0.1294289529323578
63 25113 0.13767069578170776
64 25113 0.1472080945968628
65 25113 0.0975877046585083
66 25113 0.1077241450548172
67 25113 0.1266319304704666
68 25113 0.1295011192560196
69 25113 0.10101409256458282
70 25113 0.07905326038599014
71 25113 0.20603600144386292
72 25113 0.09078740328550339
73 25113 0.07116032391786575
74 25113 0.1170964390039444
75 25113 0.1307418942451477
76 25113 0.12789760529994965
77 25113 0.1727191060781479
78 25113 0.10704026371240616
79 25113 0.10462634265422821
80 25113 0.08720607310533524
81 25113 0.0888424962759018
82 25113 0.11269158869981766
83 25113 0.13305535912513733
84 25113 0.11717363446950912
85 25113 0.13106723129749298
86 25113 0.08545272052288055
87 25113 0.07237613946199417
88 25113 0.10057291388511658
89 25113 0.13507753610610962
90 25113 0.10865499079227448
91 25113 0.08903873711824417
92 25113 0.10873578488826752
93 25113 0.16448450088500977
94 25113 0.11935431510210037
95 25113 0.09512819349765778
96 25113 0.10460080206394196
97 25113 0.10953487455844879
98 25113 0.1396586298942566
99 25113 0.15743939578533173
100 25113 0.18287399411201477
101 25113 0.12324590235948563
102 25113 0.08309416472911835
103 25113 0.09490823745727539
104 25113 0.11219418793916702
105 25113 0.07913815230131149
106 25113 0.12727007269859314
107 25113 0.1100512221455574
108 25113 0.09127290546894073
109 25113 0.1816963404417038
110 25113 0.12272114306688309
111 25113 0.09152451902627945
112 25113 0.0524962954223156
113 25113 0.073574498295784
114 25113 0.051914531737565994
115 25113 0.07815776765346527
116 25113 0.1546018123626709
117 25113 0.15125885605812073
118 25113 0.1033034473657608
119 25113 0.1371871680021286
120 25113 0.11717230826616287
121 25113 0.11069976538419724
122 25113 0.11665210872888565
123 25113 0.10855646431446075
124 25113 0.08709616214036942
125 25113 0.120573028922081
train - Global loss: 0.122196    Embedding norm: 1.0000   Triplets (all/active): 199.3/13155.7
Pos dist (min/mean/max): 0.5059/0.8333/1.2082   Neg dist (min/mean/max): 0.8876/1.4069/1.7650
0 1011 0.22016853094100952
1 1011 0.17125925421714783
2 1011 0.2722231447696686
3 1011 0.22491739690303802
4 1011 0.28474682569503784
5 1011 0.18188831210136414
val - Global loss: 0.225867    Embedding norm: 1.0000   Triplets (all/active): 168.5/21536.0
Pos dist (min/mean/max): 0.5929/0.8761/1.2057   Neg dist (min/mean/max): 0.5451/1.2481/1.6798
0 25113 0.1140102744102478
1 25113 0.1513122022151947
2 25113 0.0982150286436081
3 25113 0.1144554615020752
4 25113 0.20195753872394562
5 25113 0.14172984659671783
6 25113 0.12026531994342804
7 25113 0.1277904063463211
8 25113 0.14171932637691498
9 25113 0.13988418877124786
10 25113 0.12650427222251892
11 25113 0.09945549070835114
12 25113 0.10568304359912872
13 25113 0.10635097324848175
14 25113 0.12081505358219147
15 25113 0.09368883073329926
16 25113 0.14714542031288147
17 25113 0.1374446153640747
18 25113 0.09569256752729416
19 25113 0.06257638335227966
20 25113 0.09588424116373062
21 25113 0.09796871244907379
22 25113 0.11272042244672775
23 25113 0.09374553710222244
24 25113 0.14348603785037994
25 25113 0.11785698682069778
26 25113 0.07952190190553665
27 25113 0.1089400053024292
28 25113 0.09556836634874344
29 25113 0.12641723453998566
30 25113 0.11371126025915146
31 25113 0.11744441837072372
32 25113 0.15028440952301025
33 25113 0.08865301311016083
34 25113 0.12291041761636734
35 25113 0.1071133241057396
36 25113 0.10531681776046753
37 25113 0.09910121560096741
38 25113 0.1311008483171463
39 25113 0.13797055184841156
40 25113 0.15021075308322906
41 25113 0.11895867437124252
42 25113 0.10483099520206451
43 25113 0.09062837809324265
44 25113 0.09403252601623535
45 25113 0.12461446970701218
46 25113 0.12074709683656693
47 25113 0.10437022894620895
48 25113 0.09389563649892807
49 25113 0.10256820172071457
50 25113 0.11650725454092026
51 25113 0.06491777300834656
52 25113 0.11556529253721237
53 25113 0.1428222358226776
54 25113 0.056413330137729645
55 25113 0.12351757287979126
56 25113 0.10163474082946777
57 25113 0.08879870921373367
58 25113 0.09652012586593628
59 25113 0.046746447682380676
60 25113 0.06871262192726135
61 25113 0.08344531059265137
62 25113 0.11976122111082077
63 25113 0.13181272149085999
64 25113 0.12073070555925369
65 25113 0.08363369852304459
66 25113 0.08101355284452438
67 25113 0.10500995069742203
68 25113 0.1383102387189865
69 25113 0.10876505821943283
70 25113 0.09550973773002625
71 25113 0.20194748044013977
72 25113 0.07218430936336517
73 25113 0.10662303864955902
74 25113 0.10792464017868042
75 25113 0.11864393204450607
76 25113 0.08525005728006363
77 25113 0.1333991438150406
78 25113 0.11957988888025284
79 25113 0.07715284824371338
80 25113 0.09578250348567963
81 25113 0.07668905705213547
82 25113 0.0954027771949768
83 25113 0.10525734722614288
84 25113 0.12505072355270386
85 25113 0.1438671350479126
86 25113 0.09315672516822815
87 25113 0.058917783200740814
88 25113 0.0953163430094719
89 25113 0.12942974269390106
90 25113 0.06336374580860138
91 25113 0.08911177515983582
92 25113 0.09538248926401138
93 25113 0.14005625247955322
94 25113 0.09366336464881897
95 25113 0.07483171671628952
96 25113 0.07614235579967499
97 25113 0.12290879338979721
98 25113 0.11974319070577621
99 25113 0.13766120374202728
100 25113 0.14428138732910156
101 25113 0.09150272607803345
102 25113 0.09978841245174408
103 25113 0.10108671337366104
104 25113 0.07815136015415192
105 25113 0.11393741518259048
106 25113 0.08715644478797913
107 25113 0.091819629073143
108 25113 0.09183254837989807
109 25113 0.16084884107112885
110 25113 0.09456634521484375
111 25113 0.10511813312768936
112 25113 0.05983683466911316
113 25113 0.06345085054636002
114 25113 0.10511026531457901
115 25113 0.08092942088842392
116 25113 0.12449824064970016
117 25113 0.1135520190000534
118 25113 0.09592897444963455
119 25113 0.11200598627328873
120 25113 0.09055246412754059
121 25113 0.0970061719417572
122 25113 0.10929728299379349
123 25113 0.09029587358236313
124 25113 0.08524426072835922
125 25113 0.12822243571281433
train - Global loss: 0.107602    Embedding norm: 1.0000   Triplets (all/active): 199.3/10383.9
Pos dist (min/mean/max): 0.4944/0.8055/1.1650   Neg dist (min/mean/max): 0.8954/1.4069/1.7547
0 1011 0.17553459107875824
1 1011 0.18279162049293518
2 1011 0.24137566983699799
3 1011 0.17820705473423004
4 1011 0.2926604151725769
5 1011 0.1742388904094696
val - Global loss: 0.207468    Embedding norm: 1.0000   Triplets (all/active): 168.5/21013.0
Pos dist (min/mean/max): 0.5048/0.7820/1.0708   Neg dist (min/mean/max): 0.4684/1.1650/1.6254
0 25113 0.08591435104608536
1 25113 0.13087962567806244
2 25113 0.09472029656171799
3 25113 0.11721019446849823
4 25113 0.15327675640583038
5 25113 0.14299923181533813
6 25113 0.11643549054861069
7 25113 0.12968140840530396
8 25113 0.10418940335512161
9 25113 0.08331737667322159
10 25113 0.12414532154798508
11 25113 0.08194511383771896
12 25113 0.1257573962211609
13 25113 0.07577213644981384
14 25113 0.11070629954338074
15 25113 0.07960107177495956
16 25113 0.11926426738500595
17 25113 0.1021270826458931
18 25113 0.07786455005407333
19 25113 0.08259406685829163
20 25113 0.1115707978606224
21 25113 0.06943619251251221
22 25113 0.11840618401765823
23 25113 0.08401300013065338
24 25113 0.12622515857219696
25 25113 0.09172476083040237
26 25113 0.08823994547128677
27 25113 0.10308530926704407
28 25113 0.09560652822256088
29 25113 0.13379767537117004
30 25113 0.10581541061401367
31 25113 0.05853095278143883
32 25113 0.13073725998401642
33 25113 0.08144884556531906
34 25113 0.10586680471897125
35 25113 0.07518967241048813
36 25113 0.10175309330224991
37 25113 0.07431984692811966
38 25113 0.15794998407363892
39 25113 0.11172986775636673
40 25113 0.11494599282741547
41 25113 0.09987673163414001
42 25113 0.07662639021873474
43 25113 0.05805279314517975
44 25113 0.0801503136754036
45 25113 0.12605050206184387
46 25113 0.10292906314134598
47 25113 0.10901760309934616
48 25113 0.1385384500026703
49 25113 0.1053789034485817
50 25113 0.11773686110973358
51 25113 0.0721697211265564
52 25113 0.11326546967029572
53 25113 0.10944361984729767
54 25113 0.09809878468513489
55 25113 0.15759214758872986
56 25113 0.11197023093700409
57 25113 0.10388003289699554
58 25113 0.08542995899915695
59 25113 0.06332025676965714
60 25113 0.07447799295186996
61 25113 0.09597600996494293
62 25113 0.09983450919389725
63 25113 0.10573823004961014
64 25113 0.11452813446521759
65 25113 0.06621621549129486
66 25113 0.09334909170866013
67 25113 0.09797874093055725
68 25113 0.09882201254367828
69 25113 0.10100347548723221
70 25113 0.08310332149267197
71 25113 0.17190808057785034
72 25113 0.07723668962717056
73 25113 0.08197423070669174
74 25113 0.09553517401218414
75 25113 0.10224376618862152
76 25113 0.09034963697195053
77 25113 0.1354052871465683
78 25113 0.08605150878429413
79 25113 0.07356658577919006
80 25113 0.06397668272256851
81 25113 0.07243681699037552
82 25113 0.07394441962242126
83 25113 0.10046260058879852
84 25113 0.10865434259176254
85 25113 0.10354280471801758
86 25113 0.06414168328046799
87 25113 0.07976490259170532
88 25113 0.09530051052570343
89 25113 0.08900846540927887
90 25113 0.08916433155536652
91 25113 0.08861659467220306
92 25113 0.08468905091285706
93 25113 0.1499144732952118
94 25113 0.100240558385849
95 25113 0.0738920196890831
96 25113 0.09168572723865509
97 25113 0.10607901215553284
98 25113 0.0679672360420227
99 25113 0.10376590490341187
100 25113 0.1294834017753601
101 25113 0.08000236004590988
102 25113 0.06379115581512451
103 25113 0.07623299211263657
104 25113 0.06588030606508255
105 25113 0.07441776990890503
106 25113 0.10035844892263412
107 25113 0.08002382516860962
108 25113 0.06606091558933258
109 25113 0.1369808465242386
110 25113 0.06981749832630157
111 25113 0.06253323704004288
112 25113 0.0507727712392807
113 25113 0.05946808308362961
114 25113 0.05769867077469826
115 25113 0.05047216638922691
116 25113 0.11515922099351883
117 25113 0.08951844274997711
118 25113 0.11489882320165634
119 25113 0.0906156376004219
120 25113 0.08657483756542206
121 25113 0.07077006250619888
122 25113 0.11785857379436493
123 25113 0.13587448000907898
124 25113 0.09900177270174026
125 25113 0.1076546311378479
train - Global loss: 0.096927    Embedding norm: 1.0000   Triplets (all/active): 199.3/8459.6
Pos dist (min/mean/max): 0.4908/0.7853/1.1311   Neg dist (min/mean/max): 0.9159/1.4074/1.7547
0 1011 0.19575537741184235
1 1011 0.1760348677635193
2 1011 0.2224978804588318
3 1011 0.17679700255393982
4 1011 0.2829406261444092
5 1011 0.3260287940502167
val - Global loss: 0.230009    Embedding norm: 1.0000   Triplets (all/active): 168.5/21659.3
Pos dist (min/mean/max): 0.6044/0.8917/1.1911   Neg dist (min/mean/max): 0.5091/1.2237/1.6739
0 25113 0.07974299788475037
1 25113 0.09409374743700027
2 25113 0.10539977252483368
3 25113 0.07486143708229065
4 25113 0.09167148172855377
5 25113 0.1487116515636444
6 25113 0.11611542105674744
7 25113 0.07866323739290237
8 25113 0.11763429641723633
9 25113 0.07148362696170807
10 25113 0.104746013879776
11 25113 0.08576832711696625
12 25113 0.09096640348434448
13 25113 0.09147665649652481
14 25113 0.1163245365023613
15 25113 0.07924696803092957
16 25113 0.09539949893951416
17 25113 0.10246169567108154
18 25113 0.07596954703330994
19 25113 0.036937009543180466
20 25113 0.09409329295158386
21 25113 0.08192899078130722
22 25113 0.09943415969610214
23 25113 0.0985439196228981
24 25113 0.11276881396770477
25 25113 0.08677002787590027
26 25113 0.0658661499619484
27 25113 0.09249809384346008
28 25113 0.06930119544267654
29 25113 0.10548707842826843
30 25113 0.09720158576965332
31 25113 0.06375571340322495
32 25113 0.12098220735788345
33 25113 0.10819044709205627
34 25113 0.11098530888557434
35 25113 0.114434152841568
36 25113 0.0985780879855156
37 25113 0.071839340031147
38 25113 0.11987891793251038
39 25113 0.07110942155122757
40 25113 0.1304783970117569
41 25113 0.076812744140625
42 25113 0.07335102558135986
43 25113 0.08054398745298386
44 25113 0.09406085312366486
45 25113 0.07946547865867615
46 25113 0.12498711049556732
47 25113 0.10435431450605392
48 25113 0.10774575918912888
49 25113 0.1226373091340065
50 25113 0.08969004452228546
51 25113 0.08228273689746857
52 25113 0.10529377311468124
53 25113 0.10183082520961761
54 25113 0.0863882303237915
55 25113 0.11206010729074478
56 25113 0.11026972532272339
57 25113 0.11597486585378647
58 25113 0.10497570782899857
59 25113 0.07083562761545181
60 25113 0.10877802968025208
61 25113 0.07626672089099884
62 25113 0.10069593787193298
63 25113 0.11839272826910019
64 25113 0.13100525736808777
65 25113 0.06385121494531631
66 25113 0.09799940139055252
67 25113 0.09904357045888901
68 25113 0.1391867846250534
69 25113 0.12703706324100494
70 25113 0.13537177443504333
71 25113 0.16787804663181305
72 25113 0.08910571038722992
73 25113 0.06763780117034912
74 25113 0.12127482146024704
75 25113 0.10009399056434631
76 25113 0.08459652215242386
77 25113 0.11977166682481766
78 25113 0.12657372653484344
79 25113 0.12292996048927307
80 25113 0.07686104625463486
81 25113 0.08515310287475586
82 25113 0.07884795218706131
83 25113 0.0819263756275177
84 25113 0.09313969314098358
85 25113 0.10096286982297897
86 25113 0.0739215537905693
87 25113 0.0841543972492218
88 25113 0.08633362501859665
89 25113 0.09615086764097214
90 25113 0.0737672969698906
91 25113 0.09285825490951538
92 25113 0.09612072259187698
93 25113 0.12750646471977234
94 25113 0.08149552345275879
95 25113 0.09103220701217651
96 25113 0.09323444962501526
97 25113 0.09754738956689835
98 25113 0.0972939059138298
99 25113 0.14525313675403595
100 25113 0.16000759601593018
101 25113 0.09795277565717697
102 25113 0.09261468797922134
103 25113 0.09215143322944641
104 25113 0.08619563281536102
105 25113 0.08129715174436569
106 25113 0.0831105187535286
107 25113 0.06840620934963226
108 25113 0.07727926969528198
109 25113 0.12778408825397491
110 25113 0.08426138013601303
111 25113 0.0613434873521328
112 25113 0.057114601135253906
113 25113 0.06227709352970123
114 25113 0.06424394994974136
115 25113 0.06845086067914963
116 25113 0.11452444642782211
117 25113 0.11280451714992523
118 25113 0.0962430089712143
119 25113 0.08352643996477127
120 25113 0.09481483697891235
121 25113 0.06451787054538727
122 25113 0.09334436058998108
123 25113 0.0939173772931099
124 25113 0.07329696416854858
125 25113 0.07708685845136642
train - Global loss: 0.095516    Embedding norm: 1.0000   Triplets (all/active): 199.3/7530.8
Pos dist (min/mean/max): 0.4867/0.7779/1.1397   Neg dist (min/mean/max): 0.9274/1.4079/1.7486
0 1011 0.19795599579811096
1 1011 0.1774311661720276
2 1011 0.21200858056545258
3 1011 0.19179078936576843
4 1011 0.24444052577018738
5 1011 0.15662622451782227
val - Global loss: 0.196709    Embedding norm: 1.0000   Triplets (all/active): 168.5/19880.2
Pos dist (min/mean/max): 0.5727/0.8298/1.1290   Neg dist (min/mean/max): 0.5405/1.2264/1.6463
0 25113 0.09867554157972336
1 25113 0.09368789941072464
2 25113 0.09245511889457703
3 25113 0.1086137443780899
4 25113 0.13698990643024445
5 25113 0.10977423191070557
6 25113 0.08438420295715332
7 25113 0.07476526498794556
8 25113 0.07149050384759903
9 25113 0.062154218554496765
10 25113 0.1176047995686531
11 25113 0.07595525681972504
12 25113 0.08541766554117203
13 25113 0.0784066691994667
14 25113 0.0830804780125618
15 25113 0.05061068758368492
16 25113 0.09892388433218002
17 25113 0.0806528851389885
18 25113 0.06991491466760635
19 25113 0.07098320871591568
20 25113 0.0796474739909172
21 25113 0.06852428615093231
22 25113 0.11847878992557526
23 25113 0.07124272733926773
24 25113 0.10917149484157562
25 25113 0.09935366362333298
26 25113 0.0627785325050354
27 25113 0.08758707344532013
28 25113 0.0578203983604908
29 25113 0.11205343902111053
30 25113 0.12054428458213806
31 25113 0.08541315793991089
32 25113 0.10617468506097794
33 25113 0.09422263503074646
34 25113 0.0922468900680542
35 25113 0.07650606334209442
36 25113 0.06423967331647873
37 25113 0.09602372348308563
38 25113 0.11297829449176788
39 25113 0.07757630199193954
40 25113 0.09601064771413803
41 25113 0.08428288251161575
42 25113 0.05186111107468605
43 25113 0.08504525572061539
44 25113 0.07516611367464066
45 25113 0.10379405319690704
46 25113 0.08842373639345169
47 25113 0.09769763797521591
48 25113 0.10212907195091248
49 25113 0.0837402194738388
50 25113 0.09734948724508286
51 25113 0.07819566130638123
52 25113 0.10544651001691818
53 25113 0.10319076478481293
54 25113 0.07261564582586288
55 25113 0.08400458842515945
56 25113 0.10893207788467407
57 25113 0.09007050842046738
58 25113 0.0901038721203804
59 25113 0.06389544159173965
60 25113 0.05617431551218033
61 25113 0.06991942971944809
62 25113 0.09069421887397766
63 25113 0.10162033885717392
64 25113 0.10205090045928955
65 25113 0.0608101487159729
66 25113 0.06841062754392624
67 25113 0.09012322872877121
68 25113 0.11553706228733063
69 25113 0.09071175009012222
70 25113 0.10752525180578232
71 25113 0.19987329840660095
72 25113 0.0965166911482811
73 25113 0.08030617982149124
74 25113 0.08312540501356125
75 25113 0.06947282701730728
76 25113 0.13477177917957306
77 25113 0.11052962392568588
78 25113 0.07863563299179077
79 25113 0.06255058944225311
80 25113 0.0741853415966034
81 25113 0.09453771263360977
82 25113 0.11362432688474655
83 25113 0.07305577397346497
84 25113 0.09371579438447952
85 25113 0.08016834408044815
86 25113 0.09629668295383453
87 25113 0.059575360268354416
88 25113 0.07899962365627289
89 25113 0.09782324731349945
90 25113 0.07199686765670776
91 25113 0.05780601128935814
92 25113 0.08993882685899734
93 25113 0.1095774695277214
94 25113 0.07907546311616898
95 25113 0.07000064104795456
96 25113 0.07932063192129135
97 25113 0.11356703191995621
98 25113 0.08748726546764374
99 25113 0.11705255508422852
100 25113 0.09239411354064941
101 25113 0.06996507197618484
102 25113 0.07427135109901428
103 25113 0.06787288188934326
104 25113 0.07416895776987076
105 25113 0.07335489243268967
106 25113 0.10348055511713028
107 25113 0.07017956674098969
108 25113 0.06498219817876816
109 25113 0.08598418533802032
110 25113 0.08473794162273407
111 25113 0.07507184892892838
112 25113 0.09473717957735062
113 25113 0.07246141135692596
114 25113 0.07020159065723419
115 25113 0.05304505303502083
116 25113 0.10513715445995331
117 25113 0.09132388234138489
118 25113 0.10298576951026917
119 25113 0.08826839923858643
120 25113 0.11316094547510147
121 25113 0.06336876004934311
122 25113 0.08145304769277573
123 25113 0.11266061663627625
124 25113 0.055445101112127304
125 25113 0.08447227627038956
train - Global loss: 0.087551    Embedding norm: 1.0000   Triplets (all/active): 199.3/5967.1
Pos dist (min/mean/max): 0.4745/0.7579/1.0967   Neg dist (min/mean/max): 0.9211/1.4079/1.7492
0 1011 0.19014370441436768
1 1011 0.1611103117465973
2 1011 0.22114045917987823
3 1011 0.1582832932472229
4 1011 0.2859843373298645
5 1011 0.23572440445423126
val - Global loss: 0.208731    Embedding norm: 1.0000   Triplets (all/active): 168.5/20703.2
Pos dist (min/mean/max): 0.5653/0.8171/1.1616   Neg dist (min/mean/max): 0.5202/1.1608/1.6554
0 25113 0.09343162178993225
1 25113 0.09573766589164734
2 25113 0.10126297175884247
3 25113 0.07443555444478989
4 25113 0.08261119574308395
5 25113 0.11653817445039749
6 25113 0.07495758682489395
7 25113 0.08659292757511139
8 25113 0.09314323961734772
9 25113 0.06742945313453674
10 25113 0.08053358644247055
11 25113 0.051033150404691696
12 25113 0.07030387967824936
13 25113 0.07178517431020737
14 25113 0.09030120074748993
15 25113 0.05221179500222206
16 25113 0.07342305779457092
17 25113 0.09042129665613174
18 25113 0.05292011797428131
19 25113 0.07948610186576843
20 25113 0.08164403587579727
21 25113 0.09696242213249207
22 25113 0.09499047696590424
23 25113 0.07651044428348541
24 25113 0.07037410885095596
25 25113 0.06670553237199783
26 25113 0.0613429881632328
27 25113 0.09614892303943634
28 25113 0.09058309346437454
29 25113 0.09686986356973648
30 25113 0.0775798037648201
31 25113 0.04050714895129204
32 25113 0.09812869876623154
33 25113 0.09365306794643402
34 25113 0.08129989355802536
35 25113 0.05383880436420441
36 25113 0.05905045568943024
37 25113 0.0480317585170269
38 25113 0.09163150191307068
39 25113 0.08113270998001099
40 25113 0.07742288708686829
41 25113 0.057423364371061325
42 25113 0.05896865576505661
43 25113 0.11282895505428314
44 25113 0.08453372865915298
45 25113 0.09313282370567322
46 25113 0.07754845917224884
47 25113 0.08736347407102585
48 25113 0.08538194745779037
49 25113 0.08306405693292618
50 25113 0.07813190668821335
51 25113 0.05896996706724167
52 25113 0.08083419501781464
53 25113 0.08573346585035324
54 25113 0.07332929223775864
55 25113 0.11018675565719604
56 25113 0.08782698214054108
57 25113 0.06664127856492996
58 25113 0.04472215101122856
59 25113 0.03556317836046219
60 25113 0.06261786818504333
61 25113 0.08254747837781906
62 25113 0.0719488337635994
63 25113 0.0949140191078186
64 25113 0.10170254111289978
65 25113 0.03558163344860077
66 25113 0.07953596115112305
67 25113 0.09540144354104996
68 25113 0.10650061815977097
69 25113 0.09519849717617035
70 25113 0.05801268294453621
71 25113 0.14922969043254852
72 25113 0.041103266179561615
73 25113 0.07131028920412064
74 25113 0.08677519112825394
75 25113 0.1033802330493927
76 25113 0.0731985867023468
77 25113 0.10274314880371094
78 25113 0.10017894208431244
79 25113 0.05222921445965767
80 25113 0.06368862837553024
81 25113 0.05582888796925545
82 25113 0.09275190532207489
83 25113 0.06908772140741348
84 25113 0.09689219295978546
85 25113 0.11159783601760864
86 25113 0.08507964760065079
87 25113 0.06410481035709381
88 25113 0.056176137179136276
89 25113 0.12068678438663483
90 25113 0.0639062225818634
91 25113 0.10638909786939621
92 25113 0.0727357417345047
93 25113 0.11667169630527496
94 25113 0.06841573864221573
95 25113 0.0780821442604065
96 25113 0.06109793484210968
97 25113 0.07355024665594101
98 25113 0.10115477442741394
99 25113 0.1225128173828125
100 25113 0.12019169330596924
101 25113 0.07054983079433441
102 25113 0.049539294093847275
103 25113 0.04397507756948471
104 25113 0.08358360081911087
105 25113 0.07105066627264023
106 25113 0.08481854200363159
107 25113 0.06456020474433899
108 25113 0.08738810569047928
109 25113 0.10361924767494202
110 25113 0.07497388124465942
111 25113 0.06847348064184189
112 25113 0.1029927060008049
113 25113 0.03593619167804718
114 25113 0.07072348147630692
115 25113 0.0757075622677803
116 25113 0.097193643450737
117 25113 0.08526989072561264
118 25113 0.07998034358024597
119 25113 0.06937462836503983
120 25113 0.102701336145401
121 25113 0.055405642837285995
122 25113 0.08576148003339767
123 25113 0.083067387342453
124 25113 0.07085604220628738
125 25113 0.07985290884971619
train - Global loss: 0.079819    Embedding norm: 1.0000   Triplets (all/active): 199.3/4870.8
Pos dist (min/mean/max): 0.4661/0.7452/1.0785   Neg dist (min/mean/max): 0.9479/1.4085/1.7405
0 1011 0.19339394569396973
1 1011 0.20181244611740112
2 1011 0.1948612481355667
3 1011 0.1998867392539978
4 1011 0.24009789526462555
5 1011 0.2127598524093628
val - Global loss: 0.207135    Embedding norm: 1.0000   Triplets (all/active): 168.5/21864.7
Pos dist (min/mean/max): 0.5685/0.8330/1.1763   Neg dist (min/mean/max): 0.5781/1.2126/1.6740
0 25113 0.09134245663881302
1 25113 0.07006660103797913
2 25113 0.07805240154266357
3 25113 0.08273191004991531
4 25113 0.07345451414585114
5 25113 0.09217070788145065
6 25113 0.10167477279901505
7 25113 0.06747323274612427
8 25113 0.0630614310503006
9 25113 0.07144005596637726
10 25113 0.05461970716714859
11 25113 0.07642798870801926
12 25113 0.09044566750526428
13 25113 0.06789727509021759
14 25113 0.08348292857408524
15 25113 0.10047705471515656
16 25113 0.09110630303621292
17 25113 0.08448653668165207
18 25113 0.03456021100282669
19 25113 0.07449178397655487
20 25113 0.07535935193300247
21 25113 0.04606069251894951
22 25113 0.08482708781957626
23 25113 0.08028207719326019
24 25113 0.07875999808311462
25 25113 0.05008856579661369
26 25113 0.07011474668979645
27 25113 0.06326707452535629
28 25113 0.05799398943781853
29 25113 0.10163700580596924
30 25113 0.08330303430557251
31 25113 0.05012122914195061
32 25113 0.0696360170841217
33 25113 0.0760929137468338
34 25113 0.08451439440250397
35 25113 0.057272616773843765
36 25113 0.06446029245853424
37 25113 0.06862491369247437
38 25113 0.07778392732143402
39 25113 0.07025131583213806
40 25113 0.0720323845744133
41 25113 0.0442541241645813
42 25113 0.06305599212646484
43 25113 0.06662006676197052
44 25113 0.07018962502479553
45 25113 0.08866964280605316
46 25113 0.08264873176813126
47 25113 0.07575302571058273
48 25113 0.08507731556892395
49 25113 0.1023835763335228
50 25113 0.0945589616894722
51 25113 0.029932940378785133
52 25113 0.0840008407831192
53 25113 0.09020654112100601
54 25113 0.048114195466041565
55 25113 0.09327037632465363
56 25113 0.09562025964260101
57 25113 0.0647219866514206
58 25113 0.05853898078203201
59 25113 0.02649664133787155
60 25113 0.034004513174295425
61 25113 0.08387304842472076
62 25113 0.08475644141435623
63 25113 0.086032435297966
64 25113 0.10606248676776886
65 25113 0.060124315321445465
66 25113 0.03530040383338928
67 25113 0.06850604712963104
68 25113 0.10270155221223831
69 25113 0.07996939867734909
70 25113 0.08727949112653732
71 25113 0.13659512996673584
72 25113 0.06583573669195175
73 25113 0.07223163545131683
74 25113 0.08918508142232895
75 25113 0.09765993058681488
76 25113 0.06912490725517273
77 25113 0.11696165800094604
78 25113 0.08548115193843842
79 25113 0.07965308427810669
80 25113 0.05017352104187012
81 25113 0.043843042105436325
82 25113 0.0683211237192154
83 25113 0.04301365837454796
84 25113 0.0737181305885315
85 25113 0.08897753804922104
86 25113 0.042810071259737015
87 25113 0.06349527835845947
88 25113 0.09238777309656143
89 25113 0.07787324488162994
90 25113 0.07347438484430313
91 25113 0.05427323281764984
92 25113 0.07899071276187897
93 25113 0.1059412807226181
94 25113 0.07773422449827194
95 25113 0.051256682723760605
96 25113 0.07823840528726578
97 25113 0.1022850051522255
98 25113 0.06586766988039017
99 25113 0.10651161521673203
100 25113 0.10320651531219482
101 25113 0.06324082612991333
102 25113 0.0469486266374588
103 25113 0.056075841188430786
104 25113 0.03925357386469841
105 25113 0.03964531049132347
106 25113 0.06550410389900208
107 25113 0.026321513578295708
108 25113 0.06482817977666855
109 25113 0.09963417053222656
110 25113 0.06015637516975403
111 25113 0.06505857408046722
112 25113 0.06429796665906906
113 25113 0.04122697189450264
114 25113 0.09508127719163895
115 25113 0.07601901888847351
116 25113 0.08041246980428696
117 25113 0.1328319013118744
118 25113 0.06905796378850937
119 25113 0.11368413269519806
120 25113 0.09449435025453568
121 25113 0.08507994562387466
122 25113 0.10423852503299713
123 25113 0.08480840921401978
124 25113 0.05722961947321892
125 25113 0.08731082081794739
train - Global loss: 0.074542    Embedding norm: 1.0000   Triplets (all/active): 199.3/4409.8
Pos dist (min/mean/max): 0.4646/0.7383/1.0619   Neg dist (min/mean/max): 0.9591/1.4080/1.7421
0 1011 0.21555450558662415
1 1011 0.24072858691215515
2 1011 0.22564129531383514
3 1011 0.23188287019729614
4 1011 0.23713891208171844
5 1011 0.36763226985931396
val - Global loss: 0.253096    Embedding norm: 1.0000   Triplets (all/active): 168.5/22775.8
Pos dist (min/mean/max): 0.6299/0.9769/1.3470   Neg dist (min/mean/max): 0.6485/1.2959/1.6688
0 25113 0.09313147515058517
1 25113 0.10005734860897064
2 25113 0.07216586917638779
3 25113 0.06607037037611008
4 25113 0.10907667130231857
5 25113 0.09075748920440674
6 25113 0.08100329339504242
7 25113 0.08732076734304428
8 25113 0.09276606142520905
9 25113 0.07868154346942902
10 25113 0.10594493895769119
11 25113 0.07153297960758209
12 25113 0.0870668962597847
13 25113 0.04014136269688606
14 25113 0.08613552153110504
15 25113 0.0550718680024147
16 25113 0.056694529950618744
17 25113 0.06913834065198898
18 25113 0.09575449675321579
19 25113 0.04065466672182083
20 25113 0.08545922487974167
21 25113 0.06077016890048981
22 25113 0.07781662791967392
23 25113 0.0631849393248558
24 25113 0.06866264343261719
25 25113 0.06808186322450638
26 25113 0.07186376303434372
27 25113 0.07176588475704193
28 25113 0.04029655084013939
29 25113 0.11019108444452286
30 25113 0.08094752579927444
31 25113 0.08315567672252655
32 25113 0.12050765007734299
33 25113 0.043226633220911026
34 25113 0.08226516842842102
35 25113 0.07142691314220428
36 25113 0.03967641666531563
37 25113 0.04907766357064247
38 25113 0.07827732712030411
39 25113 0.0405023917555809
40 25113 0.07579614222049713
41 25113 0.07190892100334167
42 25113 0.04369049519300461
43 25113 0.05953005701303482
44 25113 0.0716283768415451
45 25113 0.06939071416854858
46 25113 0.09212309867143631
47 25113 0.09089252352714539
48 25113 0.0759790912270546
49 25113 0.08280450850725174
50 25113 0.10403167456388474
51 25113 0.07843412458896637
52 25113 0.08535168319940567
53 25113 0.08313403278589249
54 25113 0.0797763541340828
55 25113 0.07856667786836624
56 25113 0.07654856145381927
57 25113 0.07621598243713379
58 25113 0.0773070901632309
59 25113 0.14330115914344788
60 25113 0.0884184017777443
61 25113 0.07138723134994507
62 25113 0.08160043507814407
63 25113 0.06980418413877487
64 25113 0.09163573384284973
65 25113 0.024971848353743553
66 25113 0.08218013495206833
67 25113 0.1288364678621292
68 25113 0.058530908077955246
69 25113 0.06376907974481583
70 25113 0.07391109317541122
71 25113 0.13739243149757385
72 25113 0.0501328743994236
73 25113 0.08768733590841293
74 25113 0.09170457720756531
75 25113 0.06661336869001389
76 25113 0.07360026985406876
77 25113 0.09257011115550995
78 25113 0.08339570462703705
79 25113 0.048132505267858505
80 25113 0.061355993151664734
81 25113 0.06863032281398773
82 25113 0.09947551041841507
83 25113 0.08535598963499069
84 25113 0.0932072103023529
85 25113 0.08858505636453629
86 25113 0.04326530918478966
87 25113 0.039272841066122055
88 25113 0.06324420869350433
89 25113 0.07707367837429047
90 25113 0.0473954863846302
91 25113 0.05278325825929642
92 25113 0.05597285181283951
93 25113 0.08958331495523453
94 25113 0.06644561886787415
95 25113 0.05327056720852852
96 25113 0.08477136492729187
97 25113 0.08923131227493286
98 25113 0.08036943525075912
99 25113 0.10517784208059311
100 25113 0.10517048090696335
101 25113 0.08730752021074295
102 25113 0.07835617661476135
103 25113 0.06508725881576538
104 25113 0.07009885460138321
105 25113 0.10459332168102264
106 25113 0.08515778928995132
107 25113 0.05748378485441208
108 25113 0.05164547264575958
109 25113 0.11075687408447266
110 25113 0.06080731004476547
111 25113 0.04287205636501312
112 25113 0.06381060183048248
113 25113 0.05359167233109474
114 25113 0.06773500144481659
115 25113 0.0596344880759716
116 25113 0.08817316591739655
117 25113 0.08107591420412064
118 25113 0.06587515771389008
119 25113 0.09017378836870193
120 25113 0.07597918063402176
121 25113 0.059092991054058075
122 25113 0.09253060817718506
123 25113 0.07594083994626999
124 25113 0.05870864912867546
125 25113 0.08513420075178146
train - Global loss: 0.075796    Embedding norm: 1.0000   Triplets (all/active): 199.3/4001.5
Pos dist (min/mean/max): 0.4571/0.7295/1.0532   Neg dist (min/mean/max): 0.9537/1.4087/1.7364
0 1011 0.18228694796562195
1 1011 0.16732394695281982
2 1011 0.21171118319034576
3 1011 0.18502376973628998
4 1011 0.29264742136001587
5 1011 0.25196531414985657
val - Global loss: 0.215160    Embedding norm: 1.0000   Triplets (all/active): 168.5/18216.0
Pos dist (min/mean/max): 0.5430/0.8311/1.1656   Neg dist (min/mean/max): 0.5421/1.2211/1.6246
0 25113 0.07899768650531769
1 25113 0.08947985619306564
2 25113 0.07517493516206741
3 25113 0.08033566921949387
4 25113 0.10346245765686035
5 25113 0.09185202419757843
6 25113 0.05938097462058067
7 25113 0.11228072643280029
8 25113 0.06086287647485733
9 25113 0.08608676493167877
10 25113 0.07625751197338104
11 25113 0.05465435981750488
12 25113 0.05568220466375351
13 25113 0.04703108221292496
14 25113 0.06781072914600372
15 25113 0.06553914397954941
16 25113 0.11101464927196503
17 25113 0.07389549165964127
18 25113 0.05551401525735855
19 25113 0.09344613552093506
20 25113 0.07061571627855301
21 25113 0.07175289839506149
22 25113 0.10916510969400406
23 25113 0.051386818289756775
24 25113 0.07305588573217392
25 25113 0.04968322068452835
26 25113 0.06477873027324677
27 25113 0.07812893390655518
28 25113 0.07977688312530518
29 25113 0.09725940972566605
30 25113 0.07890471816062927
31 25113 0.06103748083114624
32 25113 0.07797220349311829
33 25113 0.048277597874403
34 25113 0.08821167796850204
35 25113 0.05305786058306694
36 25113 0.05717121809720993
37 25113 0.04929545149207115
38 25113 0.08203866332769394
39 25113 0.07328178733587265
40 25113 0.11289756000041962
41 25113 0.031148485839366913
42 25113 0.07286768406629562
43 25113 0.02916516363620758
44 25113 0.07174717634916306
45 25113 0.08281634747982025
46 25113 0.06285907328128815
47 25113 0.0871618390083313
48 25113 0.10355395823717117
49 25113 0.075595922768116
50 25113 0.0955861434340477
51 25113 0.07138192653656006
52 25113 0.05512559786438942
53 25113 0.0743195042014122
54 25113 0.05276265740394592
55 25113 0.10220294445753098
56 25113 0.08039626479148865
57 25113 0.09340038895606995
58 25113 0.05024709552526474
59 25113 0.0640445202589035
60 25113 0.03829285502433777
61 25113 0.05001997947692871
62 25113 0.06485455483198166
63 25113 0.11245713382959366
64 25113 0.0911535695195198
65 25113 0.051887355744838715
66 25113 0.08884470164775848
67 25113 0.07753979414701462
68 25113 0.08224818855524063
69 25113 0.060450177639722824
70 25113 0.046807173639535904
71 25113 0.14023883640766144
72 25113 0.04797566309571266
73 25113 0.05371581390500069
74 25113 0.04553118348121643
75 25113 0.04800568148493767
76 25113 0.06437402963638306
77 25113 0.057506807148456573
78 25113 0.04794345051050186
79 25113 0.029824620112776756
80 25113 0.045121610164642334
81 25113 0.05982839688658714
82 25113 0.09277071803808212
83 25113 0.0897451862692833
84 25113 0.07688668370246887
85 25113 0.07951182872056961
86 25113 0.04262698441743851
87 25113 0.052734531462192535
88 25113 0.09470700472593307
89 25113 0.11467438191175461
90 25113 0.06527727842330933
91 25113 0.04852086305618286
92 25113 0.062179084867239
93 25113 0.0898190513253212
94 25113 0.08290410786867142
95 25113 0.059865597635507584
96 25113 0.06296160072088242
97 25113 0.060748957097530365
98 25113 0.0700610876083374
99 25113 0.09237021952867508
100 25113 0.07029234617948532
101 25113 0.0782909020781517
102 25113 0.051665954291820526
103 25113 0.0683315247297287
104 25113 0.0712558850646019
105 25113 0.07921910285949707
106 25113 0.05565754324197769
107 25113 0.0788976326584816
108 25113 0.05845380946993828
109 25113 0.09675892442464828
110 25113 0.06935521960258484
111 25113 0.06276670098304749
112 25113 0.02121877297759056
113 25113 0.025789601728320122
114 25113 0.055545564740896225
115 25113 0.04351852461695671
116 25113 0.08367834240198135
117 25113 0.0683053731918335
118 25113 0.09459824860095978
119 25113 0.07528144866228104
120 25113 0.09214736521244049
121 25113 0.03481503203511238
122 25113 0.06372477114200592
123 25113 0.08623702824115753
124 25113 0.045452773571014404
125 25113 0.055523958057165146
train - Global loss: 0.070259    Embedding norm: 1.0000   Triplets (all/active): 199.3/3336.5
Pos dist (min/mean/max): 0.4517/0.7211/1.0462   Neg dist (min/mean/max): 0.9608/1.4085/1.7353
0 1011 0.18123048543930054
1 1011 0.1730307936668396
2 1011 0.21531890332698822
3 1011 0.17337994277477264
4 1011 0.24275091290473938
5 1011 0.23464669287204742
val - Global loss: 0.203393    Embedding norm: 1.0000   Triplets (all/active): 168.5/19788.3
Pos dist (min/mean/max): 0.6285/0.9172/1.2883   Neg dist (min/mean/max): 0.6526/1.2676/1.6717
0 25113 0.06140289828181267
1 25113 0.07864910364151001
2 25113 0.06394489109516144
3 25113 0.08519182354211807
4 25113 0.08162279427051544
5 25113 0.0891202762722969
6 25113 0.06793513149023056
7 25113 0.07352370023727417
8 25113 0.06262411922216415
9 25113 0.056071605533361435
10 25113 0.04401201382279396
11 25113 0.07970958948135376
12 25113 0.07000597566366196
13 25113 0.05629819631576538
14 25113 0.054296717047691345
15 25113 0.05153482407331467
16 25113 0.0340811163187027
17 25113 0.06585490703582764
18 25113 0.07377007603645325
19 25113 0.034397192299366
20 25113 0.060847897082567215
21 25113 0.08725521713495255
22 25113 0.067095085978508
23 25113 0.06398955732584
24 25113 0.0685342475771904
25 25113 0.05166709050536156
26 25113 0.06364157050848007
27 25113 0.07913456112146378
28 25113 0.0506250374019146
29 25113 0.08289889991283417
30 25113 0.06440950185060501
31 25113 0.11458075791597366
32 25113 0.09810318052768707
33 25113 0.042733099311590195
34 25113 0.07305941730737686
35 25113 0.10354148596525192
36 25113 0.047303032130002975
37 25113 0.06401384621858597
38 25113 0.08080609142780304
39 25113 0.04882921651005745
40 25113 0.10152769833803177
41 25113 0.06810133904218674
42 25113 0.0474848710000515
43 25113 0.07071329653263092
44 25113 0.060390908271074295
45 25113 0.09268059581518173
46 25113 0.06763926893472672
47 25113 0.060459911823272705
48 25113 0.09287101775407791
49 25113 0.07366085797548294
50 25113 0.0606684684753418
51 25113 0.05850580707192421
52 25113 0.07199636101722717
53 25113 0.08447116613388062
54 25113 0.045398980379104614
55 25113 0.08315561711788177
56 25113 0.07078658789396286
57 25113 0.04850392043590546
58 25113 0.059145499020814896
59 25113 0.03237634897232056
60 25113 0.0986776202917099
61 25113 0.08388227969408035
62 25113 0.06443168967962265
63 25113 0.08049514144659042
64 25113 0.1123792976140976
65 25113 0.035856906324625015
66 25113 0.06951670348644257
67 25113 0.1001892164349556
68 25113 0.08083326369524002
69 25113 0.07939552515745163
70 25113 0.06918915361166
71 25113 0.11812057346105576
72 25113 0.06746053695678711
73 25113 0.04191037639975548
74 25113 0.0759022980928421
75 25113 0.09377311915159225
76 25113 0.049969568848609924
77 25113 0.0851774737238884
78 25113 0.07551878690719604
79 25113 0.044443994760513306
80 25113 0.06254842132329941
81 25113 0.060769956558942795
82 25113 0.09704502671957016
83 25113 0.05714612081646919
84 25113 0.09085315465927124
85 25113 0.09407953917980194
86 25113 0.049622781574726105
87 25113 0.07178115844726562
88 25113 0.1015547439455986
89 25113 0.09131812304258347
90 25113 0.018713491037487984
91 25113 0.028133956715464592
92 25113 0.069720558822155
93 25113 0.07193528860807419
94 25113 0.05735002085566521
95 25113 0.05520647391676903
96 25113 0.06762514263391495
97 25113 0.08658403158187866
98 25113 0.076490618288517
99 25113 0.07052513211965561
100 25113 0.09290535002946854
101 25113 0.09299787878990173
102 25113 0.03818223997950554
103 25113 0.02429070509970188
104 25113 0.05953827500343323
105 25113 0.05390508472919464
106 25113 0.05690925568342209
107 25113 0.07188216596841812
108 25113 0.05809762701392174
109 25113 0.07520947605371475
110 25113 0.0914836972951889
111 25113 0.04677286744117737
112 25113 0.060696713626384735
113 25113 0.0647447407245636
114 25113 0.08018127828836441
115 25113 0.03073524869978428
116 25113 0.06495837867259979
117 25113 0.08117589354515076
118 25113 0.057424236088991165
119 25113 0.10427167266607285
120 25113 0.0723288282752037
121 25113 0.07173079997301102
122 25113 0.055077362805604935
123 25113 0.08680129051208496
124 25113 0.06781989336013794
125 25113 0.08779682219028473
train - Global loss: 0.069061    Embedding norm: 1.0000   Triplets (all/active): 199.3/2905.5
Pos dist (min/mean/max): 0.4501/0.7156/1.0280   Neg dist (min/mean/max): 0.9726/1.4085/1.7336
0 1011 0.18939931690692902
1 1011 0.19214551150798798
2 1011 0.23320919275283813
3 1011 0.18722182512283325
4 1011 0.2679843604564667
5 1011 0.10338285565376282
val - Global loss: 0.195557    Embedding norm: 1.0000   Triplets (all/active): 168.5/20942.0
Pos dist (min/mean/max): 0.6146/0.9153/1.2014   Neg dist (min/mean/max): 0.6391/1.2802/1.6488
0 25113 0.09078904241323471
1 25113 0.0742529109120369
2 25113 0.08641626685857773
3 25113 0.06000613421201706
4 25113 0.08239571005105972
5 25113 0.08706344664096832
6 25113 0.06654215604066849
7 25113 0.014246170409023762
8 25113 0.05926608666777611
9 25113 0.0259296465665102
10 25113 0.07419365644454956
11 25113 0.04411741718649864
12 25113 0.09725452214479446
13 25113 0.04715151712298393
14 25113 0.0870201587677002
15 25113 0.07836782187223434
16 25113 0.057800766080617905
17 25113 0.05901264771819115
18 25113 0.05054938793182373
19 25113 0.054937586188316345
20 25113 0.04985688254237175
21 25113 0.06676065176725388
22 25113 0.09136871248483658
23 25113 0.05615224689245224
24 25113 0.10307823866605759
25 25113 0.07770165055990219
26 25113 0.02459440566599369
27 25113 0.05184277519583702
28 25113 0.058101870119571686
29 25113 0.12170040607452393
30 25113 0.06633717566728592
31 25113 0.082134909927845
32 25113 0.06651987880468369
33 25113 0.07723154127597809
34 25113 0.09603239595890045
35 25113 0.06115849316120148
36 25113 0.07329807430505753
37 25113 0.07167870551347733
38 25113 0.09825266897678375
39 25113 0.03627447038888931
40 25113 0.08695849776268005
41 25113 0.08713355660438538
42 25113 0.05066930875182152
43 25113 0.11170190572738647
44 25113 0.06015053763985634
45 25113 0.069681815803051
46 25113 0.09351495653390884
47 25113 0.07414248585700989
48 25113 0.06917489320039749
49 25113 0.0646129697561264
50 25113 0.0880952998995781
51 25113 0.04924766719341278
52 25113 0.06439220905303955
53 25113 0.10283628851175308
54 25113 0.045045241713523865
55 25113 0.09200385957956314
56 25113 0.07283608615398407
57 25113 0.06629108637571335
58 25113 0.03208594024181366
59 25113 0.03124508447945118
60 25113 0.07380665838718414
61 25113 0.06388259679079056
62 25113 0.054166294634342194
63 25113 0.06253132224082947
64 25113 0.08298735320568085
65 25113 0.0681874081492424
66 25113 0.05398782342672348
67 25113 0.09558449685573578
68 25113 0.06726726144552231
69 25113 0.09931307286024094
70 25113 0.09748893231153488
71 25113 0.1262543648481369
72 25113 0.031556472182273865
73 25113 0.054320622235536575
74 25113 0.0772598460316658
75 25113 0.07631823420524597
76 25113 0.08745357394218445
77 25113 0.06552650779485703
78 25113 0.0871388167142868
79 25113 0.05798302963376045
80 25113 0.08411931991577148
81 25113 0.06185789778828621
82 25113 0.09278501570224762
83 25113 0.07270260155200958
84 25113 0.0832769051194191
85 25113 0.0629299208521843
86 25113 0.06521613150835037
87 25113 0.03476579859852791
88 25113 0.09991460293531418
89 25113 0.08518366515636444
90 25113 0.06611178070306778
91 25113 0.03446923941373825
92 25113 0.08293849229812622
93 25113 0.0830719843506813
94 25113 0.07162079215049744
95 25113 0.08702927827835083
96 25113 0.06715013086795807
97 25113 0.05204591155052185
98 25113 0.06013309583067894
99 25113 0.08345365524291992
100 25113 0.07163761556148529
101 25113 0.06998151540756226
102 25113 0.074395090341568
103 25113 0.04665178060531616
104 25113 0.059235770255327225
105 25113 0.07472718507051468
106 25113 0.06675656884908676
107 25113 0.04171241819858551
108 25113 0.0710359439253807
109 25113 0.06520897895097733
110 25113 0.04857944697141647
111 25113 0.05799438804388046
112 25113 0.06942848116159439
113 25113 0.03745017945766449
114 25113 0.09095940738916397
115 25113 0.04860338568687439
116 25113 0.08815895766019821
117 25113 0.08567583560943604
118 25113 0.0859759971499443
119 25113 0.07263147085905075
120 25113 0.0644640251994133
121 25113 0.13321949541568756
122 25113 0.07439780235290527
123 25113 0.054731335490942
124 25113 0.16667045652866364
125 25113 0.0666632130742073
train - Global loss: 0.070952    Embedding norm: 1.0000   Triplets (all/active): 199.3/2739.3
Pos dist (min/mean/max): 0.4448/0.7080/1.0306   Neg dist (min/mean/max): 0.9750/1.4085/1.7320
0 1011 0.19836297631263733
1 1011 0.20798331499099731
2 1011 0.2038644254207611
3 1011 0.18101154267787933
4 1011 0.28280922770500183
5 1011 0.18838149309158325
val - Global loss: 0.210402    Embedding norm: 1.0000   Triplets (all/active): 168.5/19964.5
Pos dist (min/mean/max): 0.6071/0.9288/1.2261   Neg dist (min/mean/max): 0.6693/1.3201/1.6972
0 25113 0.09592606872320175
1 25113 0.09016236662864685
2 25113 0.07545934617519379
3 25113 0.06348975002765656
4 25113 0.07269579917192459
5 25113 0.07737617939710617
6 25113 0.0835193321108818
7 25113 0.0332624576985836
8 25113 0.06482977420091629
9 25113 0.0659165233373642
10 25113 0.05409611761569977
11 25113 0.07397273927927017
12 25113 0.07820124179124832
13 25113 0.047703880816698074
14 25113 0.06246073544025421
15 25113 0.06644462794065475
16 25113 0.08180338889360428
17 25113 0.06570963561534882
18 25113 0.061483174562454224
19 25113 0.02681596577167511
20 25113 0.0407341793179512
21 25113 0.03481069579720497
22 25113 0.06543184071779251
23 25113 0.0596613734960556
24 25113 0.0664379894733429
25 25113 0.043399959802627563
26 25113 0.04613475129008293
27 25113 0.08258697390556335
28 25113 0.030843336135149002
29 25113 0.14513559639453888
30 25113 0.08574516326189041
31 25113 0.09342124313116074
32 25113 0.16084028780460358
33 25113 0.06743070483207703
34 25113 0.07000529021024704
35 25113 0.06746693700551987
36 25113 0.05882946401834488
37 25113 0.09014269709587097
38 25113 0.08857881277799606
39 25113 0.06421656161546707
40 25113 0.07148456573486328
41 25113 0.03951451554894447
42 25113 0.04632675647735596
43 25113 0.07148624211549759
44 25113 0.051576342433691025
45 25113 0.0647825300693512
46 25113 0.0500175766646862
47 25113 0.09107141941785812
48 25113 0.08317898958921432
49 25113 0.07770081609487534
50 25113 0.07493895292282104
51 25113 0.05470394715666771
52 25113 0.057550203055143356
53 25113 0.07600753754377365
54 25113 0.059336550533771515
55 25113 0.08382447808980942
56 25113 0.08253522962331772
57 25113 0.05129911005496979
58 25113 0.028711333870887756
59 25113 0.037868428975343704
60 25113 0.03424657881259918
61 25113 0.07604757696390152
62 25113 0.07875964045524597
63 25113 0.0672934502363205
64 25113 0.09374712407588959
65 25113 0.03483811393380165
66 25113 0.054970137774944305
67 25113 0.08505827188491821
68 25113 0.07241927832365036
69 25113 0.05573417618870735
70 25113 0.07811139523983002
71 25113 0.124369777739048
72 25113 0.04650259017944336
73 25113 0.054723579436540604
74 25113 0.06056934967637062
75 25113 0.0519709438085556
76 25113 0.11631079018115997
77 25113 0.0683286041021347
78 25113 0.05893959850072861
79 25113 0.08824536949396133
80 25113 0.04358415678143501
81 25113 0.044037554413080215
82 25113 0.06204526126384735
83 25113 0.08372320979833603
84 25113 0.06257545948028564
85 25113 0.09700458496809006
86 25113 0.04947585612535477
87 25113 0.04118918254971504
88 25113 0.10025855898857117
89 25113 0.08996489644050598
90 25113 0.053002264350652695
91 25113 0.058596108108758926
92 25113 0.05192842334508896
93 25113 0.0765497088432312
94 25113 0.06882896274328232
95 25113 0.06688671559095383
96 25113 0.04350162670016289
97 25113 0.08868028223514557
98 25113 0.050689924508333206
99 25113 0.07022576034069061
100 25113 0.056523337960243225
101 25113 0.06749355047941208
102 25113 0.05461915582418442
103 25113 0.0626273825764656
104 25113 0.06805349141359329
105 25113 0.031817853450775146
106 25113 0.0699242651462555
107 25113 0.05963583290576935
108 25113 0.03239704295992851
109 25113 0.05626511946320534
110 25113 0.0521056205034256
111 25113 0.03526155650615692
112 25113 0.043803244829177856
113 25113 0.03723791241645813
114 25113 0.039703257381916046
115 25113 0.036758903414011
116 25113 0.0798230990767479
117 25113 0.08260764181613922
118 25113 0.07393231987953186
119 25113 0.06360601633787155
120 25113 0.03500010073184967
121 25113 0.061722107231616974
122 25113 0.05240650102496147
123 25113 0.0789625346660614
124 25113 0.06501976400613785
125 25113 0.08226639777421951
train - Global loss: 0.065402    Embedding norm: 1.0000   Triplets (all/active): 199.3/2331.9
Pos dist (min/mean/max): 0.4405/0.6978/1.0050   Neg dist (min/mean/max): 0.9697/1.4081/1.7337
0 1011 0.21663972735404968
1 1011 0.192073255777359
2 1011 0.20377127826213837
3 1011 0.18138104677200317
4 1011 0.26128295063972473
5 1011 0.1385415494441986
val - Global loss: 0.198948    Embedding norm: 1.0000   Triplets (all/active): 168.5/18184.0
Pos dist (min/mean/max): 0.5969/0.8821/1.2785   Neg dist (min/mean/max): 0.6161/1.2898/1.6581
0 25113 0.05363040417432785
1 25113 0.0736851617693901
2 25113 0.04792752489447594
3 25113 0.05511455982923508
4 25113 0.054809167981147766
5 25113 0.11909370124340057
6 25113 0.06445525586605072
7 25113 0.06309720128774643
8 25113 0.04859710484743118
9 25113 0.04100647196173668
10 25113 0.08898762613534927
11 25113 0.06114354357123375
12 25113 0.02924543432891369
13 25113 0.06904074549674988
14 25113 0.0651802346110344
15 25113 0.036381062120199203
16 25113 0.05980602279305458
17 25113 0.031753603368997574
18 25113 0.04809863865375519
19 25113 0.041734617203474045
20 25113 0.06581269204616547
21 25113 0.03223404288291931
22 25113 0.0893796980381012
23 25113 0.06085731089115143
24 25113 0.0605548657476902
25 25113 0.05596068874001503
26 25113 0.0532723031938076
27 25113 0.045506320893764496
28 25113 0.0743752047419548
29 25113 0.07174107432365417
30 25113 0.04696662351489067
31 25113 0.04894912615418434
32 25113 0.04713862016797066
33 25113 0.03005034662783146
34 25113 0.06778828054666519
35 25113 0.07801467180252075
36 25113 0.03236595168709755
37 25113 0.04559844359755516
38 25113 0.06375575065612793
39 25113 0.040124185383319855
40 25113 0.04257243126630783
41 25113 0.03403715044260025
42 25113 0.06791585683822632
43 25113 0.03671204298734665
44 25113 0.06546223908662796
45 25113 0.03209139406681061
46 25113 0.0558968186378479
47 25113 0.11415968090295792
48 25113 0.08123200386762619
49 25113 0.07223453372716904
50 25113 0.08576181530952454
51 25113 0.08288921415805817
52 25113 0.04269660636782646
53 25113 0.08473475277423859
54 25113 0.0967680811882019
55 25113 0.09130817651748657
56 25113 0.07546737045049667
57 25113 0.07551770657300949
58 25113 0.07119163125753403
59 25113 0.05417373403906822
60 25113 0.046499352902173996
61 25113 0.10129830986261368
62 25113 0.0807466208934784
63 25113 0.08730650693178177
64 25113 0.0891483798623085
65 25113 0.060408588498830795
66 25113 0.060144152492284775
67 25113 0.06265610456466675
68 25113 0.09360423684120178
69 25113 0.05164853483438492
70 25113 0.05724794417619705
71 25113 0.1285875290632248
72 25113 0.04708564653992653
73 25113 0.06184544414281845
74 25113 0.06005654111504555
75 25113 0.075063057243824
76 25113 0.03345181420445442
77 25113 0.06879550218582153
78 25113 0.08130515366792679
79 25113 0.057446639984846115
80 25113 0.040821969509124756
81 25113 0.027530856430530548
82 25113 0.04665661230683327
83 25113 0.03219426050782204
84 25113 0.06924758106470108
85 25113 0.07178958505392075
86 25113 0.04630688950419426
87 25113 0.055370353162288666
88 25113 0.03368312865495682
89 25113 0.110183484852314
90 25113 0.08009887486696243
91 25113 0.04197905212640762
92 25113 0.04176754131913185
93 25113 0.09365646541118622
94 25113 0.10148876905441284
95 25113 0.05045586824417114
96 25113 0.04333009570837021
97 25113 0.08551185578107834
98 25113 0.07097481936216354
99 25113 0.0727943405508995
100 25113 0.0913286805152893
101 25113 0.09616237133741379
102 25113 0.05441026762127876
103 25113 0.05646603927016258
104 25113 0.06634008139371872
105 25113 0.06449595838785172
106 25113 0.06143859401345253
107 25113 0.053393349051475525
108 25113 0.058112457394599915
109 25113 0.08812354505062103
110 25113 0.09707242995500565
111 25113 0.06255287677049637
112 25113 0.05994177609682083
113 25113 0.04922406002879143
114 25113 0.04664772376418114
115 25113 0.04345354065299034
116 25113 0.060867562890052795
117 25113 0.0761772021651268
118 25113 0.06509697437286377
119 25113 0.07926185429096222
120 25113 0.06366951018571854
121 25113 0.060684118419885635
122 25113 0.0627608448266983
123 25113 0.07332385331392288
124 25113 0.07120194286108017
125 25113 0.05136055499315262
train - Global loss: 0.063173    Embedding norm: 1.0000   Triplets (all/active): 199.3/2191.0
Pos dist (min/mean/max): 0.4456/0.6981/1.0122   Neg dist (min/mean/max): 0.9795/1.4084/1.7248
0 1011 0.19325892627239227
1 1011 0.18717171251773834
2 1011 0.18835440278053284
3 1011 0.1566070169210434
4 1011 0.2239832580089569
5 1011 0.1572914719581604
val - Global loss: 0.184444    Embedding norm: 1.0000   Triplets (all/active): 168.5/18913.2
Pos dist (min/mean/max): 0.6058/0.8947/1.2705   Neg dist (min/mean/max): 0.6701/1.2569/1.6453
0 25113 0.04750741273164749
1 25113 0.08637417107820511
2 25113 0.05757969245314598
3 25113 0.062460899353027344
4 25113 0.0585748516023159
5 25113 0.05081735923886299
6 25113 0.05190745368599892
7 25113 0.019842758774757385
8 25113 0.05675755813717842
9 25113 0.04152890667319298
10 25113 0.062434084713459015
11 25113 0.048537176102399826
12 25113 0.06173549219965935
13 25113 0.030851703137159348
14 25113 0.045134082436561584
15 25113 0.03837932273745537
16 25113 0.13598372042179108
17 25113 0.06521404534578323
18 25113 0.05507978796958923
19 25113 0.03421439602971077
20 25113 0.07066131383180618
21 25113 0.07726187258958817
22 25113 0.07410413771867752
23 25113 0.06042550876736641
24 25113 0.0733252763748169
25 25113 0.07991599291563034
26 25113 0.053232114762067795
27 25113 0.08348027616739273
28 25113 0.07816066592931747
29 25113 0.08760382235050201
30 25113 0.07797092199325562
31 25113 0.06064194440841675
32 25113 0.12194297462701797
33 25113 0.04625910520553589
34 25113 0.10231754928827286
35 25113 0.0616728700697422
36 25113 0.09608004987239838
37 25113 0.12055155634880066
38 25113 0.07811836898326874
39 25113 0.07392595708370209
40 25113 0.07097763568162918
41 25113 0.07648111134767532
42 25113 0.06171378493309021
43 25113 0.049501899629831314
44 25113 0.07584112882614136
45 25113 0.07696109265089035
46 25113 0.05001525953412056
47 25113 0.07494982331991196
48 25113 0.07182401418685913
49 25113 0.047222040593624115
50 25113 0.12576788663864136
51 25113 0.029844487085938454
52 25113 0.07462228089570999
53 25113 0.04274114966392517
54 25113 0.07850618660449982
55 25113 0.0906948372721672
56 25113 0.09328404068946838
57 25113 0.08925522118806839
58 25113 0.04253402352333069
59 25113 0.0339132621884346
60 25113 0.06598005443811417
61 25113 0.053321242332458496
62 25113 0.06101240962743759
63 25113 0.08818637579679489
64 25113 0.09532272815704346
65 25113 0.029064621776342392
66 25113 0.03518886864185333
67 25113 0.10933265835046768
68 25113 0.0687248632311821
69 25113 0.04207367077469826
70 25113 0.06384498625993729
71 25113 0.0949130728840828
72 25113 0.04434848204255104
73 25113 0.06280576437711716
74 25113 0.04358402267098427
75 25113 0.07770612090826035
76 25113 0.05262911319732666
77 25113 0.07636123895645142
78 25113 0.08016792684793472
79 25113 0.0402030348777771
80 25113 0.08739930391311646
81 25113 0.08140527456998825
82 25113 0.05615643784403801
83 25113 0.03739070147275925
84 25113 0.0585939921438694
85 25113 0.08368881046772003
86 25113 0.030610520392656326
87 25113 0.04139413684606552
88 25113 0.06546978652477264
89 25113 0.06994333118200302
90 25113 0.06532715260982513
91 25113 0.07579516619443893
92 25113 0.08005586266517639
93 25113 0.08561161905527115
94 25113 0.07196202129125595
95 25113 0.08157221227884293
96 25113 0.058300551027059555
97 25113 0.059844132512807846
98 25113 0.05815862864255905
99 25113 0.06837915629148483
100 25113 0.07749661058187485
101 25113 0.03812465816736221
102 25113 0.039978913962841034
103 25113 0.06248481199145317
104 25113 0.053650133311748505
105 25113 0.03696545213460922
106 25113 0.06907129287719727
107 25113 0.07769659906625748
108 25113 0.04352473095059395
109 25113 0.08248472213745117
110 25113 0.026475604623556137
111 25113 0.04429493844509125
112 25113 0.02033284306526184
113 25113 0.039996981620788574
114 25113 0.03181413561105728
115 25113 0.05593854933977127
116 25113 0.07910330593585968
117 25113 0.07194574177265167
118 25113 0.0440390408039093
119 25113 0.07400678843259811
120 25113 0.06784213334321976
121 25113 0.06411764025688171
122 25113 0.06391292065382004
123 25113 0.07814127206802368
124 25113 0.04575658217072487
125 25113 0.06387171149253845
train - Global loss: 0.064287    Embedding norm: 1.0000   Triplets (all/active): 199.3/2317.4
Pos dist (min/mean/max): 0.4469/0.6988/1.0151   Neg dist (min/mean/max): 0.9778/1.4087/1.7279
0 1011 0.14638175070285797
1 1011 0.1485111564397812
2 1011 0.19285644590854645
3 1011 0.1378898024559021
4 1011 0.21820858120918274
5 1011 0.19853466749191284
val - Global loss: 0.173730    Embedding norm: 1.0000   Triplets (all/active): 168.5/17210.0
Pos dist (min/mean/max): 0.6155/0.9026/1.2206   Neg dist (min/mean/max): 0.6522/1.3031/1.6714
0 25113 0.08297494798898697
1 25113 0.0761769637465477
2 25113 0.06254551559686661
3 25113 0.04810400679707527
4 25113 0.14493486285209656
5 25113 0.10211147367954254
6 25113 0.03030294179916382
7 25113 0.1528700441122055
8 25113 0.07185470312833786
9 25113 0.05726940929889679
10 25113 0.04827165603637695
11 25113 0.06134682521224022
12 25113 0.05265124887228012
13 25113 0.02798067033290863
14 25113 0.08705345541238785
15 25113 0.0285168569535017
16 25113 0.06312692165374756
17 25113 0.0298855472356081
18 25113 0.0699940025806427
19 25113 0.08551455289125443
20 25113 0.053169336169958115
21 25113 0.0568750761449337
22 25113 0.07924722135066986
23 25113 0.06689117848873138
24 25113 0.05951559916138649
25 25113 0.05999382957816124
26 25113 0.06088459864258766
27 25113 0.053910546004772186
28 25113 0.08142828196287155
29 25113 0.07796783000230789
30 25113 0.04196608066558838
31 25113 0.05570710822939873
32 25113 0.0780109316110611
33 25113 0.06304578483104706
34 25113 0.06866505742073059
35 25113 0.062346942722797394
36 25113 0.05564936250448227
37 25113 0.058358702808618546
38 25113 0.06384222209453583
39 25113 0.056896671652793884
40 25113 0.06427425891160965
41 25113 0.04308096319437027
42 25113 0.05219711363315582
43 25113 0.040446147322654724
44 25113 0.05027027428150177
45 25113 0.06207192316651344
46 25113 0.05074809864163399
47 25113 0.06809750199317932
48 25113 0.08167973905801773
49 25113 0.0699489563703537
50 25113 0.03720097243785858
51 25113 0.028324661776423454
52 25113 0.04301968216896057
53 25113 0.074945829808712
54 25113 0.030309349298477173
55 25113 0.086161769926548
56 25113 0.07432716339826584
57 25113 0.04490264505147934
58 25113 0.02440141886472702
59 25113 0.0247552040964365
60 25113 0.05048433318734169
61 25113 0.04031796753406525
62 25113 0.05739204213023186
63 25113 0.07140125334262848
64 25113 0.0854688286781311
65 25113 0.021108265966176987
66 25113 0.04901295527815819
67 25113 0.05099288746714592
68 25113 0.06406804919242859
69 25113 0.053285982459783554
70 25113 0.04875976964831352
71 25113 0.11314182728528976
72 25113 0.03171497955918312
73 25113 0.044343601912260056
74 25113 0.055366355925798416
75 25113 0.08675109595060349
76 25113 0.03739360719919205
77 25113 0.06930378824472427
78 25113 0.042566169053316116
79 25113 0.0643429160118103
80 25113 0.05148299038410187
81 25113 0.08442172408103943
82 25113 0.10854692757129669
83 25113 0.04439166188240051
84 25113 0.06453603506088257
85 25113 0.0764082595705986
86 25113 0.03687422722578049
87 25113 0.055541787296533585
88 25113 0.09706266224384308
89 25113 0.09216147661209106
90 25113 0.04801610857248306
91 25113 0.0404534637928009
92 25113 0.048222463577985764
93 25113 0.060830261558294296
94 25113 0.06852912902832031
95 25113 0.03732678294181824
96 25113 0.061930108815431595
97 25113 0.06536421179771423
98 25113 0.07716747373342514
99 25113 0.05725410580635071
100 25113 0.059866148978471756
101 25113 0.05031725764274597
102 25113 0.0348706990480423
103 25113 0.05263865366578102
104 25113 0.07610082626342773
105 25113 0.039295557886362076
106 25113 0.06985969096422195
107 25113 0.054269950836896896
108 25113 0.061723124235868454
109 25113 0.05167287960648537
110 25113 0.06919298321008682
111 25113 0.07075467705726624
112 25113 0.03176044300198555
113 25113 0.0727991908788681
114 25113 0.04912193864583969
115 25113 0.07125623524188995
116 25113 0.06806202977895737
117 25113 0.06356701999902725
118 25113 0.06184139847755432
119 25113 0.06661421805620193
120 25113 0.0676867887377739
121 25113 0.07501409947872162
122 25113 0.06853198260068893
123 25113 0.062147900462150574
124 25113 0.06158509850502014
125 25113 0.07132276892662048
train - Global loss: 0.060989    Embedding norm: 1.0000   Triplets (all/active): 199.3/1719.5
Pos dist (min/mean/max): 0.4300/0.6814/0.9946   Neg dist (min/mean/max): 0.9722/1.4086/1.7310
0 1011 0.21769264340400696
1 1011 0.1855519562959671
2 1011 0.2308957278728485
3 1011 0.18380029499530792
4 1011 0.28745371103286743
5 1011 0.19126324355602264
val - Global loss: 0.216110    Embedding norm: 1.0000   Triplets (all/active): 168.5/19202.3
Pos dist (min/mean/max): 0.6051/0.9052/1.2548   Neg dist (min/mean/max): 0.6048/1.2669/1.6552
0 25113 0.05709537863731384
1 25113 0.060275848954916
2 25113 0.06862304359674454
3 25113 0.060205210000276566
4 25113 0.06771405786275864
5 25113 0.036310672760009766
6 25113 0.07788310945034027
7 25113 0.04420727863907814
8 25113 0.06432248651981354
9 25113 0.06514281034469604
10 25113 0.044522725045681
11 25113 0.04374207556247711
12 25113 0.05471307784318924
13 25113 0.04923633113503456
14 25113 0.05174689367413521
15 25113 0.04431112855672836
16 25113 0.06113488972187042
17 25113 0.04052387923002243
18 25113 0.032809868454933167
19 25113 0.037169188261032104
20 25113 0.05689576268196106
21 25113 0.036730047315359116
22 25113 0.06535891443490982
23 25113 0.06541649997234344
24 25113 0.06373302638530731
25 25113 0.05883876234292984
26 25113 0.05477716401219368
27 25113 0.05496411398053169
28 25113 0.055306389927864075
29 25113 0.11417055130004883
30 25113 0.050970304757356644
31 25113 0.030270736664533615
32 25113 0.05334701016545296
33 25113 0.044434014707803726
34 25113 0.05196668952703476
35 25113 0.05067555233836174
36 25113 0.01628711074590683
37 25113 0.01816548779606819
38 25113 0.04032887518405914
39 25113 0.0912025198340416
40 25113 0.05150751397013664
41 25113 0.03566538915038109
42 25113 0.05610629543662071
43 25113 0.11156732589006424
44 25113 0.0679510086774826
45 25113 0.038867101073265076
46 25113 0.06711544096469879
47 25113 0.07435383647680283
48 25113 0.05627726390957832
49 25113 0.06710923463106155
50 25113 0.09128032624721527
51 25113 0.045617230236530304
52 25113 0.045705344527959824
53 25113 0.06367490440607071
54 25113 0.08361272513866425
55 25113 0.05829394608736038
56 25113 0.07295991480350494
57 25113 0.06882530450820923
58 25113 0.032648734748363495
59 25113 0.04357575252652168
60 25113 0.06962879747152328
61 25113 0.04090263694524765
62 25113 0.046775270253419876
63 25113 0.05320858955383301
64 25113 0.08181475102901459
65 25113 0.03566187992691994
66 25113 0.07283349335193634
67 25113 0.05552408844232559
68 25113 0.05622870475053787
69 25113 0.04769561067223549
70 25113 0.09182309359312057
71 25113 0.08585073053836823
72 25113 0.05262204632163048
73 25113 0.050859659910202026
74 25113 0.06168173998594284
75 25113 0.030235731974244118
76 25113 0.057400140911340714
77 25113 0.08504292368888855
78 25113 0.09073077142238617
79 25113 0.03485532104969025
80 25113 0.02506302483379841
81 25113 0.06022144854068756
82 25113 0.06381818652153015
83 25113 0.07648095488548279
84 25113 0.06738978624343872
85 25113 0.06896751374006271
86 25113 0.043826304376125336
87 25113 0.04630468785762787
88 25113 0.06796721369028091
89 25113 0.04083552584052086
90 25113 0.06191767007112503
91 25113 0.06659787148237228
92 25113 0.03809530287981033
93 25113 0.06760921329259872
94 25113 0.05286553129553795
95 25113 0.04075922816991806
96 25113 0.06701963394880295
97 25113 0.11310676485300064
98 25113 0.10032708197832108
99 25113 0.06466943770647049
100 25113 0.061167072504758835
101 25113 0.04720534384250641
102 25113 0.10078718513250351
103 25113 0.04670671001076698
104 25113 0.029075531288981438
105 25113 0.045725882053375244
106 25113 0.05114566907286644
107 25113 0.07563070952892303
108 25113 0.061187922954559326
109 25113 0.0811980664730072
110 25113 0.05806320160627365
111 25113 0.043186403810977936
112 25113 0.032948657870292664
113 25113 0.028946146368980408
114 25113 0.04783696308732033
115 25113 0.05109745264053345
116 25113 0.060604825615882874
117 25113 0.08382412791252136
118 25113 0.03612412512302399
119 25113 0.055014535784721375
120 25113 0.08030369132757187
121 25113 0.051860611885786057
122 25113 0.031756285578012466
123 25113 0.0835723876953125
124 25113 0.07197185605764389
125 25113 0.06986018270254135
train - Global loss: 0.057859    Embedding norm: 1.0000   Triplets (all/active): 199.3/1333.7
Pos dist (min/mean/max): 0.4313/0.6742/0.9752   Neg dist (min/mean/max): 0.9830/1.4089/1.7287
0 1011 0.17177540063858032
1 1011 0.1673055738210678
2 1011 0.20273904502391815
3 1011 0.19201944768428802
4 1011 0.2636403441429138
5 1011 0.1954277902841568
val - Global loss: 0.198818    Embedding norm: 1.0000   Triplets (all/active): 168.5/18440.5
Pos dist (min/mean/max): 0.6120/0.8893/1.2261   Neg dist (min/mean/max): 0.6405/1.3063/1.6633
0 25113 0.060213617980480194
1 25113 0.029968367889523506
2 25113 0.07386364042758942
3 25113 0.09158571064472198
4 25113 0.08919916301965714
5 25113 0.07472652196884155
6 25113 0.03908586874604225
7 25113 0.061681803315877914
8 25113 0.054901111871004105
9 25113 0.02206271141767502
10 25113 0.047162044793367386
11 25113 0.05501846596598625
12 25113 0.03907184675335884
13 25113 0.04080093279480934
14 25113 0.10171296447515488
15 25113 0.05828295275568962
16 25113 0.06159987673163414
17 25113 0.034428488463163376
18 25113 0.02638593316078186
19 25113 0.011786341667175293
20 25113 0.07220380008220673
21 25113 0.061932265758514404
22 25113 0.05752310901880264
23 25113 0.05074271932244301
24 25113 0.07432375848293304
25 25113 0.05492689833045006
26 25113 0.07568951696157455
27 25113 0.09645097702741623
28 25113 0.044803597033023834
29 25113 0.0911400243639946
30 25113 0.06845302879810333
31 25113 0.020319845527410507
32 25113 0.07501109689474106
33 25113 0.04886952042579651
34 25113 0.07865181565284729
35 25113 0.06069382280111313
36 25113 0.05868736654520035
37 25113 0.026148172095417976
38 25113 0.07319037616252899
39 25113 0.04487673565745354
40 25113 0.11581618338823318
41 25113 0.04191445931792259
42 25113 0.023705530911684036
43 25113 0.026235215365886688
44 25113 0.06251081079244614
45 25113 0.038346756249666214
46 25113 0.0640852078795433
47 25113 0.05594612658023834
48 25113 0.08030074089765549
49 25113 0.07145160436630249
50 25113 0.0811283215880394
51 25113 0.037916868925094604
52 25113 0.07006633281707764
53 25113 0.04227401688694954
54 25113 0.029320357367396355
55 25113 0.06348872184753418
56 25113 0.06323541700839996
57 25113 0.043638281524181366
58 25113 0.038584038615226746
59 25113 0.0471317283809185
60 25113 0.0495934821665287
61 25113 0.04810693487524986
62 25113 0.06457283347845078
63 25113 0.06914938986301422
64 25113 0.09129611402750015
65 25113 0.024436049163341522
66 25113 0.04942302778363228
67 25113 0.061757493764162064
68 25113 0.03647232800722122
69 25113 0.051538825035095215
70 25113 0.04527135565876961
71 25113 0.1302964985370636
72 25113 0.01936028152704239
73 25113 0.03270076587796211
74 25113 0.06140344962477684
75 25113 0.07765144854784012
76 25113 0.04302561655640602
77 25113 0.0426173061132431
78 25113 0.1174960657954216
79 25113 0.03334003686904907
80 25113 0.07038025557994843
81 25113 0.04051115736365318
82 25113 0.05230370908975601
83 25113 0.0601261742413044
84 25113 0.051788873970508575
85 25113 0.07146096974611282
86 25113 0.027239227667450905
87 25113 0.04100186005234718
88 25113 0.03430294618010521
89 25113 0.10956192761659622
90 25113 0.03358352929353714
91 25113 0.03786231204867363
92 25113 0.03720320016145706
93 25113 0.062312107533216476
94 25113 0.058316294103860855
95 25113 0.04461348429322243
96 25113 0.042176518589258194
97 25113 0.03521609678864479
98 25113 0.024266112595796585
99 25113 0.2832081615924835
100 25113 0.07626411318778992
101 25113 0.11462108790874481
102 25113 0.047781724482774734
103 25113 0.0586397759616375
104 25113 0.09300550818443298
105 25113 0.07235666364431381
106 25113 0.0745423436164856
107 25113 0.10413321852684021
108 25113 0.06375458836555481
109 25113 0.0721120685338974
110 25113 0.06127835437655449
111 25113 0.0673857256770134
112 25113 0.047955967485904694
113 25113 0.03116188943386078
114 25113 0.06548124551773071
115 25113 0.01636516861617565
116 25113 0.07232823967933655
117 25113 0.07088430225849152
118 25113 0.06325852125883102
119 25113 0.048299532383680344
120 25113 0.07389474660158157
121 25113 0.06397119164466858
122 25113 0.07181286066770554
123 25113 0.07015561312437057
124 25113 0.06321931630373001
125 25113 0.05055944621562958
train - Global loss: 0.059424    Embedding norm: 1.0000   Triplets (all/active): 199.3/1372.7
Pos dist (min/mean/max): 0.4336/0.6756/0.9799   Neg dist (min/mean/max): 0.9910/1.4093/1.7175
0 1011 0.18895098567008972
1 1011 0.1821032166481018
2 1011 0.24861189723014832
3 1011 0.18266631662845612
4 1011 0.26836833357810974
5 1011 0.17898090183734894
val - Global loss: 0.208280    Embedding norm: 1.0000   Triplets (all/active): 168.5/20591.7
Pos dist (min/mean/max): 0.5800/0.8952/1.2082   Neg dist (min/mean/max): 0.6479/1.2627/1.6471
0 25113 0.09042725712060928
1 25113 0.06573312729597092
2 25113 0.05574498325586319
3 25113 0.07779751718044281
4 25113 0.06629882007837296
5 25113 0.050001051276922226
6 25113 0.05071846768260002
7 25113 0.0522027462720871
8 25113 0.029663102701306343
9 25113 0.05233573541045189
10 25113 0.06843677908182144
11 25113 0.06948991864919662
12 25113 0.0430556945502758
13 25113 0.04860914498567581
14 25113 0.051203835755586624
15 25113 0.05536239966750145
16 25113 0.06340029835700989
17 25113 0.02641434222459793
18 25113 0.03760829567909241
19 25113 0.05908339470624924
20 25113 0.05110776796936989
21 25113 0.03415761888027191
22 25113 0.04870462045073509
23 25113 0.07042278349399567
24 25113 0.05537659674882889
25 25113 0.07388082146644592
26 25113 0.05172276496887207
27 25113 0.03970886394381523
28 25113 0.0276406928896904
29 25113 0.07403062283992767
30 25113 0.028358493000268936
31 25113 0.06280578672885895
32 25113 0.05871877819299698
33 25113 0.03926301747560501
34 25113 0.030140696093440056
35 25113 0.04844511300325394
36 25113 0.017745450139045715
37 25113 0.02054433338344097
38 25113 0.06546106189489365
39 25113 0.05506747588515282
40 25113 0.046159300953149796
41 25113 0.03944740444421768
42 25113 0.03368739038705826
43 25113 0.043543681502342224
44 25113 0.051421020179986954
45 25113 0.07440133392810822
46 25113 0.05334596708416939
47 25113 0.040363144129514694
48 25113 0.0425686314702034
49 25113 0.055581822991371155
50 25113 0.0679001435637474
51 25113 0.031932249665260315
52 25113 0.07602150738239288
53 25113 0.0312647745013237
54 25113 0.04503081366419792
55 25113 0.07056865096092224
56 25113 0.0633358359336853
57 25113 0.04335566237568855
58 25113 0.05511946976184845
59 25113 0.018550267443060875
60 25113 0.0736430361866951
61 25113 0.09562502056360245
62 25113 0.06787784397602081
63 25113 0.08905741572380066
64 25113 0.06575573980808258
65 25113 0.064519502222538
66 25113 0.017412059009075165
67 25113 0.04675200209021568
68 25113 0.07524929195642471
69 25113 0.02989547699689865
70 25113 0.04292332008481026
71 25113 0.08225921541452408
72 25113 0.040601860731840134
73 25113 0.06932397186756134
74 25113 0.033210743218660355
75 25113 0.02517741173505783
76 25113 0.05125647783279419
77 25113 0.06411724537611008
78 25113 0.0621885284781456
79 25113 0.03038916550576687
80 25113 0.019838903099298477
81 25113 0.026613984256982803
82 25113 0.06276091188192368
83 25113 0.03707902878522873
84 25113 0.050509169697761536
85 25113 0.059538714587688446
86 25113 0.0723259374499321
87 25113 0.042075853794813156
88 25113 0.03769455477595329
89 25113 0.09594501554965973
90 25113 0.04625644162297249
91 25113 0.05521069094538689
92 25113 0.030775394290685654
93 25113 0.0828002393245697
94 25113 0.06292369216680527
95 25113 0.07627999782562256
96 25113 0.06142479181289673
97 25113 0.03899729624390602
98 25113 0.02673962339758873
99 25113 0.057796478271484375
100 25113 0.068400077521801
101 25113 0.01994907297194004
102 25113 0.09637972712516785
103 25113 0.046018749475479126
104 25113 0.06912923604249954
105 25113 0.0471610389649868
106 25113 0.058223191648721695
107 25113 0.04710734635591507
108 25113 0.06348790228366852
109 25113 0.0562361441552639
110 25113 0.03706134483218193
111 25113 0.019747020676732063
112 25113 0.02985573187470436
113 25113 0.053396012634038925
114 25113 0.024563860148191452
115 25113 0.033049263060092926
116 25113 0.11157549917697906
117 25113 0.08556390553712845
118 25113 0.015690701082348824
119 25113 0.06135193258523941
120 25113 0.08376672118902206
121 25113 0.0625607892870903
122 25113 0.044196225702762604
123 25113 0.07313622534275055
124 25113 0.07162247598171234
125 25113 0.057395294308662415
train - Global loss: 0.052841    Embedding norm: 1.0000   Triplets (all/active): 199.3/1041.1
Pos dist (min/mean/max): 0.4240/0.6623/0.9498   Neg dist (min/mean/max): 0.9892/1.4079/1.7238
0 1011 0.16562633216381073
1 1011 0.16731634736061096
2 1011 0.18564476072788239
3 1011 0.1566537618637085
4 1011 0.2440280318260193
5 1011 0.1876458078622818
val - Global loss: 0.184486    Embedding norm: 1.0000   Triplets (all/active): 168.5/15875.0
Pos dist (min/mean/max): 0.6020/0.8761/1.2046   Neg dist (min/mean/max): 0.6247/1.3016/1.6386
0 25113 0.08879170566797256
1 25113 0.05471091344952583
2 25113 0.0632055252790451
3 25113 0.05350075289607048
4 25113 0.05167930945754051
5 25113 0.046585481613874435
6 25113 0.03900350257754326
7 25113 0.020618081092834473
8 25113 0.04664219915866852
9 25113 0.05002214387059212
10 25113 0.04557641223073006
11 25113 0.03676586598157883
12 25113 0.08011696487665176
13 25113 0.0011048316955566406
14 25113 0.06750262528657913
15 25113 0.03721538186073303
16 25113 0.029328184202313423
17 25113 0.049557317048311234
18 25113 0.026049725711345673
19 25113 0.03558191657066345
20 25113 0.06700190156698227
21 25113 0.041060276329517365
22 25113 0.08453916758298874
23 25113 0.05098385736346245
24 25113 0.040976766496896744
25 25113 0.06316294521093369
26 25113 0.0407230369746685
27 25113 0.05546329915523529
28 25113 0.03780190274119377
29 25113 0.08324073255062103
30 25113 0.03993711248040199
31 25113 0.05956109240651131
32 25113 0.08297032862901688
33 25113 0.047999754548072815
34 25113 0.05744708701968193
35 25113 0.059667956084012985
36 25113 0.05448226258158684
37 25113 0.039795130491256714
38 25113 0.06565091013908386
39 25113 0.09053618460893631
40 25113 0.06331304460763931
41 25113 0.03308650478720665
42 25113 0.036280807107686996
43 25113 0.03584687411785126
44 25113 0.04962070658802986
45 25113 0.0694766417145729
46 25113 0.050692737102508545
47 25113 0.08503701537847519
48 25113 0.05796947702765465
49 25113 0.051229774951934814
50 25113 0.04748092219233513
51 25113 0.0435904860496521
52 25113 0.059397079050540924
53 25113 0.05179835855960846
54 25113 0.02163984812796116
55 25113 0.06595075875520706
56 25113 0.06269266456365585
57 25113 0.038918592035770416
58 25113 0.04593190550804138
59 25113 0.0967283770442009
60 25113 0.05508984625339508
61 25113 0.032923463732004166
62 25113 0.0623355433344841
63 25113 0.059100162237882614
64 25113 0.06546743959188461
65 25113 0.011806661263108253
66 25113 0.03775802627205849
67 25113 0.050673626363277435
68 25113 0.10497844964265823
69 25113 0.04403039440512657
70 25113 0.06010871380567551
71 25113 0.13308221101760864
72 25113 0.04219835624098778
73 25113 0.05453319475054741
74 25113 0.05226251110434532
75 25113 0.05537690967321396
76 25113 0.03384021669626236
77 25113 0.07394181191921234
78 25113 0.05380656570196152
79 25113 0.022026479244232178
80 25113 0.05283007398247719
81 25113 0.06083565950393677
82 25113 0.031078964471817017
83 25113 0.07105249166488647
84 25113 0.057457681745290756
85 25113 0.07170578837394714
86 25113 0.08661627769470215
87 25113 0.045743655413389206
88 25113 0.10476413369178772
89 25113 0.06445702910423279
90 25113 0.03717954456806183
91 25113 0.039300817996263504
92 25113 0.03929950296878815
93 25113 0.06462050974369049
94 25113 0.049421362578868866
95 25113 0.041600652039051056
96 25113 0.042912740260362625
97 25113 0.13427002727985382
98 25113 0.06764029711484909
99 25113 0.08071213215589523
100 25113 0.045685090124607086
101 25113 0.0769863948225975
102 25113 0.020094549283385277
103 25113 0.03800516575574875
104 25113 0.04087645933032036
105 25113 0.031738560646772385
106 25113 0.031101269647479057
107 25113 0.06479977816343307
108 25113 0.036517687141895294
109 25113 0.06475186347961426
110 25113 0.06127788498997688
111 25113 0.04890388622879982
112 25113 0.04970063641667366
113 25113 0.043822553008794785
114 25113 0.01770317554473877
115 25113 0.03997896984219551
116 25113 0.07353542000055313
117 25113 0.06512410193681717
118 25113 0.06256888806819916
119 25113 0.06248138099908829
120 25113 0.053167007863521576
121 25113 0.06529567390680313
122 25113 0.030427467077970505
123 25113 0.06570862233638763
124 25113 0.11003995686769485
125 25113 0.056020282208919525
train - Global loss: 0.054432    Embedding norm: 1.0000   Triplets (all/active): 199.3/1129.1
Pos dist (min/mean/max): 0.4314/0.6677/0.9629   Neg dist (min/mean/max): 0.9927/1.4084/1.7197
0 1011 0.16999582946300507
1 1011 0.19037523865699768
2 1011 0.22800351679325104
3 1011 0.1648653894662857
4 1011 0.2555183470249176
5 1011 0.10328314453363419
val - Global loss: 0.185340    Embedding norm: 1.0000   Triplets (all/active): 168.5/18828.7
Pos dist (min/mean/max): 0.5749/0.8755/1.1988   Neg dist (min/mean/max): 0.6106/1.2814/1.6672
0 25113 0.034354060888290405
1 25113 0.054226845502853394
2 25113 0.043219443410634995
3 25113 0.03567711263895035
4 25113 0.05564497783780098
5 25113 0.04084225744009018
6 25113 0.05090392008423805
7 25113 0.06248822435736656
8 25113 0.03881765902042389
9 25113 0.01467124279588461
10 25113 0.05222972854971886
11 25113 0.0512363500893116
12 25113 0.06212148070335388
13 25113 0.014936906285583973
14 25113 0.04407184198498726
15 25113 0.03668254613876343
16 25113 0.08660811930894852
17 25113 0.05292371287941933
18 25113 0.0339774526655674
19 25113 0.0510743111371994
20 25113 0.061098862439394
21 25113 0.10786103457212448
22 25113 0.05055715888738632
23 25113 0.057510100305080414
24 25113 0.07534768432378769
25 25113 0.03939563408493996
26 25113 0.023671109229326248
27 25113 0.037486400455236435
28 25113 0.05409117415547371
29 25113 0.05282646790146828
30 25113 0.07769481092691422
31 25113 0.03465193882584572
32 25113 0.07712389528751373
33 25113 0.02693999372422695
34 25113 0.05399402976036072
35 25113 0.0536440908908844
36 25113 0.03903288021683693
37 25113 0.08578111976385117
38 25113 0.0552370622754097
39 25113 0.04660511389374733
40 25113 0.0857030600309372
41 25113 0.04903579503297806
42 25113 0.0
43 25113 0.05061180889606476
44 25113 0.0463450662791729
45 25113 0.06022001430392265
46 25113 0.063321553170681
47 25113 0.0460175983607769
48 25113 0.04130042716860771
49 25113 0.033427417278289795
50 25113 0.05546850711107254
51 25113 0.03797853738069534
52 25113 0.04772596061229706
53 25113 0.06497699022293091
54 25113 0.05640584975481033
55 25113 0.07328485697507858
56 25113 0.05603447183966637
57 25113 0.08252857625484467
58 25113 0.048162467777729034
59 25113 0.05480813980102539
60 25113 0.03352294862270355
61 25113 0.02786487340927124
62 25113 0.053426068276166916
63 25113 0.07159938663244247
64 25113 0.07446344941854477
65 25113 0.04097997024655342
66 25113 0.06136884167790413
67 25113 0.05630595237016678
68 25113 0.0637691468000412
69 25113 0.06925764679908752
70 25113 0.032751310616731644
71 25113 0.06719935685396194
72 25113 0.039880093187093735
73 25113 0.1137857511639595
74 25113 0.056165825575590134
75 25113 0.068126380443573
76 25113 0.0373896099627018
77 25113 0.060968127101659775
78 25113 0.029040826484560966
79 25113 0.08169955015182495
80 25113 0.010665706358850002
81 25113 0.005534816067665815
82 25113 0.04815644025802612
83 25113 0.05363674834370613
84 25113 0.06215621158480644
85 25113 0.064479760825634
86 25113 0.03150136023759842
87 25113 0.005758186336606741
88 25113 0.04180765524506569
89 25113 0.059879120439291
90 25113 0.02566853165626526
91 25113 0.05299949273467064
92 25113 0.033958882093429565
93 25113 0.06903460621833801
94 25113 0.06599628180265427
95 25113 0.0359964445233345
96 25113 0.07586584985256195
97 25113 0.07751251757144928
98 25113 0.05473920702934265
99 25113 0.03911112621426582
100 25113 0.04665515944361687
101 25113 0.041945308446884155
102 25113 0.03024098463356495
103 25113 0.06569118797779083
104 25113 0.013230875134468079
105 25113 0.02622571773827076
106 25113 0.043569501489400864
107 25113 0.037997882813215256
108 25113 0.04210836440324783
109 25113 0.04625556245446205
110 25113 0.05427104979753494
111 25113 0.01588757522404194
112 25113 0.04633922502398491
113 25113 0.033235833048820496
114 25113 0.042335543781518936
115 25113 0.02624509111046791
116 25113 0.04723714664578438
117 25113 0.06696181744337082
118 25113 0.0406254343688488
119 25113 0.060294728726148605
120 25113 0.04798809066414833
121 25113 0.0490204319357872
122 25113 0.05931738764047623
123 25113 0.09024263918399811
124 25113 0.02677418664097786
125 25113 0.05261027067899704
train - Global loss: 0.049904    Embedding norm: 1.0000   Triplets (all/active): 199.3/818.9
Pos dist (min/mean/max): 0.4259/0.6589/0.9453   Neg dist (min/mean/max): 1.0001/1.4084/1.7131
0 1011 0.188986137509346
1 1011 0.20889364182949066
2 1011 0.21427427232265472
3 1011 0.17697308957576752
4 1011 0.2534773647785187
5 1011 0.2632819712162018
val - Global loss: 0.217648    Embedding norm: 1.0000   Triplets (all/active): 168.5/18042.7
Pos dist (min/mean/max): 0.6232/0.9055/1.2398   Neg dist (min/mean/max): 0.6412/1.2864/1.6536
0 25113 0.04177691042423248
1 25113 0.06955299526453018
2 25113 0.045383282005786896
3 25113 0.07390468567609787
4 25113 0.040786489844322205
5 25113 0.05324214696884155
6 25113 0.04867171496152878
7 25113 0.061309803277254105
8 25113 0.026036201044917107
9 25113 0.049581337720155716
10 25113 0.07448266446590424
11 25113 0.0488395169377327
12 25113 0.04908664524555206
13 25113 0.04222436994314194
14 25113 0.054218292236328125
15 25113 0.08816806226968765
16 25113 0.040532272309064865
17 25113 0.03233639523386955
18 25113 0.025419039651751518
19 25113 0.007037252187728882
20 25113 0.03855142369866371
21 25113 0.029394494369626045
22 25113 0.049494173377752304
23 25113 0.07928787916898727
24 25113 0.06746893376111984
25 25113 0.04263550043106079
26 25113 0.031141869723796844
27 25113 0.04327240586280823
28 25113 0.14889320731163025
29 25113 0.0760880559682846
30 25113 0.07420020550489426
31 25113 0.04735565930604935
32 25113 0.04668533802032471
33 25113 0.046589337289333344
34 25113 0.054402537643909454
35 25113 0.040708236396312714
36 25113 0.04092758893966675
37 25113 0.05212705582380295
38 25113 0.057387225329875946
39 25113 0.0854930728673935
40 25113 0.041212297976017
41 25113 0.03084433078765869
42 25113 0.04841676354408264
43 25113 0.05003737285733223
44 25113 0.07811620086431503
45 25113 0.058452021330595016
46 25113 0.040562838315963745
47 25113 0.051081493496894836
48 25113 0.06508053094148636
49 25113 0.09422034025192261
50 25113 0.06785521656274796
51 25113 0.07635203748941422
52 25113 0.04047054797410965
53 25113 0.028812048956751823
54 25113 0.05557249113917351
55 25113 0.05940926820039749
56 25113 0.03773181885480881
57 25113 0.04955797642469406
58 25113 0.04601529613137245
59 25113 0.02428402192890644
60 25113 0.05428551137447357
61 25113 0.03188550844788551
62 25113 0.05183516442775726
63 25113 0.04438389465212822
64 25113 0.06288161128759384
65 25113 0.07545861601829529
66 25113 0.029217515140771866
67 25113 0.042585741728544235
68 25113 0.0418541245162487
69 25113 0.03549554571509361
70 25113 0.01998450607061386
71 25113 0.05467858910560608
72 25113 0.06658745557069778
73 25113 0.04928532987833023
74 25113 0.045226551592350006
75 25113 0.06338078528642654
76 25113 0.036489952355623245
77 25113 0.053643010556697845
78 25113 0.08221728354692459
79 25113 0.03156546875834465
80 25113 0.03781996667385101
81 25113 0.02606826461851597
82 25113 0.0457221083343029
83 25113 0.042900633066892624
84 25113 0.04901384189724922
85 25113 0.043320778757333755
86 25113 0.027591638267040253
87 25113 0.051331862807273865
88 25113 0.03652692213654518
89 25113 0.056838538497686386
90 25113 0.04264165088534355
91 25113 0.03762274608016014
92 25113 0.07863156497478485
93 25113 0.05397673696279526
94 25113 0.0856352224946022
95 25113 0.030407855287194252
96 25113 0.040315184742212296
97 25113 0.10990902036428452
98 25113 0.05834028497338295
99 25113 0.035053983330726624
100 25113 0.04870039224624634
101 25113 0.1034318059682846
102 25113 0.03889048844575882
103 25113 0.027084702625870705
104 25113 0.027882132679224014
105 25113 0.032573431730270386
106 25113 0.05564722791314125
107 25113 0.03771645948290825
108 25113 0.05290377885103226
109 25113 0.05865812301635742
110 25113 0.02196720615029335
111 25113 0.04472295567393303
112 25113 0.027141213417053223
113 25113 0.0655520111322403
114 25113 0.03051607310771942
115 25113 0.03488268330693245
116 25113 0.05078057944774628
117 25113 0.06077296659350395
118 25113 0.05540405213832855
119 25113 0.042018648236989975
120 25113 0.035904545336961746
121 25113 0.07077223807573318
122 25113 0.05247664824128151
123 25113 0.040126651525497437
124 25113 0.038986895233392715
125 25113 0.0345485657453537
train - Global loss: 0.050170    Embedding norm: 1.0000   Triplets (all/active): 199.3/679.5
Pos dist (min/mean/max): 0.4139/0.6519/0.9477   Neg dist (min/mean/max): 1.0197/1.4092/1.7111
0 1011 0.14432364702224731
1 1011 0.15008191764354706
2 1011 0.20718270540237427
3 1011 0.15441860258579254
4 1011 0.24015001952648163
5 1011 0.17939820885658264
val - Global loss: 0.179259    Embedding norm: 1.0000   Triplets (all/active): 168.5/16595.8
Pos dist (min/mean/max): 0.5896/0.8734/1.1988   Neg dist (min/mean/max): 0.6725/1.2751/1.6516
0 25113 0.03058118000626564
1 25113 0.055599313229322433
2 25113 0.05495867505669594
3 25113 0.04158804938197136
4 25113 0.06571570783853531
5 25113 0.048044249415397644
6 25113 0.04172028973698616
7 25113 0.0
8 25113 0.07047294825315475
9 25113 0.0586775578558445
10 25113 0.06218872219324112
11 25113 0.03843531385064125
12 25113 0.04650040343403816
13 25113 0.0
14 25113 0.04938884824514389
15 25113 0.025633621960878372
16 25113 0.061576541513204575
17 25113 0.03192487731575966
18 25113 0.026287298649549484
19 25113 0.053792476654052734
20 25113 0.0374823734164238
21 25113 0.02336912229657173
22 25113 0.029931997880339622
23 25113 0.04779800400137901
24 25113 0.048153188079595566
25 25113 0.04677469655871391
26 25113 0.05449337139725685
27 25113 0.04020150005817413
28 25113 0.04795423522591591
29 25113 0.08688965439796448
30 25113 0.061869554221630096
31 25113 0.015715479850769043
32 25113 0.03954271972179413
33 25113 0.05257047340273857
34 25113 0.05356401950120926
35 25113 0.042830079793930054
36 25113 0.04213513061404228
37 25113 0.03086136467754841
38 25113 0.07604672014713287
39 25113 0.04419578239321709
40 25113 0.039707545191049576
41 25113 0.04636501893401146
42 25113 0.03511173278093338
43 25113 0.01777769811451435
44 25113 0.05293189734220505
45 25113 0.04998324438929558
46 25113 0.015154927968978882
47 25113 0.04245803505182266
48 25113 0.08265397697687149
49 25113 0.046818483620882034
50 25113 0.04443081095814705
51 25113 0.0498778335750103
52 25113 0.04953065514564514
53 25113 0.06075281649827957
54 25113 0.03789510577917099
55 25113 0.05678148567676544
56 25113 0.04365111514925957
57 25113 0.04871005192399025
58 25113 0.03425932675600052
59 25113 0.0648932233452797
60 25113 0.013901621103286743
61 25113 0.05917370319366455
62 25113 0.04417003318667412
63 25113 0.029547439888119698
64 25113 0.06565815955400467
65 25113 0.0006725192070007324
66 25113 0.03832800313830376
67 25113 0.07474543154239655
68 25113 0.090916208922863
69 25113 0.0504060834646225
70 25113 0.09909515827894211
71 25113 0.07081282138824463
72 25113 0.04246342554688454
73 25113 0.09097026288509369
74 25113 0.05584292113780975
75 25113 0.0725271925330162
76 25113 0.041828516870737076
77 25113 0.061092082411050797
78 25113 0.05122487246990204
79 25113 0.03036520443856716
80 25113 0.07310731709003448
81 25113 0.04694843292236328
82 25113 0.052165523171424866
83 25113 0.05523467808961868
84 25113 0.07960905879735947
85 25113 0.06257721036672592
86 25113 0.07630754262208939
87 25113 0.036171820014715195
88 25113 0.1078953891992569
89 25113 0.06617874652147293
90 25113 0.048066433519124985
91 25113 0.039598263800144196
92 25113 0.060554251074790955
93 25113 0.06527426838874817
94 25113 0.040029797703027725
95 25113 0.07212946563959122
96 25113 0.02511950396001339
97 25113 0.06620870530605316
98 25113 0.06283669918775558
99 25113 0.05109943449497223
100 25113 0.07575947791337967
101 25113 0.029834173619747162
102 25113 0.014245851896703243
103 25113 0.01626489870250225
104 25113 0.040091466158628464
105 25113 0.04516610503196716
106 25113 0.03423544764518738
107 25113 0.05162936821579933
108 25113 0.06510043889284134
109 25113 0.058695171028375626
110 25113 0.13460104167461395
111 25113 0.021444125100970268
112 25113 0.006797194480895996
113 25113 0.03454717993736267
114 25113 0.04689424857497215
115 25113 0.033361759036779404
116 25113 0.05292622745037079
117 25113 0.061135999858379364
118 25113 0.037496164441108704
119 25113 0.06797423213720322
120 25113 0.050395186990499496
121 25113 0.04337793216109276
122 25113 0.046588167548179626
123 25113 0.04511647671461105
124 25113 0.04119596630334854
125 25113 0.03863127529621124
train - Global loss: 0.048965    Embedding norm: 1.0000   Triplets (all/active): 199.3/715.7
Pos dist (min/mean/max): 0.4199/0.6606/0.9544   Neg dist (min/mean/max): 1.0330/1.4111/1.7009
0 1011 0.2153768539428711
1 1011 0.1819540113210678
2 1011 0.20634622871875763
3 1011 0.19156473875045776
4 1011 0.26702412962913513
5 1011 0.14141984283924103
val - Global loss: 0.200614    Embedding norm: 1.0000   Triplets (all/active): 168.5/17982.3
Pos dist (min/mean/max): 0.4640/0.8050/1.1761   Neg dist (min/mean/max): 0.4979/1.2568/1.6477
0 25113 0.046647440642118454
1 25113 0.040340788662433624
2 25113 0.022823046892881393
3 25113 0.04639795422554016
4 25113 0.04452041909098625
5 25113 0.038857363164424896
6 25113 0.04913100600242615
7 25113 0.0
8 25113 0.08579324930906296
9 25113 0.045691441744565964
10 25113 0.06241981312632561
11 25113 0.038752809166908264
12 25113 0.062422268092632294
13 25113 0.03788501396775246
14 25113 0.05586168169975281
15 25113 0.09301060438156128
16 25113 0.05850936099886894
17 25113 0.041843269020318985
18 25113 0.03372034430503845
19 25113 0.06011927127838135
20 25113 0.05415324121713638
21 25113 0.03836069256067276
22 25113 0.08297452330589294
23 25113 0.05078980326652527
24 25113 0.05942600592970848
25 25113 0.06634233146905899
26 25113 0.03264055401086807
27 25113 0.07204478979110718
28 25113 0.04705921933054924
29 25113 0.05062837153673172
30 25113 0.05976364016532898
31 25113 0.004842646420001984
32 25113 0.07443559169769287
33 25113 0.051013484597206116
34 25113 0.03544289618730545
35 25113 0.0824524536728859
36 25113 0.033852469176054
37 25113 0.049881692975759506
38 25113 0.04241641238331795
39 25113 0.06768208742141724
40 25113 0.06624353677034378
41 25113 0.021669715642929077
42 25113 0.01192616019397974
43 25113 0.04063763469457626
44 25113 0.052062731236219406
45 25113 0.053561996668577194
46 25113 0.04231305047869682
47 25113 0.042575348168611526
48 25113 0.022833457216620445
49 25113 0.05935743451118469
50 25113 0.04509839043021202
51 25113 0.047475337982177734
52 25113 0.04039227217435837
53 25113 0.03415187448263168
54 25113 0.029956979677081108
55 25113 0.05871149152517319
56 25113 0.03886502981185913
57 25113 0.05147159472107887
58 25113 0.051715489476919174
59 25113 0.04227956756949425
60 25113 0.11751727014780045
61 25113 0.03584421053528786
62 25113 0.04354355111718178
63 25113 0.04208054766058922
64 25113 0.05246736854314804
65 25113 0.014704079367220402
66 25113 0.03633034974336624
67 25113 0.0386655293405056
68 25113 0.0766105130314827
69 25113 0.034700844436883926
70 25113 0.12738104164600372
71 25113 0.030798422172665596
72 25113 0.05460117757320404
73 25113 0.0
74 25113 0.03494812920689583
75 25113 0.02769436128437519
76 25113 0.016237758100032806
77 25113 0.04406977817416191
78 25113 0.024162374436855316
79 25113 0.022830963134765625
80 25113 0.027878815308213234
81 25113 0.032521266490221024
82 25113 0.03617675602436066
83 25113 0.06695020198822021
84 25113 0.021846411749720573
85 25113 0.047877002507448196
86 25113 0.0
87 25113 0.009037494659423828
88 25113 0.05050075799226761
89 25113 0.07655948400497437
90 25113 0.0013491511344909668
91 25113 0.0
92 25113 0.018107188865542412
93 25113 0.03629537299275398
94 25113 0.022814583033323288
95 25113 0.04347631707787514
96 25113 0.033393848687410355
97 25113 0.02605590783059597
98 25113 0.023184804245829582
99 25113 0.03619704395532608
100 25113 0.032299913465976715
101 25113 0.034797824919223785
102 25113 0.022376013919711113
103 25113 0.010760268196463585
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.01900802180171013
109 25113 0.21597298979759216
110 25113 0.03146049380302429
111 25113 0.023270100355148315
112 25113 0.0
113 25113 0.02225782908499241
114 25113 0.019936060532927513
115 25113 0.027781575918197632
116 25113 0.03323635458946228
117 25113 0.020360980182886124
118 25113 0.02784670889377594
119 25113 0.04793251305818558
120 25113 0.06292671710252762
121 25113 0.061662089079618454
122 25113 0.029865000396966934
123 25113 0.06862566620111465
124 25113 0.052074458450078964
125 25113 0.021343324333429337
train - Global loss: 0.041631    Embedding norm: 1.0000   Triplets (all/active): 199.3/489.1
Pos dist (min/mean/max): 0.4222/0.6549/0.9491   Neg dist (min/mean/max): 1.0755/1.4142/1.6856
0 1011 0.17264550924301147
1 1011 0.17537817358970642
2 1011 0.2188357263803482
3 1011 0.15097028017044067
4 1011 0.20832203328609467
5 1011 0.19495908915996552
val - Global loss: 0.186852    Embedding norm: 1.0000   Triplets (all/active): 168.5/21063.7
Pos dist (min/mean/max): 0.4631/0.6970/1.0187   Neg dist (min/mean/max): 0.4251/1.0062/1.4050
0 25113 0.020513642579317093
1 25113 0.06060974672436714
2 25113 0.01194954477250576
3 25113 0.029393315315246582
4 25113 0.33207061886787415
5 25113 0.22471760213375092
6 25113 0.04533673822879791
7 25113 0.08734077215194702
8 25113 0.09102988243103027
9 25113 0.07301527261734009
10 25113 0.10669730603694916
11 25113 0.05221089720726013
12 25113 0.04710448905825615
13 25113 0.032644934952259064
14 25113 0.07386629283428192
15 25113 0.05216468125581741
16 25113 0.09411674737930298
17 25113 0.035523589700460434
18 25113 0.05797930061817169
19 25113 0.0667942464351654
20 25113 0.07868946343660355
21 25113 0.040301427245140076
22 25113 0.05940215662121773
23 25113 0.05760933831334114
24 25113 0.06291413307189941
25 25113 0.06206970661878586
26 25113 0.035085275769233704
27 25113 0.055072180926799774
28 25113 0.09902871400117874
29 25113 0.09170699119567871
30 25113 0.07477275282144547
31 25113 0.05325900390744209
32 25113 0.05621403455734253
33 25113 0.03657697141170502
34 25113 0.08883214741945267
35 25113 0.03430033102631569
36 25113 0.030718963593244553
37 25113 0.06987139582633972
38 25113 0.055387649685144424
39 25113 0.05627543479204178
40 25113 0.03712431713938713
41 25113 0.04586460441350937
42 25113 0.03205307945609093
43 25113 0.05151853710412979
44 25113 0.05411827191710472
45 25113 0.07226603478193283
46 25113 0.05598892271518707
47 25113 0.039099905639886856
48 25113 0.0439542718231678
49 25113 0.03837655112147331
50 25113 0.04270528629422188
51 25113 0.03540220111608505
52 25113 0.034150172024965286
53 25113 0.03706011548638344
54 25113 0.02696305699646473
55 25113 0.08517659455537796
56 25113 0.04565124213695526
57 25113 0.04469066113233566
58 25113 0.02438877336680889
59 25113 0.03980907052755356
60 25113 0.04061519354581833
61 25113 0.0325455479323864
62 25113 0.03428903967142105
63 25113 0.06719966977834702
64 25113 0.045604158192873
65 25113 0.033921316266059875
66 25113 0.04788675159215927
67 25113 0.03931540995836258
68 25113 0.04830186814069748
69 25113 0.03965279087424278
70 25113 0.03750816360116005
71 25113 0.07685008645057678
72 25113 0.03743938356637955
73 25113 0.05609483644366264
74 25113 0.04797205701470375
75 25113 0.03038095310330391
76 25113 0.0294130090624094
77 25113 0.02914765477180481
78 25113 0.028251713141798973
79 25113 0.004841826856136322
80 25113 0.021458031609654427
81 25113 0.03232013061642647
82 25113 0.05171649158000946
83 25113 0.038396090269088745
84 25113 0.032952871173620224
85 25113 0.08194315433502197
86 25113 0.0
87 25113 0.0
88 25113 0.031467992812395096
89 25113 0.10083095729351044
90 25113 0.02741239406168461
91 25113 0.034516386687755585
92 25113 0.23481348156929016
93 25113 0.035134539008140564
94 25113 0.03764007240533829
95 25113 0.040973033756017685
96 25113 0.06556572765111923
97 25113 0.06780049204826355
98 25113 0.0684158056974411
99 25113 0.07455892115831375
100 25113 0.086927130818367
101 25113 0.0877913385629654
102 25113 0.03480038791894913
103 25113 0.03590909019112587
104 25113 0.05336765572428703
105 25113 0.05200602486729622
106 25113 0.059377361088991165
107 25113 0.09394782036542892
108 25113 0.0797690823674202
109 25113 0.07717013359069824
110 25113 0.0786503478884697
111 25113 0.08055341988801956
112 25113 0.04120177403092384
113 25113 0.046385351568460464
114 25113 0.037828098982572556
115 25113 0.05224497988820076
116 25113 0.058419812470674515
117 25113 0.0800117552280426
118 25113 0.059747468680143356
119 25113 0.05679057165980339
120 25113 0.06748787313699722
121 25113 0.055046577006578445
122 25113 0.05114227160811424
123 25113 0.059520915150642395
124 25113 0.03424452617764473
125 25113 0.06406290084123611
train - Global loss: 0.056739    Embedding norm: 1.0000   Triplets (all/active): 199.3/1285.2
Pos dist (min/mean/max): 0.4348/0.6694/0.9721   Neg dist (min/mean/max): 1.0010/1.4090/1.7101
0 1011 0.18990834057331085
1 1011 0.18527443706989288
2 1011 0.21857888996601105
3 1011 0.18070019781589508
4 1011 0.24886754155158997
5 1011 0.17045293748378754
val - Global loss: 0.198964    Embedding norm: 1.0000   Triplets (all/active): 168.5/20508.2
Pos dist (min/mean/max): 0.5917/0.9111/1.2573   Neg dist (min/mean/max): 0.6526/1.2878/1.6543
0 25113 0.05563832074403763
1 25113 0.06251101940870285
2 25113 0.027590321376919746
3 25113 0.04874967783689499
4 25113 0.05723939090967178
5 25113 0.04781858250498772
6 25113 0.05483894422650337
7 25113 0.03869393840432167
8 25113 0.0687362402677536
9 25113 0.03047761134803295
10 25113 0.04290411248803139
11 25113 0.03872762992978096
12 25113 0.04545539617538452
13 25113 0.03527276590466499
14 25113 0.07921935617923737
15 25113 0.1477120965719223
16 25113 0.027830207720398903
17 25113 0.025599416345357895
18 25113 0.05302775651216507
19 25113 0.004997268319129944
20 25113 0.07664112746715546
21 25113 0.0312565378844738
22 25113 0.06786500662565231
23 25113 0.0457226000726223
24 25113 0.04681584611535072
25 25113 0.037287209182977676
26 25113 0.047077976167201996
27 25113 0.0953005850315094
28 25113 0.03835413604974747
29 25113 0.0664202868938446
30 25113 0.05527298152446747
31 25113 0.014549946412444115
32 25113 0.07008519768714905
33 25113 0.03788617625832558
34 25113 0.0643918439745903
35 25113 0.04875035583972931
36 25113 0.020759625360369682
37 25113 0.05782453343272209
38 25113 0.048954613506793976
39 25113 0.0389501228928566
40 25113 0.02875545248389244
41 25113 0.02599114179611206
42 25113 0.017132539302110672
43 25113 0.05968015640974045
44 25113 0.034570932388305664
45 25113 0.06878802180290222
46 25113 0.05753307044506073
47 25113 0.05566395819187164
48 25113 0.04733866825699806
49 25113 0.11231663078069687
50 25113 0.06930259615182877
51 25113 0.036124516278505325
52 25113 0.06139737367630005
53 25113 0.051723867654800415
54 25113 0.018346304073929787
55 25113 0.04843068867921829
56 25113 0.05548688396811485
57 25113 0.04562213271856308
58 25113 0.07390865683555603
59 25113 0.005433410406112671
60 25113 0.03838108107447624
61 25113 0.028395527973771095
62 25113 0.04172186180949211
63 25113 0.07437194883823395
64 25113 0.061673298478126526
65 25113 0.04882604628801346
66 25113 0.02102225087583065
67 25113 0.045172255486249924
68 25113 0.06601116061210632
69 25113 0.051018524914979935
70 25113 0.05732264369726181
71 25113 0.06712199747562408
72 25113 0.042463112622499466
73 25113 0.038135308772325516
74 25113 0.04807708039879799
75 25113 0.05291111767292023
76 25113 0.02184128202497959
77 25113 0.043657854199409485
78 25113 0.032508328557014465
79 25113 0.009516890160739422
80 25113 0.03382177650928497
81 25113 0.04376061633229256
82 25113 0.04871945083141327
83 25113 0.0442655086517334
84 25113 0.04692043736577034
85 25113 0.0818246528506279
86 25113 0.04396636784076691
87 25113 0.02768602967262268
88 25113 0.034833915531635284
89 25113 0.07993616908788681
90 25113 0.040372010320425034
91 25113 0.03174721449613571
92 25113 0.035438165068626404
93 25113 0.04610147699713707
94 25113 0.034959979355335236
95 25113 0.02548864856362343
96 25113 0.06283725798130035
97 25113 0.05246978998184204
98 25113 0.04495752975344658
99 25113 0.05485399439930916
100 25113 0.039437975734472275
101 25113 0.04674231633543968
102 25113 0.03590640798211098
103 25113 0.03232300654053688
104 25113 0.04264083504676819
105 25113 0.050357427448034286
106 25113 0.038965947926044464
107 25113 0.03467298299074173
108 25113 0.03794069215655327
109 25113 0.08224212378263474
110 25113 0.03635929897427559
111 25113 0.030723128467798233
112 25113 0.06238191947340965
113 25113 0.02048378810286522
114 25113 0.028148937970399857
115 25113 0.05107465013861656
116 25113 0.050829820334911346
117 25113 0.05580607056617737
118 25113 0.05942804366350174
119 25113 0.044664837419986725
120 25113 0.03671669587492943
121 25113 0.0393647663295269
122 25113 0.0236887875944376
123 25113 0.07489453256130219
124 25113 0.03023380972445011
125 25113 0.03396967053413391
train - Global loss: 0.046840    Embedding norm: 1.0000   Triplets (all/active): 199.3/647.1
Pos dist (min/mean/max): 0.4135/0.6478/0.9261   Neg dist (min/mean/max): 1.0062/1.4074/1.7164
0 1011 0.19142161309719086
1 1011 0.1613788604736328
2 1011 0.20440112054347992
3 1011 0.16735859215259552
4 1011 0.24745872616767883
5 1011 0.20052234828472137
val - Global loss: 0.195424    Embedding norm: 1.0000   Triplets (all/active): 168.5/18089.0
Pos dist (min/mean/max): 0.6195/0.9221/1.2415   Neg dist (min/mean/max): 0.6726/1.3256/1.6816
0 25113 0.04917650297284126
1 25113 0.04358861222863197
2 25113 0.040491919964551926
3 25113 0.03904334455728531
4 25113 0.07218268513679504
5 25113 0.09115252643823624
6 25113 0.03584092855453491
7 25113 0.0
8 25113 0.021402083337306976
9 25113 0.039351724088191986
10 25113 0.0555255152285099
11 25113 0.04065938666462898
12 25113 0.03274025395512581
13 25113 0.03732981160283089
14 25113 0.07032112032175064
15 25113 0.02586955390870571
16 25113 0.04722561687231064
17 25113 0.020389068871736526
18 25113 0.014091233722865582
19 25113 0.07550209760665894
20 25113 0.02462104707956314
21 25113 0.031411826610565186
22 25113 0.051412515342235565
23 25113 0.017754944041371346
24 25113 0.05552958697080612
25 25113 0.0421031191945076
26 25113 0.029090872034430504
27 25113 0.04951643943786621
28 25113 0.06183529645204544
29 25113 0.04932068660855293
30 25113 0.07814932614564896
31 25113 0.0
32 25113 0.03473024442791939
33 25113 0.01713569462299347
34 25113 0.03196218982338905
35 25113 0.04626210778951645
36 25113 0.016789209097623825
37 25113 0.0
38 25113 0.050786878913640976
39 25113 0.040138501673936844
40 25113 0.02529730461537838
41 25113 0.04376403987407684
42 25113 0.019616207107901573
43 25113 0.021591484546661377
44 25113 0.035046469420194626
45 25113 0.05406053364276886
46 25113 0.06306689232587814
47 25113 0.040034037083387375
48 25113 0.03173923119902611
49 25113 0.021473832428455353
50 25113 0.05909346044063568
51 25113 0.014355853199958801
52 25113 0.03258347883820534
53 25113 0.042591389268636703
54 25113 0.027271494269371033
55 25113 0.0639699324965477
56 25113 0.04964438080787659
57 25113 0.029095154255628586
58 25113 0.02240828610956669
59 25113 0.026420898735523224
60 25113 0.05891375243663788
61 25113 0.07141140848398209
62 25113 0.04521286115050316
63 25113 0.08778885751962662
64 25113 0.09219180792570114
65 25113 0.02635400928556919
66 25113 0.03794623166322708
67 25113 0.05123322457075119
68 25113 0.04085516184568405
69 25113 0.03481053188443184
70 25113 0.01106654666364193
71 25113 0.07455465942621231
72 25113 0.03660720959305763
73 25113 0.050061456859111786
74 25113 0.038007576018571854
75 25113 0.04075539484620094
76 25113 0.05946740880608559
77 25113 0.0625581294298172
78 25113 0.03711125999689102
79 25113 0.0
80 25113 0.010049775242805481
81 25113 0.0518387034535408
82 25113 0.03148265182971954
83 25113 0.057906728237867355
84 25113 0.04580149054527283
85 25113 0.0785476490855217
86 25113 0.041295375674963
87 25113 0.0259107518941164
88 25113 0.04718469828367233
89 25113 0.07649924606084824
90 25113 0.03366629779338837
91 25113 0.007468186318874359
92 25113 0.04092755168676376
93 25113 0.04255509749054909
94 25113 0.022697702050209045
95 25113 0.03264487534761429
96 25113 0.03812643885612488
97 25113 0.026984158903360367
98 25113 0.03837449848651886
99 25113 0.04365282878279686
100 25113 0.030704259872436523
101 25113 0.023694243282079697
102 25113 0.040252283215522766
103 25113 0.03382126986980438
104 25113 0.040083885192871094
105 25113 0.021117186173796654
106 25113 0.026549816131591797
107 25113 0.043241411447525024
108 25113 0.05997444689273834
109 25113 0.0523998886346817
110 25113 0.03555077314376831
111 25113 0.03643656522035599
112 25113 0.0
113 25113 0.033712536096572876
114 25113 0.02986348606646061
115 25113 0.09823080897331238
116 25113 0.05556201934814453
117 25113 0.0589355044066906
118 25113 0.030247129499912262
119 25113 0.0616048164665699
120 25113 0.024506058543920517
121 25113 0.051388196647167206
122 25113 0.037124425172805786
123 25113 0.055088307708501816
124 25113 0.03367501497268677
125 25113 0.02103305235505104
train - Global loss: 0.040388    Embedding norm: 1.0000   Triplets (all/active): 199.3/385.2
Pos dist (min/mean/max): 0.4104/0.6358/0.9061   Neg dist (min/mean/max): 1.0228/1.4081/1.7051
0 1011 0.18513895571231842
1 1011 0.1986301988363266
2 1011 0.22770774364471436
3 1011 0.20265330374240875
4 1011 0.31990811228752136
5 1011 0.08466137945652008
val - Global loss: 0.203117    Embedding norm: 1.0000   Triplets (all/active): 168.5/19805.5
Pos dist (min/mean/max): 0.4739/0.8119/1.1572   Neg dist (min/mean/max): 0.5004/1.2246/1.6217
0 25113 0.04523341357707977
1 25113 0.03684500604867935
2 25113 0.0460059680044651
3 25113 0.04718167334794998
4 25113 0.06430360674858093
5 25113 0.04461725801229477
6 25113 0.03788451850414276
7 25113 0.03136356174945831
8 25113 0.0459638349711895
9 25113 0.021320996806025505
10 25113 0.061609506607055664
11 25113 0.0
12 25113 0.04312024638056755
13 25113 0.0
14 25113 0.060679156333208084
15 25113 0.03714832663536072
16 25113 0.037803396582603455
17 25113 0.028122054412961006
18 25113 0.039919059723615646
19 25113 0.0
20 25113 0.045487742871046066
21 25113 0.052593596279621124
22 25113 0.028257913887500763
23 25113 0.0495942160487175
24 25113 0.056365422904491425
25 25113 0.0362728089094162
26 25113 0.05923542007803917
27 25113 0.1006850078701973
28 25113 0.03331019729375839
29 25113 0.04416158050298691
30 25113 0.040063027292490005
31 25113 0.002212047576904297
32 25113 0.08308432251214981
33 25113 0.016395755112171173
34 25113 0.03065687231719494
35 25113 0.03734596073627472
36 25113 0.019846022129058838
37 25113 0.027112390846014023
38 25113 0.03439401462674141
39 25113 0.02214072085916996
40 25113 0.03494180366396904
41 25113 0.008515149354934692
42 25113 0.011891767382621765
43 25113 0.010691027157008648
44 25113 0.045488789677619934
45 25113 0.05645596981048584
46 25113 0.040785692632198334
47 25113 0.04514461010694504
48 25113 0.02735382691025734
49 25113 0.035806793719530106
50 25113 0.032698504626750946
51 25113 0.0192917138338089
52 25113 0.04469749704003334
53 25113 0.05354570597410202
54 25113 0.04702352359890938
55 25113 0.03247707337141037
56 25113 0.06598847359418869
57 25113 0.02482965774834156
58 25113 0.04426547884941101
59 25113 0.000535130500793457
60 25113 0.03413650393486023
61 25113 0.04040592536330223
62 25113 0.044937070459127426
63 25113 0.05346042662858963
64 25113 0.06474883109331131
65 25113 0.0777837336063385
66 25113 0.0392397940158844
67 25113 0.023483887314796448
68 25113 0.029994692653417587
69 25113 0.03389693424105644
70 25113 0.04734343662858009
71 25113 0.05400635674595833
72 25113 0.0
73 25113 0.02676744945347309
74 25113 0.054617103189229965
75 25113 0.0599687360227108
76 25113 0.04462748393416405
77 25113 0.045823197811841965
78 25113 0.032340604811906815
79 25113 0.0
80 25113 0.01977958157658577
81 25113 0.0251235943287611
82 25113 0.05966316908597946
83 25113 0.03527718782424927
84 25113 0.027609873563051224
85 25113 0.0751572921872139
86 25113 0.037304650992155075
87 25113 0.033280402421951294
88 25113 0.028455276042222977
89 25113 0.07154490798711777
90 25113 0.03407895565032959
91 25113 0.040078938007354736
92 25113 0.06135931611061096
93 25113 0.056826382875442505
94 25113 0.048265490680933
95 25113 0.0429602786898613
96 25113 0.03942397981882095
97 25113 0.18376269936561584
98 25113 0.02946281246840954
99 25113 0.04720328375697136
100 25113 0.030404839664697647
101 25113 0.022647015750408173
102 25113 0.003535086987540126
103 25113 0.0310078002512455
104 25113 0.04955514892935753
105 25113 0.022925328463315964
106 25113 0.010511470027267933
107 25113 0.09089042991399765
108 25113 0.028939854353666306
109 25113 0.04767332226037979
110 25113 0.028360627591609955
111 25113 0.034953176975250244
112 25113 0.02245768904685974
113 25113 0.046920571476221085
114 25113 0.045851632952690125
115 25113 0.05543976649641991
116 25113 0.071201391518116
117 25113 0.04594863951206207
118 25113 0.04419313371181488
119 25113 0.05355999991297722
120 25113 0.05755108222365379
121 25113 0.05566423758864403
122 25113 0.018114052712917328
123 25113 0.06915845721960068
124 25113 0.054913125932216644
125 25113 0.051081493496894836
train - Global loss: 0.040702    Embedding norm: 1.0000   Triplets (all/active): 199.3/370.0
Pos dist (min/mean/max): 0.4103/0.6294/0.9054   Neg dist (min/mean/max): 1.0159/1.4089/1.7089
0 1011 0.18922485411167145
1 1011 0.17265057563781738
2 1011 0.24178071320056915
3 1011 0.19721241295337677
4 1011 0.2613930106163025
5 1011 0.18217019736766815
val - Global loss: 0.207405    Embedding norm: 1.0000   Triplets (all/active): 168.5/19838.8
Pos dist (min/mean/max): 0.5394/0.8691/1.2147   Neg dist (min/mean/max): 0.5480/1.2434/1.6461
0 25113 0.039921365678310394
1 25113 0.03286416828632355
2 25113 0.02836158312857151
3 25113 0.029001833871006966
4 25113 0.0688401386141777
5 25113 0.03744934871792793
6 25113 0.016871439293026924
7 25113 0.05624019727110863
8 25113 0.04860897734761238
9 25113 0.04784323275089264
10 25113 0.041960399597883224
11 25113 0.03740179166197777
12 25113 0.037994928658008575
13 25113 0.04758485406637192
14 25113 0.04522771015763283
15 25113 0.09158892929553986
16 25113 0.01964668743312359
17 25113 0.0419851653277874
18 25113 0.02646673657000065
19 25113 0.03481626510620117
20 25113 0.0448705293238163
21 25113 0.04467812553048134
22 25113 0.045966338366270065
23 25113 0.037902846932411194
24 25113 0.04350624978542328
25 25113 0.05298591032624245
26 25113 0.036650415509939194
27 25113 0.0529807023704052
28 25113 0.027399946004152298
29 25113 0.049646224826574326
30 25113 0.021697910502552986
31 25113 0.05954696610569954
32 25113 0.05585120618343353
33 25113 0.039885248988866806
34 25113 0.07362984865903854
35 25113 0.03683432936668396
36 25113 0.008310377597808838
37 25113 0.03312958404421806
38 25113 0.04326455295085907
39 25113 0.02899145521223545
40 25113 0.009834903292357922
41 25113 0.04283036291599274
42 25113 0.010812461376190186
43 25113 0.04109254851937294
44 25113 0.03322833776473999
45 25113 0.04830131307244301
46 25113 0.030259467661380768
47 25113 0.05787202715873718
48 25113 0.05947079136967659
49 25113 0.036286644637584686
50 25113 0.06717672944068909
51 25113 0.014910326339304447
52 25113 0.04104297608137131
53 25113 0.04820869490504265
54 25113 0.03813719004392624
55 25113 0.04586772248148918
56 25113 0.045661065727472305
57 25113 0.03241736441850662
58 25113 0.04387756437063217
59 25113 0.004031121730804443
60 25113 0.04578439146280289
61 25113 0.03735894337296486
62 25113 0.021040692925453186
63 25113 0.041224099695682526
64 25113 0.07454464584589005
65 25113 0.016116760671138763
66 25113 0.03547760099172592
67 25113 0.03379766270518303
68 25113 0.029884016141295433
69 25113 0.03103749454021454
70 25113 0.007405579090118408
71 25113 0.0673031359910965
72 25113 0.04529379680752754
73 25113 0.034705840051174164
74 25113 0.02998759038746357
75 25113 0.043685875833034515
76 25113 0.04436738044023514
77 25113 0.05475906655192375
78 25113 0.030209368094801903
79 25113 0.045100945979356766
80 25113 0.006846835371106863
81 25113 0.01871936023235321
82 25113 0.048160795122385025
83 25113 0.03808484226465225
84 25113 0.03384114429354668
85 25113 0.07531203329563141
86 25113 0.0
87 25113 0.009670525789260864
88 25113 0.06354864686727524
89 25113 0.06857773661613464
90 25113 0.03036903589963913
91 25113 0.0
92 25113 0.04607726261019707
93 25113 0.046791572123765945
94 25113 0.03438543900847435
95 25113 0.030145099386572838
96 25113 0.04985843598842621
97 25113 0.12303324043750763
98 25113 0.027243221178650856
99 25113 0.03527555987238884
100 25113 0.04807833954691887
101 25113 0.07516875118017197
102 25113 0.03979777917265892
103 25113 0.030867794528603554
104 25113 0.014200770296156406
105 25113 0.039165958762168884
106 25113 0.037400394678115845
107 25113 0.041880227625370026
108 25113 0.025903772562742233
109 25113 0.04163747280836105
110 25113 0.03482082858681679
111 25113 0.03951156511902809
112 25113 0.000209808349609375
113 25113 0.013446114957332611
114 25113 0.0377030186355114
115 25113 0.04287273809313774
116 25113 0.019976520910859108
117 25113 0.06465073674917221
118 25113 0.020019780844449997
119 25113 0.06723145395517349
120 25113 0.04418421536684036
121 25113 0.03326613828539848
122 25113 0.05675150081515312
123 25113 0.04203709214925766
124 25113 0.053995829075574875
125 25113 0.046051301062107086
train - Global loss: 0.039568    Embedding norm: 1.0000   Triplets (all/active): 199.3/277.9
Pos dist (min/mean/max): 0.4100/0.6312/0.9063   Neg dist (min/mean/max): 1.0389/1.4100/1.7029
0 1011 0.17498750984668732
1 1011 0.17694687843322754
2 1011 0.22226150333881378
3 1011 0.17798225581645966
4 1011 0.238075852394104
5 1011 0.17548811435699463
val - Global loss: 0.194290    Embedding norm: 1.0000   Triplets (all/active): 168.5/18990.7
Pos dist (min/mean/max): 0.5870/0.8887/1.2585   Neg dist (min/mean/max): 0.6074/1.2622/1.6498
0 25113 0.08382491022348404
1 25113 0.03258293867111206
2 25113 0.013300830498337746
3 25113 0.008249357342720032
4 25113 0.0
5 25113 0.027366437017917633
6 25113 0.005173375364392996
7 25113 0.037521298974752426
8 25113 0.0
9 25113 0.0
10 25113 0.002357393503189087
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0299370177090168
15 25113 0.3682153522968292
16 25113 0.06086239591240883
17 25113 0.23994353413581848
18 25113 0.033012185245752335
19 25113 0.028866946697235107
20 25113 0.0876745954155922
21 25113 0.05524353310465813
22 25113 0.07375435531139374
23 25113 0.06995172798633575
24 25113 0.080094113945961
25 25113 0.07162168622016907
26 25113 0.05733215808868408
27 25113 0.1146499514579773
28 25113 0.1053527370095253
29 25113 0.08265003561973572
30 25113 0.09451192617416382
31 25113 0.07738430798053741
32 25113 0.09241515398025513
33 25113 0.06245467811822891
34 25113 0.08422816544771194
35 25113 0.042452167719602585
36 25113 0.07139946520328522
37 25113 0.049363601952791214
38 25113 0.08542493730783463
39 25113 0.06241770461201668
40 25113 0.09003385901451111
41 25113 0.06341488659381866
42 25113 0.0541495606303215
43 25113 0.05460207164287567
44 25113 0.056808218359947205
45 25113 0.06183311715722084
46 25113 0.08337372541427612
47 25113 0.05036427453160286
48 25113 0.05026126652956009
49 25113 0.10667949914932251
50 25113 0.0514603927731514
51 25113 0.10013913363218307
52 25113 0.05676154047250748
53 25113 0.048122912645339966
54 25113 0.0210105087608099
55 25113 0.05134451761841774
56 25113 0.05780976265668869
57 25113 0.05709129571914673
58 25113 0.03780383616685867
59 25113 0.05581142008304596
60 25113 0.03474397212266922
61 25113 0.04451178014278412
62 25113 0.0377282053232193
63 25113 0.026656320318579674
64 25113 0.05270994454622269
65 25113 0.041261572390794754
66 25113 0.040728598833084106
67 25113 0.06932377070188522
68 25113 0.06070474535226822
69 25113 0.052120909094810486
70 25113 0.06014840304851532
71 25113 0.09806548058986664
72 25113 0.032301828265190125
73 25113 0.03470069169998169
74 25113 0.040018267929553986
75 25113 0.0626847967505455
76 25113 0.04453987255692482
77 25113 0.040947407484054565
78 25113 0.04813520610332489
79 25113 0.0
80 25113 0.03679521381855011
81 25113 0.04227570444345474
82 25113 0.029316149652004242
83 25113 0.04340898245573044
84 25113 0.04248951002955437
85 25113 0.0746697336435318
86 25113 0.0418756902217865
87 25113 0.04778388515114784
88 25113 0.031367674469947815
89 25113 0.06395597755908966
90 25113 0.0
91 25113 0.06878429651260376
92 25113 0.05241480842232704
93 25113 0.06864023208618164
94 25113 0.05359047278761864
95 25113 0.06883344799280167
96 25113 0.04094122722744942
97 25113 0.09395938366651535
98 25113 0.059150904417037964
99 25113 0.036340683698654175
100 25113 0.07271797955036163
101 25113 0.04345288500189781
102 25113 0.02446405403316021
103 25113 0.02828317880630493
104 25113 0.013695335946977139
105 25113 0.03163646161556244
106 25113 0.037907399237155914
107 25113 0.040494173765182495
108 25113 0.037119049578905106
109 25113 0.04622628539800644
110 25113 0.034735508263111115
111 25113 0.02816205844283104
112 25113 0.022584915161132812
113 25113 0.014998946338891983
114 25113 0.01893550157546997
115 25113 0.03850771114230156
116 25113 0.04024717956781387
117 25113 0.041883960366249084
118 25113 0.061094265431165695
119 25113 0.028463110327720642
120 25113 0.06467773765325546
121 25113 0.025385035201907158
122 25113 0.044310394674539566
123 25113 0.06096997112035751
124 25113 0.04359553009271622
125 25113 0.04377489164471626
train - Global loss: 0.052440    Embedding norm: 1.0000   Triplets (all/active): 199.3/1103.9
Pos dist (min/mean/max): 0.4274/0.6605/0.9482   Neg dist (min/mean/max): 1.0183/1.4098/1.7110
0 1011 0.20306265354156494
1 1011 0.18257270753383636
2 1011 0.2034459263086319
3 1011 0.17614515125751495
4 1011 0.31256693601608276
5 1011 0.06924828141927719
val - Global loss: 0.191174    Embedding norm: 1.0000   Triplets (all/active): 168.5/20266.7
Pos dist (min/mean/max): 0.4823/0.7985/1.1641   Neg dist (min/mean/max): 0.4859/1.2059/1.6347
0 25113 0.10468212515115738
1 25113 0.02487260289490223
2 25113 0.04174872860312462
3 25113 0.046775203198194504
4 25113 0.10382700711488724
5 25113 0.021160373464226723
6 25113 0.03787728026509285
7 25113 0.0
8 25113 0.035005535930395126
9 25113 0.04215755686163902
10 25113 0.030041245743632317
11 25113 0.04265763983130455
12 25113 0.01794024370610714
13 25113 0.012904107570648193
14 25113 0.0585995614528656
15 25113 0.058685414493083954
16 25113 0.05739415064454079
17 25113 0.05997592583298683
18 25113 0.04077178239822388
19 25113 0.004253089427947998
20 25113 0.015128829516470432
21 25113 0.04106193035840988
22 25113 0.035795651376247406
23 25113 0.045096978545188904
24 25113 0.03265608102083206
25 25113 0.04384065419435501
26 25113 0.027770964428782463
27 25113 0.08943236619234085
28 25113 0.06824863702058792
29 25113 0.04103899002075195
30 25113 0.026721669360995293
31 25113 0.03326268866658211
32 25113 0.04600191116333008
33 25113 0.0236086193472147
34 25113 0.04986381530761719
35 25113 0.04642421379685402
36 25113 0.0
37 25113 0.04053758084774017
38 25113 0.03507388383150101
39 25113 0.02622615359723568
40 25113 0.01031571626663208
41 25113 0.0
42 25113 0.0070847272872924805
43 25113 0.03729218989610672
44 25113 0.030385751277208328
45 25113 0.05657321959733963
46 25113 0.02385403774678707
47 25113 0.03905114158987999
48 25113 0.03699853643774986
49 25113 0.03817794471979141
50 25113 0.039319880306720734
51 25113 0.030978135764598846
52 25113 0.045359380543231964
53 25113 0.04349268227815628
54 25113 0.03159349784255028
55 25113 0.047216735780239105
56 25113 0.0418911911547184
57 25113 0.04109105467796326
58 25113 0.03208956867456436
59 25113 0.05362985283136368
60 25113 0.03214557096362114
61 25113 0.0414205938577652
62 25113 0.03659746050834656
63 25113 0.05230177938938141
64 25113 0.062411464750766754
65 25113 0.042510826140642166
66 25113 0.02963045984506607
67 25113 0.03249993920326233
68 25113 0.04310834780335426
69 25113 0.012956048361957073
70 25113 0.03154696151614189
71 25113 0.05885486304759979
72 25113 0.023540480062365532
73 25113 0.05318081006407738
74 25113 0.10070986300706863
75 25113 0.03483889251947403
76 25113 0.033839669078588486
77 25113 0.05976391211152077
78 25113 0.039682600647211075
79 25113 0.0
80 25113 0.03573263809084892
81 25113 0.0
82 25113 0.04787368327379227
83 25113 0.040215685963630676
84 25113 0.061558570712804794
85 25113 0.059711601585149765
86 25113 0.009598225355148315
87 25113 0.012454122304916382
88 25113 0.07313897460699081
89 25113 0.07725093513727188
90 25113 0.02393309772014618
91 25113 0.0566457137465477
92 25113 0.035685159265995026
93 25113 0.07684841006994247
94 25113 0.025747090578079224
95 25113 0.024324871599674225
96 25113 0.05469612032175064
97 25113 0.05399918928742409
98 25113 0.03394833207130432
99 25113 0.04239663854241371
100 25113 0.04272085055708885
101 25113 0.11270932108163834
102 25113 0.02595636621117592
103 25113 0.03813239559531212
104 25113 0.042416494339704514
105 25113 0.029359033331274986
106 25113 0.03724561259150505
107 25113 0.03239170089364052
108 25113 0.03884390369057655
109 25113 0.035777125507593155
110 25113 0.05046740546822548
111 25113 0.023415857926011086
112 25113 0.0
113 25113 0.04014947637915611
114 25113 0.023476766422390938
115 25113 0.037355925887823105
116 25113 0.0495372898876667
117 25113 0.07350657135248184
118 25113 0.04356832429766655
119 25113 0.07359877228736877
120 25113 0.03203919902443886
121 25113 0.03028956428170204
122 25113 0.03184187412261963
123 25113 0.04153378680348396
124 25113 0.022049743682146072
125 25113 0.03333648294210434
train - Global loss: 0.039719    Embedding norm: 1.0000   Triplets (all/active): 199.3/287.9
Pos dist (min/mean/max): 0.4130/0.6313/0.8973   Neg dist (min/mean/max): 1.0302/1.4091/1.7078
0 1011 0.2297879010438919
1 1011 0.19681859016418457
2 1011 0.23890314996242523
3 1011 0.18561549484729767
4 1011 0.26869621872901917
5 1011 0.13817574083805084
val - Global loss: 0.209666    Embedding norm: 1.0000   Triplets (all/active): 168.5/20438.0
Pos dist (min/mean/max): 0.5257/0.8533/1.1959   Neg dist (min/mean/max): 0.5263/1.2523/1.6401
0 25113 0.0681019276380539
1 25113 0.029757091775536537
2 25113 0.05663684010505676
3 25113 0.02980172634124756
4 25113 0.0290849506855011
5 25113 0.058162394911050797
6 25113 0.02722516655921936
7 25113 0.00968623161315918
8 25113 0.03572428598999977
9 25113 0.03267752379179001
10 25113 0.03424365445971489
11 25113 0.030974697321653366
12 25113 0.0297240037471056
13 25113 0.01982903480529785
14 25113 0.047412388026714325
15 25113 0.04258467257022858
16 25113 0.0430404469370842
17 25113 0.03946639597415924
18 25113 0.018702832981944084
19 25113 0.0
20 25113 0.02979235351085663
21 25113 0.016719350591301918
22 25113 0.029795091599225998
23 25113 0.03778471797704697
24 25113 0.04444791004061699
25 25113 0.04040919244289398
26 25113 0.021667957305908203
27 25113 0.033053088933229446
28 25113 0.007075786590576172
29 25113 0.03744375333189964
30 25113 0.0345415435731411
31 25113 0.00682300329208374
32 25113 0.04451410472393036
33 25113 0.0
34 25113 0.04041948541998863
35 25113 0.06277401745319366
36 25113 0.029419464990496635
37 25113 0.04276031255722046
38 25113 0.04277567192912102
39 25113 0.016609851270914078
40 25113 0.03106905147433281
41 25113 0.02856878936290741
42 25113 0.019411981105804443
43 25113 0.024973660707473755
44 25113 0.02552117593586445
45 25113 0.032213956117630005
46 25113 0.0734512209892273
47 25113 0.023268096148967743
48 25113 0.024420971050858498
49 25113 0.033785901963710785
50 25113 0.04445556923747063
51 25113 0.030431751161813736
52 25113 0.02427850291132927
53 25113 0.03758254274725914
54 25113 0.03210348263382912
55 25113 0.044261183589696884
56 25113 0.06602589786052704
57 25113 0.052447978407144547
58 25113 0.03573433682322502
59 25113 0.030677741393446922
60 25113 0.02255978249013424
61 25113 0.0335586778819561
62 25113 0.018647463992238045
63 25113 0.05157613381743431
64 25113 0.05732924863696098
65 25113 0.0018548071384429932
66 25113 0.016347568482160568
67 25113 0.030797729268670082
68 25113 0.037401940673589706
69 25113 0.0553508885204792
70 25113 0.05078066885471344
71 25113 0.04670613259077072
72 25113 0.022639280185103416
73 25113 0.048526450991630554
74 25113 0.030504392459988594
75 25113 0.040403127670288086
76 25113 0.02392439730465412
77 25113 0.04822354391217232
78 25113 0.03990434482693672
79 25113 0.0
80 25113 0.0
81 25113 0.023419661447405815
82 25113 0.019951893016695976
83 25113 0.05136984959244728
84 25113 0.04171512648463249
85 25113 0.05097748711705208
86 25113 0.03795504570007324
87 25113 0.04116089642047882
88 25113 0.03936769813299179
89 25113 0.036745667457580566
90 25113 0.04559670016169548
91 25113 0.02014254406094551
92 25113 0.03724955394864082
93 25113 0.06958450376987457
94 25113 0.037132516503334045
95 25113 0.0279080867767334
96 25113 0.03823684900999069
97 25113 0.050005894154310226
98 25113 0.03331754729151726
99 25113 0.0572628527879715
100 25113 0.05689140409231186
101 25113 0.034624334424734116
102 25113 0.05621582642197609
103 25113 0.04064777493476868
104 25113 0.029356995597481728
105 25113 0.00894549023360014
106 25113 0.016131682321429253
107 25113 0.02942373976111412
108 25113 0.006973744835704565
109 25113 0.018450014293193817
110 25113 0.03420228511095047
111 25113 0.008681035600602627
112 25113 0.03488947078585625
113 25113 0.0
114 25113 0.027442961931228638
115 25113 0.029454346746206284
116 25113 0.03771912306547165
117 25113 0.04079503193497658
118 25113 0.03137202188372612
119 25113 0.014136448502540588
120 25113 0.04517572000622749
121 25113 0.054422102868556976
122 25113 0.03033073991537094
123 25113 0.058519862592220306
124 25113 0.02341429702937603
125 25113 0.014877463690936565
train - Global loss: 0.033616    Embedding norm: 1.0000   Triplets (all/active): 199.3/217.3
Pos dist (min/mean/max): 0.4032/0.6229/0.8839   Neg dist (min/mean/max): 1.0434/1.4095/1.6946
0 1011 0.2410481572151184
1 1011 0.1939540058374405
2 1011 0.26852262020111084
3 1011 0.210877925157547
4 1011 0.3264659345149994
5 1011 0.1769949048757553
val - Global loss: 0.236311    Embedding norm: 1.0000   Triplets (all/active): 168.5/22328.3
Pos dist (min/mean/max): 0.4674/0.8218/1.2249   Neg dist (min/mean/max): 0.4820/1.1758/1.6261
0 25113 0.04069793224334717
1 25113 0.04943027347326279
2 25113 0.041830308735370636
3 25113 0.0450388602912426
4 25113 0.04965375363826752
5 25113 0.044655174016952515
6 25113 0.03632420301437378
7 25113 0.0
8 25113 0.0
9 25113 0.04249485582113266
10 25113 0.03271717578172684
11 25113 0.02708587981760502
12 25113 0.022788044065237045
13 25113 0.013834020122885704
14 25113 0.02752159908413887
15 25113 0.018284423276782036
16 25113 0.019989538937807083
17 25113 0.03484019264578819
18 25113 0.02316376566886902
19 25113 0.0
20 25113 0.005324751138687134
21 25113 0.024570787325501442
22 25113 0.04287301003932953
23 25113 0.02727237343788147
24 25113 0.01253923773765564
25 25113 0.04244241863489151
26 25113 0.02508804015815258
27 25113 0.054265521466732025
28 25113 0.0
29 25113 0.03829812631011009
30 25113 0.045361388474702835
31 25113 0.047359272837638855
32 25113 0.03903196379542351
33 25113 0.028015751391649246
34 25113 0.04173160716891289
35 25113 0.046199291944503784
36 25113 0.0
37 25113 0.023242220282554626
38 25113 0.023018663749098778
39 25113 0.011725729331374168
40 25113 0.05830498784780502
41 25113 0.0
42 25113 0.03144467994570732
43 25113 0.0
44 25113 0.041725967079401016
45 25113 0.0416543111205101
46 25113 0.040022242814302444
47 25113 0.03217152878642082
48 25113 0.07948759198188782
49 25113 0.01572324149310589
50 25113 0.0879499763250351
51 25113 0.02146001346409321
52 25113 0.029117990285158157
53 25113 0.044142525643110275
54 25113 0.021734535694122314
55 25113 0.05606744810938835
56 25113 0.0630519762635231
57 25113 0.05507821589708328
58 25113 0.015075087547302246
59 25113 0.009703636169433594
60 25113 0.01133476197719574
61 25113 0.03392008692026138
62 25113 0.036464620381593704
63 25113 0.05522269010543823
64 25113 0.05183880031108856
65 25113 0.02767263725399971
66 25113 0.017326222732663155
67 25113 0.038950029760599136
68 25113 0.0936371460556984
69 25113 0.02887202799320221
70 25113 0.10279029607772827
71 25113 0.04275655746459961
72 25113 0.0
73 25113 0.0181842353194952
74 25113 0.030711660161614418
75 25113 0.01714366115629673
76 25113 0.0
77 25113 0.05169801414012909
78 25113 0.045027900487184525
79 25113 0.03404923528432846
80 25113 0.0
81 25113 0.01909903809428215
82 25113 0.07401049137115479
83 25113 0.06777212768793106
84 25113 0.05167602375149727
85 25113 0.054882798343896866
86 25113 0.025702357292175293
87 25113 0.007990768179297447
88 25113 0.015845293179154396
89 25113 0.04069775342941284
90 25113 0.019357360899448395
91 25113 0.0
92 25113 0.030699554830789566
93 25113 0.05718997120857239
94 25113 0.03440150246024132
95 25113 0.04125017672777176
96 25113 0.027988553047180176
97 25113 0.04743295907974243
98 25113 0.06303476542234421
99 25113 0.04411252960562706
100 25113 0.07562077790498734
101 25113 0.05240600183606148
102 25113 0.011350991204380989
103 25113 0.011641820892691612
104 25113 0.016720294952392578
105 25113 0.028782833367586136
106 25113 0.018267955631017685
107 25113 0.02534586563706398
108 25113 0.035058461129665375
109 25113 0.04203546419739723
110 25113 0.04027748852968216
111 25113 0.024023503065109253
112 25113 0.0
113 25113 0.030903508886694908
114 25113 0.008201658725738525
115 25113 0.0296446792781353
116 25113 0.0379490852355957
117 25113 0.03465914726257324
118 25113 0.02384808473289013
119 25113 0.04386637359857559
120 25113 0.020893776789307594
121 25113 0.021040476858615875
122 25113 0.05050473287701607
123 25113 0.04880151525139809
124 25113 0.0420236773788929
125 25113 0.02531265653669834
train - Global loss: 0.032957    Embedding norm: 1.0000   Triplets (all/active): 199.3/173.6
Pos dist (min/mean/max): 0.3990/0.6161/0.8814   Neg dist (min/mean/max): 1.0469/1.4102/1.6995
0 1011 0.21200589835643768
1 1011 0.19782377779483795
2 1011 0.19837479293346405
3 1011 0.18343566358089447
4 1011 0.2639833390712738
5 1011 0.24000513553619385
val - Global loss: 0.215938    Embedding norm: 1.0000   Triplets (all/active): 168.5/19422.5
Pos dist (min/mean/max): 0.5360/0.8427/1.2152   Neg dist (min/mean/max): 0.5164/1.2232/1.6345
0 25113 0.03828735277056694
1 25113 0.032991599291563034
2 25113 0.029209289699792862
3 25113 0.021935271099209785
4 25113 0.0
5 25113 0.016643567010760307
6 25113 0.03590665012598038
7 25113 0.008859708905220032
8 25113 0.030380481854081154
9 25113 0.034258805215358734
10 25113 0.035962339490652084
11 25113 0.03126085177063942
12 25113 0.01797974854707718
13 25113 0.029854029417037964
14 25113 0.030493328347802162
15 25113 0.04634012281894684
16 25113 0.02446918934583664
17 25113 0.02254454232752323
18 25113 0.014584807679057121
19 25113 0.0387810654938221
20 25113 0.05114278197288513
21 25113 0.021225761622190475
22 25113 0.03216494619846344
23 25113 0.04410877451300621
24 25113 0.0466153621673584
25 25113 0.03376191854476929
26 25113 0.028788972645998
27 25113 0.08324038237333298
28 25113 0.04539298266172409
29 25113 0.05272340402007103
30 25113 0.022859737277030945
31 25113 0.02084367349743843
32 25113 0.06224856525659561
33 25113 0.036382123827934265
34 25113 0.03717287629842758
35 25113 0.03620469570159912
36 25113 0.03286357969045639
37 25113 0.044831737875938416
38 25113 0.025092167779803276
39 25113 0.04951460286974907
40 25113 0.03621450811624527
41 25113 0.03736165910959244
42 25113 0.03255026787519455
43 25113 0.033818334341049194
44 25113 0.01587817072868347
45 25113 0.10901186615228653
46 25113 0.01325297076255083
47 25113 0.0473385788500309
48 25113 0.029527680948376656
49 25113 0.020713865756988525
50 25113 0.03407692909240723
51 25113 0.0
52 25113 0.0341884084045887
53 25113 0.050645772367715836
54 25113 0.0
55 25113 0.03388978913426399
56 25113 0.03040659986436367
57 25113 0.03235159069299698
58 25113 0.05217430368065834
59 25113 0.024126438423991203
60 25113 0.0
61 25113 0.03400614857673645
62 25113 0.03243010863661766
63 25113 0.0307143721729517
64 25113 0.05079556256532669
65 25113 0.04026677459478378
66 25113 0.004964292049407959
67 25113 0.0003376007080078125
68 25113 0.02638174593448639
69 25113 0.05915150046348572
70 25113 0.048037584871053696
71 25113 0.05321846902370453
72 25113 0.016785264015197754
73 25113 0.021840602159500122
74 25113 0.02437908761203289
75 25113 0.0384787917137146
76 25113 0.007661407347768545
77 25113 0.060744307935237885
78 25113 0.0649162083864212
79 25113 0.01917828619480133
80 25113 0.0
81 25113 0.008644282817840576
82 25113 0.025224389508366585
83 25113 0.014449676498770714
84 25113 0.034800730645656586
85 25113 0.05133095011115074
86 25113 0.021408379077911377
87 25113 0.009398043155670166
88 25113 0.031250961124897
89 25113 0.12481620907783508
90 25113 0.03286873549222946
91 25113 0.021512387320399284
92 25113 0.0
93 25113 0.08043146133422852
94 25113 0.010922557674348354
95 25113 0.021750492975115776
96 25113 0.024216199293732643
97 25113 0.027896348387002945
98 25113 0.0
99 25113 0.04352394491434097
100 25113 0.0
101 25113 0.037869423627853394
102 25113 0.0
103 25113 0.022883102297782898
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.008844375610351562
108 25113 0.0
109 25113 0.30871719121932983
110 25113 0.23508189618587494
111 25113 0.0
112 25113 0.042042285203933716
113 25113 0.03063836693763733
114 25113 0.03712897747755051
115 25113 0.047027625143527985
116 25113 0.0676686093211174
117 25113 0.05755137652158737
118 25113 0.06330425292253494
119 25113 0.0707617849111557
120 25113 0.057577453553676605
121 25113 0.0763683170080185
122 25113 0.05436025932431221
123 25113 0.06525541096925735
124 25113 0.08992619812488556
125 25113 0.062427401542663574
train - Global loss: 0.037060    Embedding norm: 1.0000   Triplets (all/active): 199.3/218.3
Pos dist (min/mean/max): 0.3959/0.6160/0.8861   Neg dist (min/mean/max): 1.0543/1.4121/1.6961
0 1011 0.19865459203720093
1 1011 0.19101020693778992
2 1011 0.2037373036146164
3 1011 0.1980358511209488
4 1011 0.26118069887161255
5 1011 0.2453378289937973
val - Global loss: 0.216326    Embedding norm: 1.0000   Triplets (all/active): 168.5/24505.7
Pos dist (min/mean/max): 0.6669/0.9527/1.2608   Neg dist (min/mean/max): 0.6095/1.2778/1.6794
0 25113 0.045952197164297104
1 25113 0.04123181104660034
2 25113 0.024909354746341705
3 25113 0.09481197595596313
4 25113 0.05550673231482506
5 25113 0.03300033509731293
6 25113 0.0262574702501297
7 25113 0.034541837871074677
8 25113 0.05448660999536514
9 25113 0.030313054099678993
10 25113 0.06908044219017029
11 25113 0.0325150191783905
12 25113 0.03214467316865921
13 25113 0.01276436448097229
14 25113 0.05104067921638489
15 25113 0.021515600383281708
16 25113 0.017873886972665787
17 25113 0.055976711213588715
18 25113 0.038585763424634933
19 25113 0.030225083231925964
20 25113 0.0344991497695446
21 25113 0.04123987630009651
22 25113 0.0327979139983654
23 25113 0.058951836079359055
24 25113 0.03238022327423096
25 25113 0.03625016659498215
26 25113 0.031271059066057205
27 25113 0.032815683633089066
28 25113 0.0
29 25113 0.03018452227115631
30 25113 0.02162310667335987
31 25113 0.0
32 25113 0.057501550763845444
33 25113 0.017299633473157883
34 25113 0.025132032111287117
35 25113 0.02740243263542652
36 25113 0.032141394913196564
37 25113 0.0
38 25113 0.025563601404428482
39 25113 0.04644254967570305
40 25113 0.021232111379504204
41 25113 0.0
42 25113 0.0375126376748085
43 25113 0.020544514060020447
44 25113 0.02497105859220028
45 25113 0.03529544547200203
46 25113 0.05561372637748718
47 25113 0.0375942699611187
48 25113 0.03073924407362938
49 25113 0.02108749747276306
50 25113 0.015980470925569534
51 25113 0.0
52 25113 0.0
53 25113 0.025132521986961365
54 25113 0.015110817737877369
55 25113 0.04658529534935951
56 25113 0.03864094242453575
57 25113 0.023035025224089622
58 25113 0.041597943753004074
59 25113 0.0
60 25113 0.03658697009086609
61 25113 0.0245673768222332
62 25113 0.033629484474658966
63 25113 0.02696712128818035
64 25113 0.04983987659215927
65 25113 0.03107616864144802
66 25113 0.04048722982406616
67 25113 0.03554409742355347
68 25113 0.03273029997944832
69 25113 0.021272122859954834
70 25113 0.04745933413505554
71 25113 0.0990811288356781
72 25113 0.022957801818847656
73 25113 0.015076126903295517
74 25113 0.0353122353553772
75 25113 0.03502191603183746
76 25113 0.02476416900753975
77 25113 0.03896425664424896
78 25113 0.05680437758564949
79 25113 0.0
80 25113 0.008150535635650158
81 25113 0.017078042030334473
82 25113 0.03567367047071457
83 25113 0.019202709197998047
84 25113 0.030010757967829704
85 25113 0.04800450801849365
86 25113 0.0
87 25113 0.0001423656940460205
88 25113 0.045780498534440994
89 25113 0.02667035162448883
90 25113 0.008584086783230305
91 25113 0.023645728826522827
92 25113 0.006196456961333752
93 25113 0.02917422726750374
94 25113 0.022969890385866165
95 25113 0.022030197083950043
96 25113 0.026821397244930267
97 25113 0.03393039479851723
98 25113 0.017133118584752083
99 25113 0.037394456565380096
100 25113 0.03128485754132271
101 25113 0.03023916482925415
102 25113 0.0
103 25113 0.03527950495481491
104 25113 0.01743251085281372
105 25113 0.024740174412727356
106 25113 0.038433533161878586
107 25113 0.03529190644621849
108 25113 0.014770464971661568
109 25113 0.03362409025430679
110 25113 0.028015676885843277
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.003915846347808838
115 25113 0.03550621494650841
116 25113 0.042557310312986374
117 25113 0.025916188955307007
118 25113 0.0031840503215789795
119 25113 0.0428641177713871
120 25113 0.014177083969116211
121 25113 0.0
122 25113 0.032708678394556046
123 25113 0.035450540482997894
124 25113 0.0
125 25113 0.032000832259655
train - Global loss: 0.028580    Embedding norm: 1.0000   Triplets (all/active): 199.3/103.9
Pos dist (min/mean/max): 0.3911/0.6064/0.8625   Neg dist (min/mean/max): 1.0480/1.4095/1.6998
0 1011 0.218177929520607
1 1011 0.19038115441799164
2 1011 0.22053956985473633
3 1011 0.24494242668151855
4 1011 0.2914640009403229
5 1011 0.1866426020860672
val - Global loss: 0.225358    Embedding norm: 1.0000   Triplets (all/active): 168.5/20684.7
Pos dist (min/mean/max): 0.6023/0.8787/1.2175   Neg dist (min/mean/max): 0.5662/1.2392/1.6559
0 25113 0.032122038304805756
1 25113 0.03347686678171158
2 25113 0.04331711307168007
3 25113 0.0373569056391716
4 25113 0.009903371334075928
5 25113 0.03169022127985954
6 25113 0.05588508024811745
7 25113 0.0
8 25113 0.0
9 25113 0.024155473336577415
10 25113 0.030752714723348618
11 25113 0.0
12 25113 0.0
13 25113 0.023076415061950684
14 25113 0.03740774467587471
15 25113 0.03256205841898918
16 25113 0.04726066812872887
17 25113 0.0
18 25113 0.021166861057281494
19 25113 0.0
20 25113 0.015062547288835049
21 25113 0.009034154005348682
22 25113 0.02947540581226349
23 25113 0.03558437153697014
24 25113 0.051435548812150955
25 25113 0.0
26 25113 0.030386772006750107
27 25113 0.05180376023054123
28 25113 0.011775076389312744
29 25113 0.010077237151563168
30 25113 0.025020290166139603
31 25113 0.0
32 25113 0.03607726842164993
33 25113 0.0441674143075943
34 25113 0.03533906862139702
35 25113 0.023380985483527184
36 25113 0.0
37 25113 0.024786675348877907
38 25113 0.028161656111478806
39 25113 0.036904606968164444
40 25113 0.019550053402781487
41 25113 0.02805235981941223
42 25113 0.0
43 25113 0.0
44 25113 0.03688275068998337
45 25113 0.04502349719405174
46 25113 0.02404634654521942
47 25113 0.026126569136977196
48 25113 0.019294381141662598
49 25113 0.0070247650146484375
50 25113 0.032636888325214386
51 25113 0.0
52 25113 0.0
53 25113 0.025010960176587105
54 25113 0.0
55 25113 0.04811789467930794
56 25113 0.026934240013360977
57 25113 0.03960732743144035
58 25113 0.0
59 25113 0.0
60 25113 0.007315933704376221
61 25113 0.0
62 25113 0.0018913845997303724
63 25113 0.016537129878997803
64 25113 0.03542087972164154
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.025083405897021294
69 25113 0.004397690296173096
70 25113 0.028054581955075264
71 25113 0.050177350640296936
72 25113 0.0
73 25113 0.001064389944076538
74 25113 0.02285870909690857
75 25113 0.018264710903167725
76 25113 0.0
77 25113 0.0
78 25113 0.050314005464315414
79 25113 0.0
80 25113 0.02986043691635132
81 25113 0.0
82 25113 0.027029069140553474
83 25113 0.024989426136016846
84 25113 0.01255422830581665
85 25113 0.038095440715551376
86 25113 0.0
87 25113 0.20471800863742828
88 25113 0.05773581936955452
89 25113 0.03967312350869179
90 25113 0.0
91 25113 0.023738743737339973
92 25113 0.015748057514429092
93 25113 0.02781156823039055
94 25113 0.040729641914367676
95 25113 0.026701224967837334
96 25113 0.09296277165412903
97 25113 0.03803803771734238
98 25113 0.028468750417232513
99 25113 0.2143135815858841
100 25113 0.07044743001461029
101 25113 0.10887270420789719
102 25113 0.05498039722442627
103 25113 0.012079847045242786
104 25113 0.03903050720691681
105 25113 0.02534375712275505
106 25113 0.02191678248345852
107 25113 0.04694724082946777
108 25113 0.0856490284204483
109 25113 0.033064961433410645
110 25113 0.036516498774290085
111 25113 0.03974028304219246
112 25113 0.03783903270959854
113 25113 0.04771960899233818
114 25113 0.041557859629392624
115 25113 0.04220877215266228
116 25113 0.06132908910512924
117 25113 0.041612036526203156
118 25113 0.020627519115805626
119 25113 0.043980903923511505
120 25113 0.04558989778161049
121 25113 0.03846554085612297
122 25113 0.025660868734121323
123 25113 0.04656203091144562
124 25113 0.03690345957875252
125 25113 0.053599707782268524
train - Global loss: 0.029363    Embedding norm: 1.0000   Triplets (all/active): 199.3/172.6
Pos dist (min/mean/max): 0.3948/0.6111/0.8841   Neg dist (min/mean/max): 1.0848/1.4136/1.6782
0 1011 0.18333755433559418
1 1011 0.1657244861125946
2 1011 0.1888597160577774
3 1011 0.1787358969449997
4 1011 0.25309544801712036
5 1011 0.16193728148937225
val - Global loss: 0.188615    Embedding norm: 1.0000   Triplets (all/active): 168.5/19585.2
Pos dist (min/mean/max): 0.5983/0.8895/1.2095   Neg dist (min/mean/max): 0.6279/1.2719/1.6291
0 25113 0.0375845842063427
1 25113 0.023733753710985184
2 25113 0.050136499106884
3 25113 0.03402331843972206
4 25113 0.04378214105963707
5 25113 0.05874093994498253
6 25113 0.020559420809149742
7 25113 0.0
8 25113 0.0
9 25113 0.011537847109138966
10 25113 0.09506849199533463
11 25113 0.030107317492365837
12 25113 0.043273065239191055
13 25113 0.0
14 25113 0.03931952267885208
15 25113 0.029109051451086998
16 25113 0.023037489503622055
17 25113 0.03540162369608879
18 25113 0.003734782338142395
19 25113 0.0
20 25113 0.03418298438191414
21 25113 0.02785322442650795
22 25113 0.016308967024087906
23 25113 0.02370031177997589
24 25113 0.03890477493405342
25 25113 0.03581661731004715
26 25113 0.03820740804076195
27 25113 0.04453166201710701
28 25113 0.0
29 25113 0.03743284195661545
30 25113 0.016411278396844864
31 25113 0.0
32 25113 0.04011285677552223
33 25113 0.007247401867061853
34 25113 0.042486317455768585
35 25113 0.011379259638488293
36 25113 0.05356955528259277
37 25113 0.021716764196753502
38 25113 0.043200764805078506
39 25113 0.00749506801366806
40 25113 0.010610908269882202
41 25113 0.0
42 25113 0.01175186038017273
43 25113 0.042133115231990814
44 25113 0.0
45 25113 0.021112047135829926
46 25113 0.027565792202949524
47 25113 0.03267296031117439
48 25113 0.023620128631591797
49 25113 0.0
50 25113 0.026608576998114586
51 25113 0.01435072161257267
52 25113 0.039014384150505066
53 25113 0.009898046962916851
54 25113 0.05541335046291351
55 25113 0.040487825870513916
56 25113 0.023387357592582703
57 25113 0.03566335514187813
58 25113 0.014116436243057251
59 25113 0.024095656350255013
60 25113 0.0
61 25113 0.09283177554607391
62 25113 0.01570500060915947
63 25113 0.08176369220018387
64 25113 0.044026635587215424
65 25113 0.002566039562225342
66 25113 0.042655061930418015
67 25113 0.04028023034334183
68 25113 0.01635780930519104
69 25113 0.02412271499633789
70 25113 0.0322689414024353
71 25113 0.060279205441474915
72 25113 0.020113686099648476
73 25113 0.009711802005767822
74 25113 0.03279024362564087
75 25113 0.04732262343168259
76 25113 0.021467741578817368
77 25113 0.05016901344060898
78 25113 0.023072445765137672
79 25113 0.0
80 25113 0.04048643261194229
81 25113 0.0
82 25113 0.03788967430591583
83 25113 0.043353382498025894
84 25113 0.03472712263464928
85 25113 0.04149261862039566
86 25113 0.011992126703262329
87 25113 0.0
88 25113 0.0
89 25113 0.04368948936462402
90 25113 0.0275083240121603
91 25113 0.020800845697522163
92 25113 0.011645526625216007
93 25113 0.03976453095674515
94 25113 0.035279735922813416
95 25113 0.021349584683775902
96 25113 0.03262324631214142
97 25113 0.011921106837689877
98 25113 0.05793501436710358
99 25113 0.027822209522128105
100 25113 0.034642186015844345
101 25113 0.04592449590563774
102 25113 0.0
103 25113 0.004921533167362213
104 25113 0.013665720820426941
105 25113 0.01660752296447754
106 25113 0.019264236092567444
107 25113 0.020325124263763428
108 25113 0.003493085503578186
109 25113 0.03986189886927605
110 25113 0.03483769670128822
111 25113 0.023108910769224167
112 25113 0.0
113 25113 0.012989685870707035
114 25113 0.0
115 25113 0.02745005115866661
116 25113 0.04102424159646034
117 25113 0.05554936081171036
118 25113 0.019252372905611992
119 25113 0.04998870566487312
120 25113 0.024014335125684738
121 25113 0.0357954241335392
122 25113 0.0233647171407938
123 25113 0.03441225737333298
124 25113 0.0
125 25113 0.04067425802350044
train - Global loss: 0.026914    Embedding norm: 1.0000   Triplets (all/active): 199.3/94.1
Pos dist (min/mean/max): 0.3880/0.6036/0.8596   Neg dist (min/mean/max): 1.0576/1.4107/1.6929
0 1011 0.21354974806308746
1 1011 0.19684883952140808
2 1011 0.24051499366760254
3 1011 0.18427887558937073
4 1011 0.29562467336654663
5 1011 0.1805032342672348
val - Global loss: 0.218553    Embedding norm: 1.0000   Triplets (all/active): 168.5/21134.8
Pos dist (min/mean/max): 0.5720/0.8781/1.2371   Neg dist (min/mean/max): 0.5324/1.2312/1.6312
0 25113 0.02227221429347992
1 25113 0.026317941024899483
2 25113 0.025170711800456047
3 25113 0.001642376184463501
4 25113 0.0
5 25113 0.021855730563402176
6 25113 0.0036156773567199707
7 25113 0.0
8 25113 0.0
9 25113 0.01932622492313385
10 25113 0.036496806889772415
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.018696511164307594
15 25113 0.0
16 25113 0.016670793294906616
17 25113 0.020263100042939186
18 25113 0.003870934247970581
19 25113 0.031793300062417984
20 25113 0.0
21 25113 0.0
22 25113 0.029613925144076347
23 25113 0.03780404478311539
24 25113 0.008038163185119629
25 25113 0.036851637065410614
26 25113 0.0
27 25113 0.03650622069835663
28 25113 0.0
29 25113 0.011672387830913067
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0444227010011673
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.026278555393218994
43 25113 0.0
44 25113 0.01835760474205017
45 25113 0.006414055824279785
46 25113 0.0
47 25113 0.0
48 25113 0.07747317850589752
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.024307044222950935
56 25113 0.029059838503599167
57 25113 0.03756259009242058
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.02108818292617798
64 25113 0.039616674184799194
65 25113 0.029010100290179253
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.0210447795689106
71 25113 0.014478027820587158
72 25113 0.0
73 25113 0.007975876331329346
74 25113 0.0
75 25113 0.0306900292634964
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.020114243030548096
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.003808259963989258
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.04082844778895378
90 25113 0.44431984424591064
91 25113 0.0
92 25113 0.0
93 25113 0.03176698088645935
94 25113 0.0
95 25113 0.021899186074733734
96 25113 0.017535308375954628
97 25113 0.052777249366045
98 25113 0.021271467208862305
99 25113 0.02947806939482689
100 25113 0.042530160397291183
101 25113 0.0
102 25113 0.02454380691051483
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.02102382481098175
109 25113 0.002848386764526367
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.028110476210713387
117 25113 0.018682390451431274
118 25113 0.0
119 25113 0.008282512426376343
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
train - Global loss: 0.013223    Embedding norm: 1.0000   Triplets (all/active): 199.3/252.4
Pos dist (min/mean/max): 0.3841/0.5981/0.8666   Neg dist (min/mean/max): 1.1631/1.4209/1.6394
0 1011 0.21510399878025055
1 1011 0.1805855929851532
2 1011 0.2195856273174286
3 1011 0.18952523171901703
4 1011 0.30453360080718994
5 1011 0.19233198463916779
val - Global loss: 0.216944    Embedding norm: 1.0000   Triplets (all/active): 168.5/20510.0
Pos dist (min/mean/max): 0.5971/0.9005/1.2582   Neg dist (min/mean/max): 0.5798/1.2781/1.6833
0 25113 0.0
1 25113 0.0
2 25113 0.018012791872024536
3 25113 0.0
4 25113 0.0
5 25113 0.008842498064041138
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.029924213886260986
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.05493590980768204
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0402778722345829
33 25113 0.06627392768859863
34 25113 0.06820422410964966
35 25113 0.036996111273765564
36 25113 0.039240483194589615
37 25113 0.038256604224443436
38 25113 0.04759342968463898
39 25113 0.04673834517598152
40 25113 0.030256953090429306
41 25113 0.04228351265192032
42 25113 0.027204224839806557
43 25113 0.012535572052001953
44 25113 0.04150085151195526
45 25113 0.03447766974568367
46 25113 0.04751741513609886
47 25113 0.06101994216442108
48 25113 0.06431121379137039
49 25113 0.09223000705242157
50 25113 0.05671147257089615
51 25113 0.029207218438386917
52 25113 0.037084706127643585
53 25113 0.03740915283560753
54 25113 0.05097399279475212
55 25113 0.03322751075029373
56 25113 0.022821221500635147
57 25113 0.03246462717652321
58 25113 0.03929252550005913
59 25113 0.03669549524784088
60 25113 0.020513594150543213
61 25113 0.030308540910482407
62 25113 0.04363588988780975
63 25113 0.020269915461540222
64 25113 0.028827004134655
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.06385872513055801
69 25113 0.0
70 25113 0.0
71 25113 0.0325276255607605
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.002507925033569336
76 25113 0.0
77 25113 0.009478643536567688
78 25113 0.10869953781366348
79 25113 0.0
80 25113 0.0
81 25113 0.031711041927337646
82 25113 0.026933323591947556
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.021090783178806305
90 25113 0.0
91 25113 0.0
92 25113 0.01903669349849224
93 25113 0.03678135573863983
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.002382442355155945
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.007510349154472351
117 25113 0.006846189498901367
118 25113 0.0
119 25113 0.02791435830295086
120 25113 0.0
121 25113 0.0
122 25113 0.2845834195613861
123 25113 0.03362772613763809
124 25113 0.0
125 25113 0.0
train - Global loss: 0.017330    Embedding norm: 1.0000   Triplets (all/active): 199.3/196.1
Pos dist (min/mean/max): 0.3952/0.6148/0.8946   Neg dist (min/mean/max): 1.1717/1.4231/1.6332
0 1011 0.18818449974060059
1 1011 0.15376290678977966
2 1011 0.20677296817302704
3 1011 0.15207843482494354
4 1011 0.30297914147377014
5 1011 0.19256199896335602
val - Global loss: 0.199390    Embedding norm: 1.0000   Triplets (all/active): 168.5/18724.7
Pos dist (min/mean/max): 0.5393/0.8444/1.1803   Neg dist (min/mean/max): 0.5750/1.2034/1.6308
0 25113 0.009772701188921928
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.18509840965270996
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.1517065167427063
12 25113 0.017659947276115417
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.020040472969412804
23 25113 0.0
24 25113 0.034791599959135056
25 25113 0.0
26 25113 0.0
27 25113 0.04117906838655472
28 25113 0.0
29 25113 0.03086899407207966
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.08033035695552826
48 25113 0.0
49 25113 0.0
50 25113 0.015394210815429688
51 25113 0.02702724188566208
52 25113 0.039601895958185196
53 25113 0.03582016006112099
54 25113 0.0
55 25113 0.03396446630358696
56 25113 0.044764965772628784
57 25113 0.0399010106921196
58 25113 0.03758707270026207
59 25113 0.03710870444774628
60 25113 0.02979796752333641
61 25113 0.03620380163192749
62 25113 0.03747766464948654
63 25113 0.061414774507284164
64 25113 0.05533919483423233
65 25113 0.021113445982336998
66 25113 0.048119597136974335
67 25113 0.06182006001472473
68 25113 0.08138079196214676
69 25113 0.03368862345814705
70 25113 0.0608939565718174
71 25113 0.06154262274503708
72 25113 0.037647027522325516
73 25113 0.03992582485079765
74 25113 0.0430324412882328
75 25113 0.04405324533581734
76 25113 0.02413470670580864
77 25113 0.04355159029364586
78 25113 0.05179055780172348
79 25113 0.0227841567248106
80 25113 0.009842276573181152
81 25113 0.01947689615190029
82 25113 0.03387998789548874
83 25113 0.02251392975449562
84 25113 0.03145410493016243
85 25113 0.05761891230940819
86 25113 0.031094983220100403
87 25113 0.014937043190002441
88 25113 0.027344392612576485
89 25113 0.07245203107595444
90 25113 0.03953743353486061
91 25113 0.020176291465759277
92 25113 0.030542481690645218
93 25113 0.042642682790756226
94 25113 0.03092103824019432
95 25113 0.0
96 25113 0.024812232702970505
97 25113 0.0
98 25113 0.02378714084625244
99 25113 0.02319922298192978
100 25113 0.0206521637737751
101 25113 0.03295709192752838
102 25113 0.028663208708167076
103 25113 0.028742488473653793
104 25113 0.04100241884589195
105 25113 0.012020353227853775
106 25113 0.05019105225801468
107 25113 0.03546610847115517
108 25113 0.03127502650022507
109 25113 0.03594186529517174
110 25113 0.04468236491084099
111 25113 0.004769816994667053
112 25113 0.0
113 25113 0.023632263764739037
114 25113 0.0
115 25113 0.023953935131430626
116 25113 0.03221612423658371
117 25113 0.03494635969400406
118 25113 0.02333461306989193
119 25113 0.036976948380470276
120 25113 0.017701685428619385
121 25113 0.0
122 25113 0.019904891029000282
123 25113 0.0
124 25113 0.0
125 25113 0.02414768934249878
train - Global loss: 0.023315    Embedding norm: 1.0000   Triplets (all/active): 199.3/224.4
Pos dist (min/mean/max): 0.3897/0.6076/0.8770   Neg dist (min/mean/max): 1.1111/1.4173/1.6637
0 1011 0.19825351238250732
1 1011 0.1915280818939209
2 1011 0.21893027424812317
3 1011 0.1876455843448639
4 1011 0.2791103422641754
5 1011 0.20286156237125397
val - Global loss: 0.213055    Embedding norm: 1.0000   Triplets (all/active): 168.5/20376.3
Pos dist (min/mean/max): 0.6133/0.9030/1.2488   Neg dist (min/mean/max): 0.5705/1.2509/1.6511
0 25113 0.03997408598661423
1 25113 0.02536044269800186
2 25113 0.02057282067835331
3 25113 0.03670835494995117
4 25113 0.03953187167644501
5 25113 0.02443872019648552
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.006960511207580566
10 25113 0.011023387312889099
11 25113 0.0
12 25113 0.039989084005355835
13 25113 0.0
14 25113 0.05543781816959381
15 25113 0.05345268175005913
16 25113 0.0032748430967330933
17 25113 0.08558382093906403
18 25113 0.02767826057970524
19 25113 0.0
20 25113 0.01317415852099657
21 25113 0.050481002777814865
22 25113 0.026194361969828606
23 25113 0.017673030495643616
24 25113 0.04079185053706169
25 25113 0.018469013273715973
26 25113 0.0
27 25113 0.02331935428082943
28 25113 0.020783960819244385
29 25113 0.02828621119260788
30 25113 0.018647450953722
31 25113 0.0
32 25113 0.020656108856201172
33 25113 0.03974496200680733
34 25113 0.02946491166949272
35 25113 0.033739302307367325
36 25113 0.0
37 25113 0.0
38 25113 0.04028824716806412
39 25113 0.0
40 25113 0.029730426147580147
41 25113 0.04565441608428955
42 25113 0.025841861963272095
43 25113 0.030967820435762405
44 25113 0.051905374974012375
45 25113 0.027053114026784897
46 25113 0.03367425501346588
47 25113 0.07372789829969406
48 25113 0.005842670798301697
49 25113 0.046035367995500565
50 25113 0.04952796921133995
51 25113 0.00440448522567749
52 25113 0.0
53 25113 0.048372238874435425
54 25113 0.0
55 25113 0.009975597262382507
56 25113 0.02770947478711605
57 25113 0.025473345071077347
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.02992938458919525
63 25113 0.0274102371186018
64 25113 0.04375595971941948
65 25113 0.0
66 25113 0.0
67 25113 0.022091981023550034
68 25113 0.05114537850022316
69 25113 0.008342614397406578
70 25113 0.006775304675102234
71 25113 0.0441148616373539
72 25113 0.02914869785308838
73 25113 0.015791743993759155
74 25113 0.0
75 25113 0.006901271175593138
76 25113 0.005624711513519287
77 25113 0.0
78 25113 0.019942497834563255
79 25113 0.0
80 25113 0.005723714828491211
81 25113 0.0
82 25113 0.018108472228050232
83 25113 0.0077033936977386475
84 25113 0.02465924434363842
85 25113 0.028943253681063652
86 25113 0.003367185592651367
87 25113 0.0
88 25113 0.0
89 25113 0.025610169395804405
90 25113 0.009780168533325195
91 25113 0.0
92 25113 0.0
93 25113 0.026297736912965775
94 25113 0.0
95 25113 0.009123921394348145
96 25113 0.03434350714087486
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.007628500461578369
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.014509737491607666
112 25113 0.0
113 25113 0.0
114 25113 0.034653495997190475
115 25113 0.0
116 25113 0.025158410891890526
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.04951690509915352
121 25113 0.0
122 25113 0.0
123 25113 0.04661036282777786
124 25113 0.0
125 25113 0.0
train - Global loss: 0.016748    Embedding norm: 1.0000   Triplets (all/active): 199.3/33.8
Pos dist (min/mean/max): 0.3911/0.6037/0.8711   Neg dist (min/mean/max): 1.1237/1.4177/1.6620
0 1011 0.20743124186992645
1 1011 0.19905562698841095
2 1011 0.18944600224494934
3 1011 0.22986628115177155
4 1011 0.32447341084480286
5 1011 0.2821572422981262
val - Global loss: 0.238738    Embedding norm: 1.0000   Triplets (all/active): 168.5/20948.8
Pos dist (min/mean/max): 0.6668/0.9427/1.2667   Neg dist (min/mean/max): 0.6278/1.2769/1.6757
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.03320924565196037
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.007211863994598389
25 25113 0.0036554336547851562
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.005765348672866821
46 25113 0.0
47 25113 0.016976237297058105
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.01175239309668541
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.019570350646972656
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.017218926921486855
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.018554598093032837
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.001616746187210083
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
train - Global loss: 0.001076    Embedding norm: 1.0000   Triplets (all/active): 199.3/2.3
Pos dist (min/mean/max): 0.3926/0.6048/0.8753   Neg dist (min/mean/max): 1.2470/1.4263/1.5872
0 1011 0.22012142837047577
1 1011 0.20554053783416748
2 1011 0.20093144476413727
3 1011 0.21040402352809906
4 1011 0.3463927209377289
5 1011 0.20010171830654144
val - Global loss: 0.230582    Embedding norm: 1.0000   Triplets (all/active): 168.5/20696.8
Pos dist (min/mean/max): 0.5938/0.8874/1.2633   Neg dist (min/mean/max): 0.5665/1.2678/1.6843
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.012364000082015991
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.03099440596997738
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.029078254476189613
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0146323312073946
117 25113 0.0
118 25113 0.007173979189246893
119 25113 0.0
120 25113 0.02222287654876709
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
train - Global loss: 0.000924    Embedding norm: 1.0000   Triplets (all/active): 199.3/0.3
Pos dist (min/mean/max): 0.3831/0.5986/0.8539   Neg dist (min/mean/max): 1.2487/1.4285/1.5890
0 1011 0.23362255096435547
1 1011 0.2119116187095642
2 1011 0.20901325345039368
3 1011 0.21472497284412384
4 1011 0.3354801535606384
5 1011 0.29334935545921326
val - Global loss: 0.249684    Embedding norm: 1.0000   Triplets (all/active): 168.5/21479.7
Pos dist (min/mean/max): 0.6334/0.9040/1.2812   Neg dist (min/mean/max): 0.4861/1.2550/1.6823
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.05936932563781738
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.02194499969482422
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.052792854607105255
65 25113 0.0
66 25113 0.006034433841705322
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.0
71 25113 0.036546871066093445
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.01413959264755249
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.013114362955093384
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
train - Global loss: 0.001619    Embedding norm: 1.0000   Triplets (all/active): 199.3/1.7
Pos dist (min/mean/max): 0.3818/0.5953/0.8536   Neg dist (min/mean/max): 1.2548/1.4300/1.5877
0 1011 0.225341796875
1 1011 0.22779393196105957
2 1011 0.2224496752023697
3 1011 0.22889834642410278
4 1011 0.3490508794784546
5 1011 0.3191480040550232
val - Global loss: 0.262114    Embedding norm: 1.0000   Triplets (all/active): 168.5/20858.0
Pos dist (min/mean/max): 0.6414/0.9114/1.2886   Neg dist (min/mean/max): 0.4999/1.2598/1.6872
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.011506497859954834
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.06923162937164307
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.013506710529327393
64 25113 0.02287231758236885
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.05218387767672539
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.022570859640836716
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.02267974615097046
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0620562918484211
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.018397256731987
117 25113 0.0
118 25113 0.0
119 25113 0.026560097932815552
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.01142832636833191
124 25113 0.0
125 25113 0.0
train - Global loss: 0.002643    Embedding norm: 1.0000   Triplets (all/active): 199.3/2.7
Pos dist (min/mean/max): 0.3809/0.5974/0.8590   Neg dist (min/mean/max): 1.2567/1.4283/1.5798
0 1011 0.2074888050556183
1 1011 0.1838676631450653
2 1011 0.1833866983652115
3 1011 0.19533197581768036
4 1011 0.24494069814682007
5 1011 0.2644504904747009
val - Global loss: 0.213244    Embedding norm: 1.0000   Triplets (all/active): 168.5/20076.8
Pos dist (min/mean/max): 0.6829/0.9594/1.2588   Neg dist (min/mean/max): 0.7348/1.3079/1.6818
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.006318330764770508
4 25113 0.032198429107666016
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.021817415952682495
18 25113 0.0
19 25113 0.0022786855697631836
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.03505217656493187
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.03328661620616913
33 25113 0.03045501559972763
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.029195163398981094
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.04125523567199707
61 25113 0.0
62 25113 0.0
63 25113 0.012478649616241455
64 25113 0.04823297634720802
65 25113 0.0
66 25113 0.0
67 25113 0.01390451192855835
68 25113 0.0
69 25113 0.0
70 25113 0.0
71 25113 0.03061717003583908
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.020898044109344482
79 25113 0.0
80 25113 0.04020409658551216
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.02028203010559082
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.02660965919494629
89 25113 0.01993083953857422
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.02487555705010891
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.04851292818784714
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.0
124 25113 0.0
125 25113 0.0
train - Global loss: 0.004273    Embedding norm: 1.0000   Triplets (all/active): 199.3/4.1
Pos dist (min/mean/max): 0.3920/0.6121/0.8765   Neg dist (min/mean/max): 1.2582/1.4270/1.5761
0 1011 0.18472088873386383
1 1011 0.17048588395118713
2 1011 0.18204307556152344
3 1011 0.17378053069114685
4 1011 0.26223745942115784
5 1011 0.2564052939414978
val - Global loss: 0.204946    Embedding norm: 1.0000   Triplets (all/active): 168.5/18816.2
Pos dist (min/mean/max): 0.6150/0.9114/1.2395   Neg dist (min/mean/max): 0.6341/1.2935/1.6819
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.02680528163909912
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.0
71 25113 0.0533515028655529
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.01171603798866272
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.010214160196483135
100 25113 0.008926868438720703
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.0
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.0
110 25113 0.0
111 25113 0.0
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.0
123 25113 0.039561107754707336
124 25113 0.0
125 25113 0.0
train - Global loss: 0.001195    Embedding norm: 1.0000   Triplets (all/active): 199.3/3.3
Pos dist (min/mean/max): 0.3841/0.5990/0.8665   Neg dist (min/mean/max): 1.2790/1.4277/1.5602
0 1011 0.19369804859161377
1 1011 0.1883304864168167
2 1011 0.19215482473373413
3 1011 0.18322955071926117
4 1011 0.26715508103370667
5 1011 0.29427599906921387
val - Global loss: 0.219807    Embedding norm: 1.0000   Triplets (all/active): 168.5/18609.2
Pos dist (min/mean/max): 0.6050/0.9092/1.2717   Neg dist (min/mean/max): 0.6448/1.3013/1.6877
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.03814462199807167
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.03601737320423126
51 25113 0.0
52 25113 0.0
53 25113 0.0013634562492370605
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.020665496587753296
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.004196047782897949
69 25113 0.0
70 25113 0.0
71 25113 0.037125930190086365
72 25113 0.0
73 25113 0.017181457951664925
74 25113 0.0
75 25113 0.02868059277534485
76 25113 0.04769916832447052
77 25113 0.0
78 25113 0.0
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/6.8
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 25113 nan
1 25113 nan
2 25113 nan
3 25113 nan
4 25113 nan
5 25113 nan
6 25113 nan
7 25113 nan
8 25113 nan
9 25113 nan
10 25113 nan
11 25113 nan
12 25113 nan
13 25113 nan
14 25113 nan
15 25113 nan
16 25113 nan
17 25113 nan
18 25113 nan
19 25113 nan
20 25113 nan
21 25113 nan
22 25113 nan
23 25113 nan
24 25113 nan
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
37 25113 nan
38 25113 nan
39 25113 nan
40 25113 nan
41 25113 nan
42 25113 nan
43 25113 nan
44 25113 nan
45 25113 nan
46 25113 nan
47 25113 nan
48 25113 nan
49 25113 nan
50 25113 nan
51 25113 nan
52 25113 nan
53 25113 nan
54 25113 nan
55 25113 nan
56 25113 nan
57 25113 nan
58 25113 nan
59 25113 nan
60 25113 nan
61 25113 nan
62 25113 nan
63 25113 nan
64 25113 nan
65 25113 nan
66 25113 nan
67 25113 nan
68 25113 nan
69 25113 nan
70 25113 nan
71 25113 nan
72 25113 nan
73 25113 nan
74 25113 nan
75 25113 nan
76 25113 nan
77 25113 nan
78 25113 nan
79 25113 nan
80 25113 nan
81 25113 nan
82 25113 nan
83 25113 nan
84 25113 nan
85 25113 nan
86 25113 nan
87 25113 nan
88 25113 nan
89 25113 nan
90 25113 nan
91 25113 nan
92 25113 nan
93 25113 nan
94 25113 nan
95 25113 nan
96 25113 nan
97 25113 nan
98 25113 nan
99 25113 nan
100 25113 nan
101 25113 nan
102 25113 nan
103 25113 nan
104 25113 nan
105 25113 nan
106 25113 nan
107 25113 nan
108 25113 nan
109 25113 nan
110 25113 nan
111 25113 nan
112 25113 nan
113 25113 nan
114 25113 nan
115 25113 nan
116 25113 nan
117 25113 nan
118 25113 nan
119 25113 nan
120 25113 nan
121 25113 nan
122 25113 nan
123 25113 nan
124 25113 nan
125 25113 nan
train - Global loss: nan    Embedding norm: nan   Triplets (all/active): 199.3/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
0 1011 nan
1 1011 nan
2 1011 nan
3 1011 nan
4 1011 nan
5 1011 nan
val - Global loss: nan    Embedding norm: nan   Triplets (all/active): 168.5/0.0
Pos dist (min/mean/max): nan/nan/nan   Neg dist (min/mean/max): nan/nan/nan
Training completed.
  0%|                                                    | 0/12 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 499, in do_train
    global_stats = evaluator_test_set.evaluate(model)
  File "/code/RLoc/eval/evaluate.py", line 1469, in evaluate
    query_embeddings, map_embeddings, query_positions, map_positions = self.compute_embeddings(model)
  File "/code/RLoc/eval/evaluate.py", line 1498, in compute_embeddings
    for query, maps, query_pos, map_pos in tqdm.tqdm(self.test_loader):
ValueError: not enough values to unpack (expected 4, got 2)
