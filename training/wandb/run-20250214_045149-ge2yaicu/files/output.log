  0%|                                                                      | 0/80 [00:00<?, ?it/s]
0 42635 1.0578699111938477
1 42635 0.8276667594909668
2 42635 0.948606550693512
3 42635 0.6120384931564331
4 42635 0.8476773500442505
5 42635 1.0784354209899902
6 42635 0.7027176022529602
7 42635 0.7451564073562622
8 42635 0.7339439988136292
9 42635 0.5967522859573364
10 42635 0.6731558442115784
11 42635 0.6036732792854309
12 42635 0.7414894700050354
13 42635 0.5954867601394653
14 42635 0.624984860420227
15 42635 0.5209490060806274
16 42635 0.45724567770957947
17 42635 0.42897480726242065
18 42635 0.6811588406562805
19 42635 0.5789849758148193
20 42635 0.47933757305145264
21 42635 0.5791485905647278
22 42635 0.4365275502204895
23 42635 0.4891718924045563
24 42635 0.45024892687797546
25 42635 0.564035177230835
26 42635 0.45999085903167725
27 42635 0.83777916431427
28 42635 0.48892828822135925
29 42635 0.44304198026657104
30 42635 0.4728938043117523
31 42635 0.41875648498535156
32 42635 0.49882441759109497
33 42635 0.4895007312297821
34 42635 0.4567682147026062
35 42635 0.41656506061553955
36 42635 0.4516003727912903
37 42635 0.49050503969192505
38 42635 0.43785277009010315
39 42635 0.4394911825656891
40 42635 0.42651912569999695
41 42635 0.4846474230289459
42 42635 0.42918646335601807
43 42635 0.444898784160614
44 42635 0.5009067058563232
45 42635 0.471749484539032
46 42635 0.4745609164237976
47 42635 0.44216009974479675
48 42635 0.5417789220809937
49 42635 0.4199375808238983
50 42635 0.35589712858200073
51 42635 0.5796158313751221
52 42635 0.41875898838043213
53 42635 0.37495067715644836
54 42635 0.39449018239974976
55 42635 0.3800326883792877
56 42635 0.44883033633232117
57 42635 0.36837294697761536
58 42635 0.4608471691608429
59 42635 0.49204954504966736
60 42635 0.41068586707115173
61 42635 0.391953706741333
62 42635 0.37584564089775085
63 42635 0.34158822894096375
64 42635 0.33129632472991943
65 42635 0.4061463475227356
66 42635 0.44253507256507874
67 42635 0.3879420757293701
68 42635 0.36113953590393066
69 42635 0.4056130647659302
70 42635 0.3535565137863159
71 42635 0.414257287979126
72 42635 0.33579641580581665
73 42635 0.3917202651500702
74 42635 0.3494333028793335
75 42635 0.4090229868888855
76 42635 0.3576831519603729
77 42635 0.3290961682796478
78 42635 0.3824308216571808
79 42635 0.4552287757396698
80 42635 0.3546261191368103
81 42635 0.4199081361293793
82 42635 0.3892326354980469
83 42635 0.3830304741859436
84 42635 0.37218305468559265
85 42635 0.3581281900405884
86 42635 0.34199339151382446
87 42635 0.38031190633773804
88 42635 0.39550742506980896
89 42635 0.46286091208457947
90 42635 0.5469484329223633
91 42635 0.410561203956604
92 42635 0.3678686320781708
93 42635 0.3247298002243042
94 42635 0.4580574035644531
95 42635 0.48631033301353455
96 42635 0.45088449120521545
97 42635 0.33276575803756714
98 42635 0.31558817625045776
99 42635 0.4399701654911041
100 42635 0.4030308127403259
101 42635 0.366374135017395
102 42635 0.35402658581733704
103 42635 0.4237406849861145
104 42635 0.42203229665756226
105 42635 0.4221118092536926
106 42635 0.3705570101737976
107 42635 0.3872157335281372
108 42635 0.4112567901611328
109 42635 0.4018293619155884
110 42635 0.37526634335517883
111 42635 0.35594072937965393
112 42635 0.44702208042144775
113 42635 0.36476606130599976
114 42635 0.39396318793296814
115 42635 0.38248661160469055
116 42635 0.4101182520389557
117 42635 0.3920761048793793
118 42635 0.34635207056999207
119 42635 0.4025895893573761
120 42635 0.3629504442214966
121 42635 0.387912780046463
122 42635 0.34884482622146606
123 42635 0.33729225397109985
124 42635 0.327460378408432
125 42635 0.32416000962257385
126 42635 0.41184601187705994
127 42635 0.32316893339157104
128 42635 0.3050661087036133
129 42635 0.3548649847507477
130 42635 0.36782291531562805
131 42635 0.33312952518463135
132 42635 0.31932857632637024
133 42635 0.339607298374176
train - Global loss: 0.455737    Embedding norm: 9.3629   Triplets (all/active): 318.2/101478.7
Pos dist (min/mean/max): 1.5060/1.8966/2.5441   Neg dist (min/mean/max): 1.4700/1.9594/2.9966
0 1011 0.38963451981544495
1 1011 0.5160836577415466
2 1011 0.45420801639556885
3 1011 0.8735874891281128
val - Global loss: 0.558378    Embedding norm: 8.9635   Triplets (all/active): 252.8/75580.5
Pos dist (min/mean/max): 0.8008/1.2509/2.1815   Neg dist (min/mean/max): 0.7515/1.2964/2.4657
0 42635 0.3024555444717407
1 42635 0.3077883720397949
2 42635 0.29733580350875854
3 42635 0.30980947613716125
4 42635 0.27192389965057373
5 42635 0.3998112380504608
6 42635 0.2793431878089905
7 42635 0.2959497570991516
8 42635 0.31893104314804077
9 42635 0.24021409451961517
10 42635 0.2575019299983978
11 42635 0.22650443017482758
12 42635 0.30000415444374084
13 42635 0.24429097771644592
14 42635 0.27782726287841797
15 42635 0.2612540125846863
16 42635 0.2780826687812805
17 42635 0.23145250976085663
18 42635 0.31523945927619934
19 42635 0.31022337079048157
20 42635 0.20504628121852875
21 42635 0.2864641547203064
22 42635 0.21023578941822052
23 42635 0.21502242982387543
24 42635 0.19537052512168884
25 42635 0.2823069989681244
26 42635 0.2289801687002182
27 42635 0.49177879095077515
28 42635 0.2425011247396469
29 42635 0.24242228269577026
30 42635 0.2714543640613556
31 42635 0.20748482644557953
32 42635 0.25637802481651306
33 42635 0.3384324014186859
34 42635 0.28274667263031006
35 42635 0.2236655205488205
36 42635 0.24465411901474
37 42635 0.3121601939201355
38 42635 0.2553751766681671
39 42635 0.2293393909931183
40 42635 0.2380949854850769
41 42635 0.26001664996147156
42 42635 0.21601101756095886
43 42635 0.2390972077846527
44 42635 0.33181333541870117
45 42635 0.29146289825439453
46 42635 0.2327694296836853
47 42635 0.33815911412239075
48 42635 0.3989669382572174
49 42635 0.2591947317123413
50 42635 0.2185286581516266
51 42635 0.4255768358707428
52 42635 0.3200327754020691
53 42635 0.20271295309066772
54 42635 0.18208077549934387
55 42635 0.16553336381912231
56 42635 0.22949527204036713
57 42635 0.2667052149772644
58 42635 0.469476580619812
59 42635 0.4678690433502197
60 42635 0.2164406180381775
61 42635 0.27575400471687317
62 42635 0.2546136975288391
63 42635 0.16923804581165314
64 42635 0.1890725940465927
65 42635 0.2693377435207367
66 42635 0.3857187330722809
67 42635 0.2876608669757843
68 42635 0.23724161088466644
69 42635 0.30017584562301636
70 42635 0.2183009684085846
71 42635 0.35071903467178345
72 42635 0.19585655629634857
73 42635 0.25966936349868774
74 42635 0.20047903060913086
75 42635 0.4312593936920166
76 42635 0.3117702603340149
77 42635 0.19359491765499115
78 42635 0.33876436948776245
79 42635 0.4697988033294678
80 42635 0.2041698396205902
81 42635 0.27678850293159485
82 42635 0.2146831452846527
83 42635 0.14907459914684296
84 42635 0.22636212408542633
85 42635 0.28166842460632324
86 42635 0.22528329491615295
87 42635 0.24983522295951843
88 42635 0.39661705493927
89 42635 0.38252270221710205
90 42635 0.29677075147628784
91 42635 0.18281644582748413
92 42635 0.12276137620210648
93 42635 0.17976221442222595
94 42635 0.4416714608669281
95 42635 0.583217203617096
96 42635 0.5609697103500366
97 42635 0.2659248113632202
98 42635 0.22525067627429962
99 42635 0.43677136301994324
100 42635 0.3339168429374695
101 42635 0.3160434067249298
102 42635 0.2749602794647217
103 42635 0.3721920847892761
104 42635 0.3761965334415436
105 42635 0.3744662404060364
106 42635 0.2909407913684845
107 42635 0.3274526298046112
108 42635 0.376015841960907
109 42635 0.31882381439208984
110 42635 0.2748836874961853
111 42635 0.2726171016693115
112 42635 0.3551173806190491
113 42635 0.2699146270751953
114 42635 0.33736830949783325
115 42635 0.234907865524292
116 42635 0.28741538524627686
117 42635 0.3251801133155823
118 42635 0.2521831691265106
119 42635 0.3592236340045929
120 42635 0.30702173709869385
121 42635 0.3468935489654541
122 42635 0.26153621077537537
123 42635 0.28356441855430603
124 42635 0.19258299469947815
125 42635 0.16432097554206848
126 42635 0.34646934270858765
127 42635 0.24011467397212982
128 42635 0.22884386777877808
129 42635 0.24560081958770752
130 42635 0.2774115204811096
131 42635 0.200588196516037
132 42635 0.23362477123737335
133 42635 0.22076116502285004
train - Global loss: 0.283872    Embedding norm: 9.5536   Triplets (all/active): 318.2/84828.6
Pos dist (min/mean/max): 1.2278/1.6014/2.2447   Neg dist (min/mean/max): 1.3610/2.0406/3.2662
0 1011 0.35946449637413025
1 1011 0.5707749128341675
2 1011 0.48395970463752747
3 1011 1.0635567903518677
val - Global loss: 0.619439    Embedding norm: 9.0976   Triplets (all/active): 252.8/74766.0
Pos dist (min/mean/max): 0.7362/1.3753/2.6285   Neg dist (min/mean/max): 0.7136/1.5631/3.1271
0 42635 0.20083492994308472
1 42635 0.2068796455860138
2 42635 0.17647336423397064
3 42635 0.2678622901439667
4 42635 0.19254270195960999
5 42635 0.2958841323852539
6 42635 0.2119172364473343
7 42635 0.23147985339164734
8 42635 0.2718450129032135
9 42635 0.1726275086402893
10 42635 0.15987493097782135
11 42635 0.13785412907600403
12 42635 0.16941919922828674
13 42635 0.18177270889282227
14 42635 0.17425327003002167
15 42635 0.19721783697605133
16 42635 0.2644090950489044
17 42635 0.1682112216949463
18 42635 0.21181674301624298
19 42635 0.2763898968696594
20 42635 0.1484258472919464
21 42635 0.2508503496646881
22 42635 0.13688592612743378
23 42635 0.13320524990558624
24 42635 0.14653083682060242
25 42635 0.21013647317886353
26 42635 0.19257214665412903
27 42635 0.5074356198310852
28 42635 0.29949432611465454
29 42635 0.15998364984989166
30 42635 0.1886989176273346
31 42635 0.1595861166715622
32 42635 0.15705323219299316
33 42635 0.3397602438926697
34 42635 0.24544870853424072
35 42635 0.21864794194698334
36 42635 0.2939542531967163
37 42635 0.24062283337116241
38 42635 0.21976031363010406
39 42635 0.1937953233718872
40 42635 0.22620348632335663
41 42635 0.2298661172389984
42 42635 0.1644962579011917
43 42635 0.2309655249118805
44 42635 0.32204028964042664
45 42635 0.246962770819664
46 42635 0.23387694358825684
47 42635 0.344342976808548
48 42635 0.4220166802406311
49 42635 0.186820387840271
50 42635 0.1707262545824051
51 42635 0.40253645181655884
52 42635 0.3487672209739685
53 42635 0.14822392165660858
54 42635 0.14840607345104218
55 42635 0.12015881389379501
56 42635 0.1699734777212143
57 42635 0.2805723547935486
58 42635 0.29137614369392395
59 42635 0.32040122151374817
60 42635 0.18522903323173523
61 42635 0.1889270544052124
62 42635 0.259814590215683
63 42635 0.1534373015165329
64 42635 0.16606533527374268
65 42635 0.3051147162914276
66 42635 0.3825938105583191
67 42635 0.2722929120063782
68 42635 0.2264070063829422
69 42635 0.28822341561317444
70 42635 0.19158554077148438
71 42635 0.3915751874446869
72 42635 0.17472711205482483
73 42635 0.21222880482673645
74 42635 0.15515777468681335
75 42635 0.5004675984382629
76 42635 0.29811733961105347
77 42635 0.1795327365398407
78 42635 0.26726391911506653
79 42635 0.25826770067214966
80 42635 0.15017671883106232
81 42635 0.06713172048330307
82 42635 0.04684828221797943
83 42635 0.0
84 42635 0.13473056256771088
85 42635 0.2670915424823761
86 42635 0.22797977924346924
87 42635 0.20977789163589478
88 42635 0.3521336317062378
89 42635 0.20273366570472717
90 42635 0.2462880164384842
91 42635 0.02518138475716114
92 42635 0.0
93 42635 0.1573430746793747
94 42635 0.3244904577732086
95 42635 0.4945088326931
96 42635 0.5028231739997864
97 42635 0.21818144619464874
98 42635 0.18685728311538696
99 42635 0.4144469201564789
100 42635 0.28563249111175537
101 42635 0.21502670645713806
102 42635 0.19818247854709625
103 42635 0.2638995051383972
104 42635 0.27687394618988037
105 42635 0.32822033762931824
106 42635 0.21250595152378082
107 42635 0.2764171063899994
108 42635 0.2310548722743988
109 42635 0.2256125658750534
110 42635 0.2180958390235901
111 42635 0.25432538986206055
112 42635 0.25885069370269775
113 42635 0.1701953411102295
114 42635 0.23966196179389954
115 42635 0.17404291033744812
116 42635 0.19490458071231842
117 42635 0.2694414258003235
118 42635 0.2302566021680832
119 42635 0.3838030993938446
120 42635 0.3417663872241974
121 42635 0.3006947338581085
122 42635 0.18858638405799866
123 42635 0.21233117580413818
124 42635 0.14959067106246948
125 42635 0.11344975233078003
126 42635 0.3137924075126648
127 42635 0.21694399416446686
128 42635 0.14288200438022614
129 42635 0.16819091141223907
130 42635 0.2409200370311737
131 42635 0.16669531166553497
132 42635 0.18307368457317352
133 42635 0.11541546136140823
train - Global loss: 0.228867    Embedding norm: 9.8082   Triplets (all/active): 318.2/50529.8
Pos dist (min/mean/max): 1.3338/1.7456/2.4531   Neg dist (min/mean/max): 1.6214/2.5215/3.7705
0 1011 0.32693371176719666
1 1011 0.5669424533843994
2 1011 0.5032787919044495
3 1011 1.101393222808838
val - Global loss: 0.624637    Embedding norm: 9.3966   Triplets (all/active): 252.8/71399.2
Pos dist (min/mean/max): 0.7026/1.4567/2.6797   Neg dist (min/mean/max): 0.7074/1.7683/2.9627
0 42635 0.14705400168895721
1 42635 0.2086772322654724
2 42635 0.12111856043338776
3 42635 0.25897592306137085
4 42635 0.16478240489959717
5 42635 0.21896763145923615
6 42635 0.17034807801246643
7 42635 0.1893065869808197
8 42635 0.27002570033073425
9 42635 0.12397485226392746
10 42635 0.12886758148670197
11 42635 0.08805234730243683
12 42635 0.16076479852199554
13 42635 0.14286449551582336
14 42635 0.12473596632480621
15 42635 0.16361865401268005
16 42635 0.3683605492115021
17 42635 0.1383812129497528
18 42635 0.1425536423921585
19 42635 0.27604252099990845
20 42635 0.1476202756166458
21 42635 0.23518677055835724
22 42635 0.13766945898532867
23 42635 0.08411097526550293
24 42635 0.06087825447320938
25 42635 0.1481567919254303
26 42635 0.21755880117416382
27 42635 0.4731830954551697
28 42635 0.26272571086883545
29 42635 0.17802733182907104
30 42635 0.08923879265785217
31 42635 0.1456775665283203
32 42635 0.11696687340736389
33 42635 0.2608388066291809
34 42635 0.10805900394916534
35 42635 0.17713268101215363
36 42635 0.3039499521255493
37 42635 0.15060976147651672
38 42635 0.18551236391067505
39 42635 0.18358448147773743
40 42635 0.21028226613998413
41 42635 0.2092117965221405
42 42635 0.14580197632312775
43 42635 0.24089500308036804
44 42635 0.3001372516155243
45 42635 0.19729512929916382
46 42635 0.1734742373228073
47 42635 0.3624882698059082
48 42635 0.3806394040584564
49 42635 0.20559154450893402
50 42635 0.21657925844192505
51 42635 0.3665757179260254
52 42635 0.28264081478118896
53 42635 0.08067912608385086
54 42635 0.08394094556570053
55 42635 0.04401330649852753
56 42635 0.16297990083694458
57 42635 0.2032187432050705
58 42635 0.1763303577899933
59 42635 0.13686078786849976
60 42635 0.0
61 42635 0.23407836258411407
62 42635 0.42104727029800415
63 42635 0.19742949306964874
64 42635 0.19171351194381714
65 42635 0.42910173535346985
66 42635 0.477449893951416
67 42635 0.3126644790172577
68 42635 0.2095622718334198
69 42635 0.30610644817352295
70 42635 0.18630868196487427
71 42635 0.3683798313140869
72 42635 0.12791115045547485
73 42635 0.24885235726833344
74 42635 0.06940218806266785
75 42635 0.46316614747047424
76 42635 0.2946508824825287
77 42635 0.17004545032978058
78 42635 0.2789458930492401
79 42635 0.12655670940876007
80 42635 0.08427824825048447
81 42635 0.0
82 42635 0.0
83 42635 0.0
84 42635 0.18462428450584412
85 42635 0.30092722177505493
86 42635 0.2659161686897278
87 42635 0.2703762650489807
88 42635 0.31287461519241333
89 42635 0.14920705556869507
90 42635 0.009196500293910503
91 42635 0.06269007921218872
92 42635 0.0
93 42635 0.12818323075771332
94 42635 0.2634793519973755
95 42635 0.30163803696632385
96 42635 0.5255901217460632
97 42635 0.2147233784198761
98 42635 0.16204753518104553
99 42635 0.3235490322113037
100 42635 0.31106576323509216
101 42635 0.1754486858844757
102 42635 0.18407946825027466
103 42635 0.1815277487039566
104 42635 0.3028022050857544
105 42635 0.37105435132980347
106 42635 0.19087345898151398
107 42635 0.2747633457183838
108 42635 0.18564356863498688
109 42635 0.18556854128837585
110 42635 0.24204346537590027
111 42635 0.2792167365550995
112 42635 0.32199040055274963
113 42635 0.12552253901958466
114 42635 0.15573826432228088
115 42635 0.12105192989110947
116 42635 0.22728662192821503
117 42635 0.2740405797958374
118 42635 0.2351377308368683
119 42635 0.381955087184906
120 42635 0.3766336739063263
121 42635 0.2990730404853821
122 42635 0.13673242926597595
123 42635 0.16559739410877228
124 42635 0.11553604900836945
125 42635 0.08362817019224167
126 42635 0.3224727511405945
127 42635 0.33595970273017883
128 42635 0.07177747786045074
129 42635 0.1523885428905487
130 42635 0.2211092710494995
131 42635 0.16249802708625793
132 42635 0.11810612678527832
133 42635 0.0
train - Global loss: 0.204588    Embedding norm: 10.0605   Triplets (all/active): 318.2/25151.3
Pos dist (min/mean/max): 1.6223/2.1035/2.8917   Neg dist (min/mean/max): 2.1492/3.2747/4.6623
0 1011 0.37828415632247925
1 1011 0.7100454568862915
2 1011 0.6861529350280762
3 1011 1.29142165184021
val - Global loss: 0.766476    Embedding norm: 10.0000   Triplets (all/active): 252.8/67940.0
Pos dist (min/mean/max): 0.7274/1.6668/3.3057   Neg dist (min/mean/max): 0.6877/1.9608/3.5096
0 42635 0.12981170415878296
1 42635 0.2594461441040039
2 42635 0.10659408569335938
3 42635 0.275137722492218
4 42635 0.24586205184459686
5 42635 0.15333257615566254
6 42635 0.23008279502391815
7 42635 0.24836726486682892
8 42635 0.2895165979862213
9 42635 0.1543925702571869
10 42635 0.11503788828849792
11 42635 0.07794933766126633
12 42635 0.16216211020946503
13 42635 0.16491419076919556
14 42635 0.10178709775209427
15 42635 0.14659202098846436
16 42635 0.7291779518127441
17 42635 0.2448199838399887
18 42635 0.12727513909339905
19 42635 0.35613641142845154
20 42635 0.1737038791179657
21 42635 0.2440050095319748
22 42635 0.17428939044475555
23 42635 0.03738818317651749
24 42635 0.014272901229560375
25 42635 0.1223987266421318
26 42635 0.3416065573692322
27 42635 0.37917476892471313
28 42635 0.20826685428619385
29 42635 0.21421091258525848
30 42635 0.0
31 42635 0.0506477989256382
32 42635 0.09723733365535736
33 42635 0.16836227476596832
34 42635 0.073908232152462
35 42635 0.0
36 42635 0.0
37 42635 0.04445524141192436
38 42635 0.09707652777433395
39 42635 0.14433562755584717
40 42635 0.33183789253234863
41 42635 0.27796217799186707
42 42635 0.11962885409593582
43 42635 0.23965869843959808
44 42635 0.3833960294723511
45 42635 0.1900205910205841
46 42635 0.21172094345092773
47 42635 0.39147424697875977
48 42635 0.35226428508758545
49 42635 0.2710309624671936
50 42635 0.20320989191532135
51 42635 0.3384436070919037
52 42635 0.23068177700042725
53 42635 0.09094862639904022
54 42635 0.0
55 42635 0.0
56 42635 0.10485246032476425
57 42635 0.1925061047077179
58 42635 0.10649331659078598
59 42635 0.07606417685747147
60 42635 0.0
61 42635 0.0
62 42635 0.45864471793174744
63 42635 0.16916678845882416
64 42635 0.27561360597610474
65 42635 0.5670491456985474
66 42635 0.7060695290565491
67 42635 0.4947602450847626
68 42635 0.29391396045684814
69 42635 0.3934408724308014
70 42635 0.20389406383037567
71 42635 0.2913476526737213
72 42635 0.206283301115036
73 42635 0.2953788936138153
74 42635 0.07760626077651978
75 42635 0.23269128799438477
76 42635 0.2682133913040161
77 42635 0.1883426457643509
78 42635 0.2570840120315552
79 42635 0.0
80 42635 0.0
81 42635 0.0
82 42635 0.0
83 42635 0.0
84 42635 0.12430526316165924
85 42635 0.3017304241657257
86 42635 0.2814518213272095
87 42635 0.28055816888809204
88 42635 0.20992493629455566
89 42635 0.035876788198947906
90 42635 0.0
91 42635 0.0
92 42635 0.0
93 42635 0.08947288244962692
94 42635 0.2341197431087494
95 42635 0.29492732882499695
96 42635 0.5932105183601379
97 42635 0.16839911043643951
98 42635 0.1269029974937439
99 42635 0.22860832512378693
100 42635 0.23680411279201508
101 42635 0.16022168099880219
102 42635 0.19575220346450806
103 42635 0.1651233583688736
104 42635 0.24369023740291595
105 42635 0.37504875659942627
106 42635 0.11719358712434769
107 42635 0.13621333241462708
108 42635 0.17591796815395355
109 42635 0.12129554152488708
110 42635 0.269281268119812
111 42635 0.2646966874599457
112 42635 0.32032716274261475
113 42635 0.06494535505771637
114 42635 0.125698983669281
115 42635 0.13644489645957947
116 42635 0.0
117 42635 0.3085160553455353
118 42635 0.13411475718021393
119 42635 0.4173530638217926
120 42635 0.2470320165157318
121 42635 0.2576914131641388
122 42635 0.12610676884651184
123 42635 0.27679726481437683
124 42635 0.08588418364524841
125 42635 0.0
126 42635 0.41890332102775574
127 42635 0.18912449479103088
128 42635 0.0
129 42635 0.061121866106987
130 42635 0.20460371673107147
131 42635 0.20277585089206696
132 42635 0.0
133 42635 0.0
train - Global loss: 0.189579    Embedding norm: 10.2162   Triplets (all/active): 318.2/12784.2
Pos dist (min/mean/max): 2.0145/2.5847/3.4391   Neg dist (min/mean/max): 2.9006/4.2962/6.0743
0 1011 0.41813740134239197
1 1011 0.7387259602546692
2 1011 0.7269212007522583
3 1011 1.3569214344024658
val - Global loss: 0.810176    Embedding norm: 10.1011   Triplets (all/active): 252.8/63566.5
Pos dist (min/mean/max): 0.8442/1.8089/3.4163   Neg dist (min/mean/max): 0.7726/2.2063/3.7081
0 42635 0.12406005710363388
1 42635 0.21043257415294647
2 42635 0.08541593700647354
3 42635 0.25119879841804504
4 42635 0.31714487075805664
5 42635 0.17507021129131317
6 42635 0.2357003539800644
7 42635 0.26549357175827026
8 42635 0.2766406238079071
9 42635 0.13655318319797516
10 42635 0.10001865774393082
11 42635 0.037308089435100555
12 42635 0.12105956673622131
13 42635 0.1656298190355301
14 42635 0.09264454245567322
15 42635 0.11124474555253983
16 42635 0.8625869750976562
17 42635 0.43161267042160034
18 42635 0.12033911049365997
19 42635 0.45350703597068787
20 42635 0.2562650144100189
21 42635 0.28717273473739624
22 42635 0.16937704384326935
23 42635 0.058606039732694626
24 42635 0.0636867880821228
25 42635 0.07548423111438751
26 42635 0.5798647403717041
27 42635 0.2903841435909271
28 42635 0.14032158255577087
29 42635 0.09280014783143997
30 42635 0.0
31 42635 0.0
32 42635 0.0
33 42635 0.05418657138943672
34 42635 0.0
35 42635 0.0
36 42635 0.0
37 42635 0.0
38 42635 0.07824913412332535
39 42635 0.09709054976701736
40 42635 0.31608685851097107
41 42635 0.29693934321403503
42 42635 0.09121911227703094
43 42635 0.3015138506889343
44 42635 0.12681438028812408
45 42635 0.0
46 42635 0.06768292188644409
47 42635 0.29424601793289185
48 42635 0.2087533324956894
49 42635 0.4168681204319
50 42635 0.1308058351278305
51 42635 0.27633631229400635
52 42635 0.15942226350307465
53 42635 0.0
54 42635 0.0
55 42635 0.0
56 42635 0.0
57 42635 0.07570298761129379
58 42635 0.08633388578891754
59 42635 0.0
60 42635 0.0
61 42635 0.0
62 42635 0.5008085370063782
63 42635 0.2865578532218933
64 42635 0.12355175614356995
65 42635 0.4430415630340576
66 42635 0.45710453391075134
67 42635 0.49374908208847046
68 42635 0.22155173122882843
69 42635 0.13837160170078278
70 42635 0.2017909288406372
71 42635 0.3193063735961914
72 42635 0.0
73 42635 0.22064343094825745
74 42635 0.039805710315704346
75 42635 0.16743981838226318
76 42635 0.1992187649011612
77 42635 0.053252995014190674
78 42635 0.16637957096099854
79 42635 0.0
80 42635 0.0
81 42635 0.0
82 42635 0.0
83 42635 0.0
84 42635 0.0
85 42635 0.25432947278022766
86 42635 0.48110121488571167
87 42635 0.16911934316158295
88 42635 0.11908893287181854
89 42635 0.0
90 42635 0.0
91 42635 0.0
92 42635 0.0
93 42635 0.0
94 42635 0.463018536567688
95 42635 0.2574688494205475
96 42635 1.2004151344299316
97 42635 0.12778416275978088
98 42635 0.0
99 42635 0.20847086608409882
100 42635 0.18503834307193756
101 42635 0.14326994121074677
102 42635 0.07752151787281036
103 42635 0.08435258269309998
104 42635 0.18339326977729797
105 42635 0.3240222930908203
106 42635 0.0895480215549469
107 42635 0.08472347259521484
108 42635 0.10644984245300293
109 42635 0.05732816457748413
110 42635 0.15789224207401276
111 42635 0.18389707803726196
112 42635 0.16175319254398346
113 42635 0.0
114 42635 0.0
115 42635 0.0
116 42635 0.0
117 42635 0.17460477352142334
118 42635 0.16228652000427246
119 42635 0.3422297537326813
120 42635 0.1138877421617508
121 42635 0.13274697959423065
122 42635 0.0
123 42635 0.0
124 42635 0.0
125 42635 0.0
126 42635 0.45649483799934387
127 42635 0.3186310827732086
128 42635 0.0
129 42635 0.10403644293546677
130 42635 0.0
131 42635 0.09852205216884613
132 42635 0.0
133 42635 0.0
train - Global loss: 0.154641    Embedding norm: 10.2397   Triplets (all/active): 318.2/7350.5
Pos dist (min/mean/max): 2.1061/2.6738/3.5146   Neg dist (min/mean/max): 3.3563/4.9715/7.1183
0 1011 0.43217185139656067
1 1011 0.6980268955230713
2 1011 0.6954972743988037
3 1011 1.2472914457321167
val - Global loss: 0.768247    Embedding norm: 10.2670   Triplets (all/active): 252.8/67141.8
Pos dist (min/mean/max): 0.8642/1.7369/3.3045   Neg dist (min/mean/max): 0.7325/2.0913/3.5890
0 42635 0.09713612496852875
1 42635 0.18421396613121033
2 42635 0.08878909796476364
3 42635 0.2625117599964142
4 42635 0.4251210391521454
5 42635 0.307422399520874
6 42635 0.4418683648109436
7 42635 0.23330138623714447
8 42635 0.26070496439933777
9 42635 0.12155022472143173
10 42635 0.06111761927604675
11 42635 0.07919268310070038
12 42635 0.13317161798477173
13 42635 0.14155536890029907
14 42635 0.09860003739595413
15 42635 0.0955963060259819
16 42635 0.4791531562805176
17 42635 0.42856118083000183
18 42635 0.22169597446918488
19 42635 0.35285255312919617
20 42635 0.18577806651592255
21 42635 0.2855533957481384
22 42635 0.13266855478286743
23 42635 0.03935428336262703
24 42635 0.0
25 42635 0.06045680493116379
26 42635 0.5243682265281677
27 42635 0.16411975026130676
28 42635 0.0
29 42635 0.0
30 42635 0.0
31 42635 0.0
32 42635 0.0
33 42635 0.0
34 42635 0.0
35 42635 0.0
36 42635 0.0
37 42635 0.0
38 42635 0.0
39 42635 0.0
40 42635 0.3535056412220001
41 42635 0.28172218799591064
42 42635 0.0
43 42635 0.0
44 42635 0.0
45 42635 0.0
46 42635 0.0
47 42635 0.20008520781993866
48 42635 0.18185992538928986
49 42635 0.5829669237136841
50 42635 0.0581333264708519
51 42635 0.0
52 42635 0.0
53 42635 0.0
54 42635 0.0
55 42635 0.0
56 42635 0.0
57 42635 0.14868982136249542
58 42635 0.09137868881225586
59 42635 0.15907829999923706
60 42635 0.0
61 42635 0.0
62 42635 0.26435384154319763
63 42635 0.12119891494512558
64 42635 0.0
65 42635 0.19462396204471588
66 42635 0.14883682131767273
67 42635 0.17309898138046265
68 42635 0.1479206681251526
69 42635 0.11141745001077652
70 42635 0.0
71 42635 0.0
72 42635 0.0
73 42635 0.0
74 42635 0.0
75 42635 0.0
76 42635 0.0
77 42635 0.0
78 42635 0.48301416635513306
79 42635 0.0
80 42635 0.0
81 42635 0.0
82 42635 0.0
83 42635 0.0
84 42635 0.0
85 42635 0.047324638813734055
86 42635 0.38917192816734314
87 42635 0.1098516657948494
88 42635 0.23212067782878876
89 42635 0.0
90 42635 0.0
91 42635 0.0
92 42635 0.0
93 42635 0.0
94 42635 0.10305074602365494
95 42635 0.1734505146741867
96 42635 0.32156479358673096
97 42635 0.064452163875103
98 42635 0.0
99 42635 0.27879586815834045
100 42635 0.17432311177253723
101 42635 0.0
102 42635 0.0
103 42635 0.0
104 42635 0.0
105 42635 0.4082656800746918
106 42635 0.0
107 42635 0.0
108 42635 0.11670803278684616
109 42635 0.0
110 42635 0.4015691578388214
111 42635 0.16987338662147522
112 42635 0.0
113 42635 0.0
114 42635 0.0421808622777462
115 42635 0.0819113478064537
116 42635 0.042855024337768555
117 42635 0.0
118 42635 0.0
119 42635 0.12423781305551529
120 42635 0.0
121 42635 0.0
122 42635 0.0
123 42635 0.0
124 42635 0.08484524488449097
125 42635 0.0
126 42635 0.6530905365943909
127 42635 0.37020137906074524
128 42635 0.0
129 42635 0.0
130 42635 0.14296329021453857
131 42635 0.12272297590970993
132 42635 0.07652729749679565
133 42635 0.0
train - Global loss: 0.107018    Embedding norm: 10.2585   Triplets (all/active): 318.2/4858.3
Pos dist (min/mean/max): 2.1536/2.7247/3.6225   Neg dist (min/mean/max): 3.7815/5.6277/8.0445
0 1011 0.48060187697410583
1 1011 0.7590175271034241
2 1011 0.7091153264045715
3 1011 1.2549484968185425
val - Global loss: 0.800921    Embedding norm: 10.4121   Triplets (all/active): 252.8/70182.5
Pos dist (min/mean/max): 0.6797/1.5867/3.0756   Neg dist (min/mean/max): 0.5925/1.8575/3.3713
0 42635 0.10379507392644882
1 42635 0.20456455647945404
2 42635 0.10298950970172882
3 42635 0.21840274333953857
4 42635 0.1344572901725769
5 42635 0.19649730622768402
6 42635 0.2008385807275772
7 42635 0.22318914532661438
8 42635 0.24813024699687958
9 42635 0.10572101920843124
10 42635 0.09963250160217285
11 42635 0.06368966400623322
12 42635 0.09612290561199188
13 42635 0.13969966769218445
14 42635 0.10408990830183029
15 42635 0.09622513502836227
16 42635 0.27124306559562683
17 42635 0.1902911514043808
18 42635 0.1243603304028511
19 42635 0.2632872462272644
20 42635 0.15195004642009735
21 42635 0.23826776444911957
22 42635 0.08059370517730713
23 42635 0.0626119077205658
24 42635 0.06908565759658813
25 42635 0.1268174648284912
26 42635 0.25272122025489807
27 42635 0.16015496850013733
28 42635 0.0
29 42635 0.0
30 42635 0.0
31 42635 0.0
32 42635 0.0
33 42635 0.0
34 42635 0.0
35 42635 0.0
36 42635 0.0
37 42635 0.0
38 42635 0.0
39 42635 0.0
40 42635 0.21135534346103668
41 42635 0.45990654826164246
42 42635 0.0
43 42635 0.0
44 42635 0.0
45 42635 0.0
46 42635 0.0
47 42635 0.0
48 42635 0.0
49 42635 0.24619582295417786
50 42635 0.0
51 42635 0.0
52 42635 0.09255646169185638
53 42635 0.0
54 42635 0.0
55 42635 0.0
56 42635 0.0
57 42635 0.0
58 42635 0.0
59 42635 0.0
60 42635 0.0
61 42635 0.0
62 42635 0.0
63 42635 0.0
64 42635 0.0
65 42635 0.20404063165187836
66 42635 0.09364897012710571
67 42635 0.0
68 42635 0.0
69 42635 0.0
70 42635 0.0
71 42635 0.0
72 42635 0.005133211612701416
73 42635 0.08402448892593384
74 42635 0.0
75 42635 0.0
76 42635 0.0
77 42635 0.0
78 42635 0.0
79 42635 0.0
80 42635 0.0
81 42635 0.0
82 42635 0.0
83 42635 0.0
84 42635 0.0
85 42635 0.0
86 42635 0.17513298988342285
87 42635 0.0
88 42635 0.0
89 42635 0.0
90 42635 0.0
91 42635 0.0
92 42635 0.0
93 42635 0.0
94 42635 0.0632883608341217
95 42635 0.0
96 42635 0.0
97 42635 0.0
98 42635 0.0
99 42635 0.18656058609485626
100 42635 0.09473520517349243
101 42635 0.0
102 42635 0.0
103 42635 0.0
104 42635 0.1147165298461914
105 42635 0.20386572182178497
106 42635 0.0
107 42635 0.0
108 42635 0.0
109 42635 0.0
110 42635 0.17224954068660736
111 42635 0.2926448881626129
112 42635 0.0
113 42635 0.0
114 42635 0.0
115 42635 0.0
116 42635 0.0
117 42635 0.11603814363479614
118 42635 0.0
119 42635 0.14319369196891785
120 42635 0.0
121 42635 0.0
122 42635 0.0
123 42635 0.0
124 42635 0.0
125 42635 0.0
126 42635 0.6306041479110718
127 42635 0.0
128 42635 0.0
129 42635 0.0
130 42635 0.0
131 42635 0.0
132 42635 0.0
133 42635 0.0
train - Global loss: 0.059099    Embedding norm: 10.2175   Triplets (all/active): 318.2/4647.3
Pos dist (min/mean/max): 2.0175/2.5513/3.3340   Neg dist (min/mean/max): 4.0422/6.1207/8.5151
0 1011 0.45120108127593994
1 1011 0.6753556132316589
2 1011 0.6831857562065125
3 1011 1.241581916809082
val - Global loss: 0.762831    Embedding norm: 10.2202   Triplets (all/active): 252.8/70146.5
Pos dist (min/mean/max): 0.7716/1.6178/3.2229   Neg dist (min/mean/max): 0.6373/1.9453/3.5194
0 42635 0.13331297039985657
1 42635 0.1581438034772873
2 42635 0.07561268657445908
3 42635 0.19131498038768768
4 42635 0.16635967791080475
5 42635 0.20759077370166779
6 42635 0.17550714313983917
7 42635 0.1994457095861435
8 42635 0.21886669099330902
9 42635 0.10798654705286026
10 42635 0.05883941426873207
11 42635 0.03887567296624184
12 42635 0.05799943208694458
13 42635 0.11309501528739929
14 42635 0.05264453962445259
15 42635 0.08141782134771347
16 42635 0.1926826536655426
17 42635 0.14638878405094147
18 42635 0.11659188568592072
19 42635 0.19860775768756866
20 42635 0.14876168966293335
21 42635 0.20132021605968475
22 42635 0.10195264965295792
23 42635 0.02908453904092312
24 42635 0.030366241931915283
25 42635 0.10352864116430283
26 42635 0.20753373205661774
27 42635 0.0
28 42635 0.0
29 42635 0.0
30 42635 0.0
31 42635 0.0
32 42635 0.0
33 42635 0.0
34 42635 0.0
35 42635 0.0
36 42635 0.0
37 42635 0.0
38 42635 0.0
39 42635 0.0
40 42635 0.0
41 42635 0.24498093128204346
42 42635 0.0
43 42635 0.0
44 42635 0.0
45 42635 0.0
46 42635 0.0
47 42635 0.08167392015457153
48 42635 0.3156425356864929
49 42635 0.17055565118789673
50 42635 0.0
51 42635 0.0
52 42635 0.0
53 42635 0.0
54 42635 0.0
55 42635 0.0
56 42635 0.0
57 42635 0.0
58 42635 0.0
59 42635 0.0
60 42635 0.0
61 42635 0.0
62 42635 0.0
63 42635 0.0
64 42635 0.0
65 42635 0.0
66 42635 0.0
67 42635 0.28179359436035156
68 42635 0.0
69 42635 0.0
70 42635 0.0
71 42635 0.0
72 42635 0.0
73 42635 0.39866065979003906
74 42635 0.0
75 42635 0.15706801414489746
76 42635 0.0
77 42635 0.0
78 42635 0.0
79 42635 0.0
80 42635 0.0
81 42635 0.0
82 42635 0.0
83 42635 0.0
84 42635 0.0
85 42635 0.0
86 42635 0.10577136278152466
87 42635 0.0
88 42635 0.0
89 42635 0.0
90 42635 0.0
91 42635 0.0
92 42635 0.180709570646286
93 42635 0.0
94 42635 0.0
95 42635 0.0
96 42635 0.0
97 42635 0.0
98 42635 0.0
99 42635 0.0028248270973563194
100 42635 0.15812133252620697
101 42635 0.0
102 42635 0.0
103 42635 0.0
104 42635 0.0
105 42635 0.15952850878238678
106 42635 0.0
107 42635 0.0
108 42635 0.0
109 42635 0.0
110 42635 0.15767301619052887
111 42635 0.0
112 42635 0.0
113 42635 0.0
114 42635 0.0
115 42635 0.0
116 42635 0.0
117 42635 0.0
118 42635 0.0
119 42635 0.0
120 42635 0.03762906789779663
121 42635 0.0
122 42635 0.0
123 42635 0.0
124 42635 0.0
125 42635 0.0
126 42635 0.4894252419471741
127 42635 0.0
128 42635 0.0
129 42635 0.0
130 42635 0.0
131 42635 0.0
132 42635 0.0
133 42635 0.0
train - Global loss: 0.048178    Embedding norm: 10.2245   Triplets (all/active): 318.2/3202.3
Pos dist (min/mean/max): 2.1669/2.7385/3.6437   Neg dist (min/mean/max): 4.5131/6.7286/9.4143
0 1011 0.5257800221443176
1 1011 0.83968585729599
2 1011 0.7522101998329163
3 1011 1.338731050491333
val - Global loss: 0.864102    Embedding norm: 10.4442   Triplets (all/active): 252.8/68352.2
Pos dist (min/mean/max): 0.8172/1.7850/3.4142   Neg dist (min/mean/max): 0.7107/2.0781/3.6554
0 42635 0.10226651281118393
1 42635 0.18530113995075226
2 42635 0.10025369375944138
3 42635 0.2054058164358139
4 42635 0.14164115488529205
5 42635 0.22446118295192719
6 42635 0.17110714316368103
7 42635 0.20504863560199738
8 42635 0.23775316774845123
9 42635 0.08958446979522705
10 42635 0.06804715842008591
11 42635 0.050692662596702576
12 42635 0.09873245656490326
13 42635 0.08279263228178024
14 42635 0.0
15 42635 0.09177394211292267
16 42635 0.21588371694087982
17 42635 0.15274815261363983
18 42635 0.13406763970851898
19 42635 0.19253937900066376
20 42635 0.08737741410732269
21 42635 0.19031281769275665
22 42635 0.06147469952702522
23 42635 0.031805627048015594
24 42635 0.0
25 42635 0.09488854557275772
26 42635 0.13850116729736328
27 42635 0.0
28 42635 0.0
29 42635 0.0
30 42635 0.0
31 42635 0.0
32 42635 0.0
33 42635 0.0
34 42635 0.0
35 42635 0.0
36 42635 0.0
37 42635 0.0
38 42635 0.0
39 42635 0.0
40 42635 0.36805257201194763
41 42635 0.07469385862350464
42 42635 0.0
43 42635 0.0
44 42635 0.0
45 42635 0.0
46 42635 0.0
47 42635 0.2007269263267517
48 42635 0.0
49 42635 0.0
50 42635 0.0
51 42635 0.0
52 42635 0.0
53 42635 0.0
54 42635 0.0
55 42635 0.0
56 42635 0.0
57 42635 0.0
58 42635 0.0
59 42635 0.0
60 42635 0.0
61 42635 0.0
62 42635 0.0
63 42635 0.0
64 42635 0.0
65 42635 0.0
66 42635 0.0
67 42635 0.0
68 42635 0.0
69 42635 0.0
70 42635 0.0
71 42635 0.0
72 42635 0.0
73 42635 0.0
74 42635 0.0
75 42635 0.0
76 42635 0.0
77 42635 0.0
78 42635 0.1797444224357605
79 42635 0.0
80 42635 0.0
81 42635 0.0
82 42635 0.0
83 42635 0.0
84 42635 0.0
85 42635 0.0
86 42635 0.0
87 42635 0.0
88 42635 0.0
89 42635 0.0
90 42635 0.0
91 42635 0.0
92 42635 0.0
93 42635 0.0
94 42635 0.0
95 42635 0.033607542514801025
96 42635 0.0
97 42635 0.0
98 42635 0.0
99 42635 0.0
100 42635 0.0
101 42635 0.0
102 42635 0.0
103 42635 0.0
104 42635 0.0
105 42635 0.17066140472888947
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 406, in do_train
    optimizer.step()
  File "/usr/local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/optim/optimizer.py", line 113, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/optim/adamw.py", line 161, in step
    adamw(params_with_grad,
  File "/usr/local/lib/python3.9/site-packages/torch/optim/adamw.py", line 218, in adamw
    func(params,
  File "/usr/local/lib/python3.9/site-packages/torch/optim/adamw.py", line 309, in _single_tensor_adamw
    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)
KeyboardInterrupt
