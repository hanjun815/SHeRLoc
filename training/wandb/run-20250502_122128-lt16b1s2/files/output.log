  0%|                                                   | 0/20 [00:00<?, ?it/s]
0 11083 0.4653925597667694
1 11083 0.5908944010734558
2 11083 0.5719776749610901
3 11083 0.5818805694580078
4 11083 0.551805853843689
5 11083 0.49562615156173706
6 11083 0.4263369143009186
7 11083 0.4637681245803833
8 11083 0.40893006324768066
9 11083 0.3428325057029724
10 11083 0.3707738518714905
11 11083 0.34911540150642395
12 11083 0.3717067837715149
13 11083 0.31640884280204773
14 11083 0.2938317060470581
15 11083 0.4460923373699188
16 11083 0.286460816860199
17 11083 0.28968939185142517
18 11083 0.30969083309173584
19 11083 0.28472307324409485
20 11083 0.24098509550094604
21 11083 0.24903661012649536
22 11083 0.2607594430446625
23 11083 0.25609713792800903
24 11083 0.2455265372991562
25 11083 0.2012101113796234
26 11083 0.29589495062828064
27 11083 0.29143115878105164
28 11083 0.2127654105424881
29 11083 0.20156918466091156
30 11083 0.2982431948184967
31 11083 0.23879210650920868
32 11083 0.2451750934123993
33 11083 0.2519178092479706
34 11083 0.1915646195411682
35 11083 0.19137609004974365
36 11083 0.2201356589794159
37 11083 0.15000450611114502
38 11083 0.21466249227523804
39 11083 0.1677996814250946
40 11083 0.2327665090560913
41 11083 0.18446886539459229
42 11083 0.14774362742900848
43 11083 0.2525688409805298
44 11083 0.19146457314491272
45 11083 0.1423242688179016
46 11083 0.22595585882663727
47 11083 0.15462853014469147
48 11083 0.27755364775657654
49 11083 0.16062040627002716
50 11083 0.13987188041210175
51 11083 0.13952548801898956
52 11083 0.1217929869890213
53 11083 0.11842358112335205
54 11083 0.1318833827972412
55 11083 0.18098673224449158
56 11083 0.23364068567752838
57 11083 0.2135126292705536
58 11083 0.3629429042339325
59 11083 0.3973064422607422
60 11083 0.3530040681362152
61 11083 0.24633783102035522
62 11083 0.21183963119983673
63 11083 0.2411186397075653
64 11083 0.16509656608104706
65 11083 0.15279445052146912
66 11083 0.22284087538719177
67 11083 0.25872668623924255
68 11083 0.21640442311763763
69 11083 0.28042370080947876
70 11083 0.19310297071933746
71 11083 0.1962689608335495
72 11083 0.11457213014364243
73 11083 0.21599870920181274
74 11083 0.12799109518527985
75 11083 0.15517078340053558
76 11083 0.11148779094219208
77 11083 0.09533815830945969
78 11083 0.20877939462661743
79 11083 0.2422332763671875
80 11083 0.17207099497318268
81 11083 0.1171075627207756
82 11083 0.14541685581207275
83 11083 0.1304972916841507
84 11083 0.1514122486114502
85 11083 0.3236062824726105
86 11083 0.10260753333568573
87 11083 0.1439974159002304
88 11083 0.14671672880649567
89 11083 0.09702097624540329
90 11083 0.23589272797107697
91 11083 0.15615971386432648
92 11083 0.2945805788040161
93 11083 0.10669584572315216
94 11083 0.12232720851898193
95 11083 0.11068303138017654
96 11083 0.17940744757652283
97 11083 0.153236985206604
98 11083 0.12515731155872345
99 11083 0.10821892321109772
100 11083 0.11225592344999313
101 11083 0.14164714515209198
102 11083 0.1330871284008026
103 11083 0.11448976397514343
104 11083 0.15680143237113953
105 11083 0.13377714157104492
106 11083 0.11541640013456345
107 11083 0.09494650363922119
108 11083 0.11178628355264664
109 11083 0.10198348760604858
110 11083 0.10473224520683289
train - Global loss: 0.227983    Embedding norm: 1.0000   Triplets (all/active): 99.8/5052.0
Pos dist (min/mean/max): 0.3609/0.8666/1.3847   Neg dist (min/mean/max): 0.8355/1.4023/1.7878
0 445 0.02671537734568119
1 445 0.04431356117129326
2 445 0.07613099366426468
3 445 0.06141405180096626
4 445 0.02311606891453266
val - Global loss: 0.046338    Embedding norm: 1.0000   Triplets (all/active): 89.0/532.8
Pos dist (min/mean/max): 0.1227/0.2540/0.4499   Neg dist (min/mean/max): 0.6468/1.0203/1.5427
0 11083 0.15329976379871368
1 11083 0.12765802443027496
2 11083 0.09332164376974106
3 11083 0.09598533064126968
4 11083 0.10680428147315979
5 11083 0.09175747632980347
6 11083 0.0676964595913887
7 11083 0.12023449689149857
8 11083 0.10227452963590622
9 11083 0.08168993145227432
10 11083 0.09044326096773148
11 11083 0.1354450285434723
12 11083 0.1707373410463333
13 11083 0.09155367314815521
14 11083 0.12855997681617737
15 11083 0.12822851538658142
16 11083 0.09679998457431793
17 11083 0.08588714897632599
18 11083 0.11833975464105606
19 11083 0.09599573165178299
20 11083 0.07331909984350204
21 11083 0.09675469994544983
22 11083 0.10049094259738922
23 11083 0.05505072697997093
24 11083 0.09569588303565979
25 11083 0.06319267302751541
26 11083 0.11161382496356964
27 11083 0.07058902084827423
28 11083 0.04166201502084732
29 11083 0.11109572649002075
30 11083 0.1460188627243042
31 11083 0.1233401745557785
32 11083 0.06966934353113174
33 11083 0.08883518725633621
34 11083 0.06574451178312302
35 11083 0.06500217318534851
36 11083 0.10352060198783875
37 11083 0.0934562236070633
38 11083 0.08555067330598831
39 11083 0.09594153612852097
40 11083 0.11456736922264099
41 11083 0.09960684180259705
42 11083 0.09305313229560852
43 11083 0.12959641218185425
44 11083 0.10442547500133514
45 11083 0.10302776843309402
46 11083 0.11994074285030365
47 11083 0.07712630182504654
48 11083 0.09488312900066376
49 11083 0.08223175257444382
50 11083 0.06261949986219406
51 11083 0.08631540089845657
52 11083 0.07117634266614914
53 11083 0.0796995609998703
54 11083 0.08826407045125961
55 11083 0.08784656971693039
56 11083 0.18881160020828247
57 11083 0.19803737103939056
58 11083 0.3127206563949585
59 11083 0.3697907328605652
60 11083 0.38066262006759644
61 11083 0.17341765761375427
62 11083 0.14009271562099457
63 11083 0.17511506378650665
64 11083 0.0985318273305893
65 11083 0.09605170786380768
66 11083 0.17501839995384216
67 11083 0.2538720965385437
68 11083 0.24176116287708282
69 11083 0.25052809715270996
70 11083 0.14129091799259186
71 11083 0.15385927259922028
72 11083 0.05896236002445221
73 11083 0.15560172498226166
74 11083 0.11519113928079605
75 11083 0.0977177768945694
76 11083 0.09236259758472443
77 11083 0.10860900580883026
78 11083 0.14241476356983185
79 11083 0.25109031796455383
80 11083 0.12280157208442688
81 11083 0.1129264086484909
82 11083 0.08280806243419647
83 11083 0.10812044143676758
84 11083 0.1463913917541504
85 11083 0.30967363715171814
86 11083 0.09640929102897644
87 11083 0.11561852693557739
88 11083 0.10889311879873276
89 11083 0.11438284069299698
90 11083 0.15007595717906952
91 11083 0.11009729653596878
92 11083 0.25511831045150757
93 11083 0.06815949082374573
94 11083 0.09977222234010696
95 11083 0.079655721783638
96 11083 0.12821227312088013
97 11083 0.13874086737632751
98 11083 0.08189793676137924
99 11083 0.0881371721625328
100 11083 0.06760451197624207
101 11083 0.0909465104341507
102 11083 0.13907258212566376
103 11083 0.11627107113599777
104 11083 0.1354144960641861
105 11083 0.13228626549243927
106 11083 0.1283375471830368
107 11083 0.1038973405957222
108 11083 0.10234400629997253
109 11083 0.09374522417783737
110 11083 0.14806286990642548
train - Global loss: 0.122352    Embedding norm: 1.0000   Triplets (all/active): 99.8/2630.0
Pos dist (min/mean/max): 0.4087/0.8143/1.2021   Neg dist (min/mean/max): 1.0122/1.4102/1.7022
0 445 0.05778488144278526
1 445 0.0048621175810694695
2 445 0.06284835934638977
3 445 0.041400790214538574
4 445 0.0
val - Global loss: 0.033379    Embedding norm: 1.0000   Triplets (all/active): 89.0/99.6
Pos dist (min/mean/max): 0.1454/0.3101/0.5321   Neg dist (min/mean/max): 0.8073/1.2232/1.5238
0 11083 0.15193772315979004
1 11083 0.13153009116649628
2 11083 0.07638698071241379
3 11083 0.1004340797662735
4 11083 0.1199042871594429
5 11083 0.11615043133497238
6 11083 0.07243021577596664
7 11083 0.08081062138080597
8 11083 0.08087620884180069
9 11083 0.06166905164718628
10 11083 0.0408480167388916
11 11083 0.12684611976146698
12 11083 0.15986691415309906
13 11083 0.10336926579475403
14 11083 0.05222710222005844
15 11083 0.08314760029315948
16 11083 0.06942184269428253
17 11083 0.10591679811477661
18 11083 0.10827463865280151
19 11083 0.08976990729570389
20 11083 0.05422598123550415
21 11083 0.0762227475643158
22 11083 0.13335619866847992
23 11083 0.0727134719491005
24 11083 0.11211296916007996
25 11083 0.07596399635076523
26 11083 0.08997222036123276
27 11083 0.07119016349315643
28 11083 0.06973420828580856
29 11083 0.10474678874015808
30 11083 0.14646029472351074
31 11083 0.13495291769504547
32 11083 0.07728520780801773
33 11083 0.09226147085428238
34 11083 0.045438364148139954
35 11083 0.10648546367883682
36 11083 0.08143153041601181
37 11083 0.03173062950372696
38 11083 0.11039698123931885
39 11083 0.1161867305636406
40 11083 0.07227399200201035
41 11083 0.08456707745790482
42 11083 0.08727828413248062
43 11083 0.09005140513181686
44 11083 0.10411674529314041
45 11083 0.09213896840810776
46 11083 0.09025172889232635
47 11083 0.10356961190700531
48 11083 0.15165896713733673
49 11083 0.11295110732316971
50 11083 0.05682022497057915
51 11083 0.05959821492433548
52 11083 0.06739958375692368
53 11083 0.0809967890381813
54 11083 0.10201272368431091
55 11083 0.09051385521888733
56 11083 0.16541630029678345
57 11083 0.1527145802974701
58 11083 0.2774609625339508
59 11083 0.3401060700416565
60 11083 0.30163446068763733
61 11083 0.13733609020709991
62 11083 0.13556978106498718
63 11083 0.16402113437652588
64 11083 0.11999767273664474
65 11083 0.11494499444961548
66 11083 0.2398330122232437
67 11083 0.2599128186702728
68 11083 0.17065003514289856
69 11083 0.21656940877437592
70 11083 0.1840408742427826
71 11083 0.15427632629871368
72 11083 0.059820421040058136
73 11083 0.1866718828678131
74 11083 0.11259004473686218
75 11083 0.08003280311822891
76 11083 0.07014752924442291
77 11083 0.09559538960456848
78 11083 0.1357433795928955
79 11083 0.24303698539733887
80 11083 0.1269979029893875
81 11083 0.08679582923650742
82 11083 0.07161302119493484
83 11083 0.06065911799669266
84 11083 0.11876118928194046
85 11083 0.31713420152664185
86 11083 0.093709297478199
87 11083 0.07640381157398224
88 11083 0.0915239006280899
89 11083 0.072641521692276
90 11083 0.1341070979833603
91 11083 0.16317889094352722
92 11083 0.24720533192157745
93 11083 0.1272825002670288
94 11083 0.10355185717344284
95 11083 0.06661646068096161
96 11083 0.13069279491901398
97 11083 0.14655138552188873
98 11083 0.06037289649248123
99 11083 0.08772438764572144
100 11083 0.05477739870548248
101 11083 0.11451455950737
102 11083 0.13936029374599457
103 11083 0.04134178161621094
104 11083 0.1643260270357132
105 11083 0.1654578447341919
106 11083 0.1728201061487198
107 11083 0.12216965854167938
108 11083 0.10381150245666504
109 11083 0.08779935538768768
110 11083 0.11484502255916595
train - Global loss: 0.116791    Embedding norm: 1.0000   Triplets (all/active): 99.8/2402.5
Pos dist (min/mean/max): 0.4040/0.8036/1.1981   Neg dist (min/mean/max): 1.0227/1.4097/1.6925
0 445 0.0
1 445 0.04090359807014465
2 445 0.03622478246688843
3 445 0.040385451167821884
4 445 0.0
val - Global loss: 0.023503    Embedding norm: 1.0000   Triplets (all/active): 89.0/24.8
Pos dist (min/mean/max): 0.1351/0.2941/0.5566   Neg dist (min/mean/max): 0.9545/1.2431/1.5036
0 11083 0.09240159392356873
1 11083 0.09226730465888977
2 11083 0.09996576607227325
3 11083 0.07827060669660568
4 11083 0.09380989521741867
5 11083 0.09028191864490509
6 11083 0.06848420202732086
7 11083 0.10230182111263275
8 11083 0.08422508090734482
9 11083 0.09544248133897781
10 11083 0.10642044991254807
11 11083 0.0940670371055603
12 11083 0.14259718358516693
13 11083 0.09040825068950653
14 11083 0.09084447473287582
15 11083 0.07904264330863953
16 11083 0.053860023617744446
17 11083 0.09382350742816925
18 11083 0.12956596910953522
19 11083 0.0701616182923317
20 11083 0.0533224456012249
21 11083 0.05639594420790672
22 11083 0.07782122492790222
23 11083 0.07726588845252991
24 11083 0.07485547661781311
25 11083 0.03961285576224327
26 11083 0.09784190356731415
27 11083 0.09815599769353867
28 11083 0.04023728147149086
29 11083 0.11278915405273438
30 11083 0.14020559191703796
31 11083 0.12752920389175415
32 11083 0.04880821332335472
33 11083 0.08023261278867722
34 11083 0.06071064621210098
35 11083 0.08465813845396042
36 11083 0.04135267436504364
37 11083 0.03190648555755615
38 11083 0.07169003039598465
39 11083 0.08427344262599945
40 11083 0.06705334037542343
41 11083 0.08219391852617264
42 11083 0.08835935592651367
43 11083 0.11333668231964111
44 11083 0.07936742901802063
45 11083 0.07571252435445786
46 11083 0.13273103535175323
47 11083 0.05237489193677902
48 11083 0.1120627149939537
49 11083 0.11275698244571686
50 11083 0.0717027485370636
51 11083 0.0385541208088398
52 11083 0.06352364271879196
53 11083 0.10369645804166794
54 11083 0.036745835095644
55 11083 0.09508364647626877
56 11083 0.1618187427520752
57 11083 0.1321854293346405
58 11083 0.2550216615200043
59 11083 0.34765660762786865
60 11083 0.3102933168411255
61 11083 0.16147378087043762
62 11083 0.11069676280021667
63 11083 0.1359812319278717
64 11083 0.11946816742420197
65 11083 0.0857011079788208
66 11083 0.17969074845314026
67 11083 0.2902999520301819
68 11083 0.22757643461227417
69 11083 0.2150132954120636
70 11083 0.1742740273475647
71 11083 0.1326834112405777
72 11083 0.061782244592905045
73 11083 0.14579766988754272
74 11083 0.0918499082326889
75 11083 0.08859702944755554
76 11083 0.08836402744054794
77 11083 0.08943318575620651
78 11083 0.14438629150390625
79 11083 0.18410566449165344
80 11083 0.11401653289794922
81 11083 0.051141414791345596
82 11083 0.07979884743690491
83 11083 0.05669384449720383
84 11083 0.1548902541399002
85 11083 0.3090401887893677
86 11083 0.05012834444642067
87 11083 0.06597201526165009
88 11083 0.06658945977687836
89 11083 0.043330512940883636
90 11083 0.128580704331398
91 11083 0.1218588575720787
92 11083 0.23433899879455566
93 11083 0.10917782038450241
94 11083 0.06616576761007309
95 11083 0.0620163194835186
96 11083 0.1116693839430809
97 11083 0.15247377753257751
98 11083 0.060574721544981
99 11083 0.0838383361697197
100 11083 0.09129727631807327
101 11083 0.10070043802261353
102 11083 0.1129385456442833
103 11083 0.059241048991680145
104 11083 0.13924893736839294
105 11083 0.09197337925434113
106 11083 0.13342627882957458
107 11083 0.06981933116912842
108 11083 0.11527665704488754
109 11083 0.08397769182920456
110 11083 0.0902467593550682
train - Global loss: 0.106466    Embedding norm: 1.0000   Triplets (all/active): 99.8/2115.0
Pos dist (min/mean/max): 0.4018/0.7918/1.1634   Neg dist (min/mean/max): 1.0461/1.4100/1.6884
0 445 0.0
1 445 0.044730644673109055
2 445 0.052649110555648804
3 445 0.07117576152086258
4 445 0.0
val - Global loss: 0.033711    Embedding norm: 1.0000   Triplets (all/active): 89.0/13.0
Pos dist (min/mean/max): 0.1521/0.2998/0.5383   Neg dist (min/mean/max): 0.9245/1.3035/1.6148
0 11083 0.11074455082416534
1 11083 0.13499601185321808
2 11083 0.09409208595752716
3 11083 0.06287290900945663
4 11083 0.08017560839653015
5 11083 0.08711683750152588
6 11083 0.048696745187044144
7 11083 0.10186208784580231
8 11083 0.13683246076107025
9 11083 0.051690127700567245
10 11083 0.051793672144412994
11 11083 0.11410220712423325
12 11083 0.12157934159040451
13 11083 0.10346431285142899
14 11083 0.09665051102638245
15 11083 0.08023794740438461
16 11083 0.07772153615951538
17 11083 0.06112854927778244
18 11083 0.0983080118894577
19 11083 0.10423887521028519
20 11083 0.0708666518330574
21 11083 0.0889822244644165
22 11083 0.10867155343294144
23 11083 0.07885510474443436
24 11083 0.09178552776575089
25 11083 0.05064890533685684
26 11083 0.10029598325490952
27 11083 0.05636723339557648
28 11083 0.026682520285248756
29 11083 0.11376877129077911
30 11083 0.11809609085321426
31 11083 0.1034618392586708
32 11083 0.0675821378827095
33 11083 0.0983472391963005
34 11083 0.02823362872004509
35 11083 0.06323479861021042
36 11083 0.060557421296834946
37 11083 0.04540448635816574
38 11083 0.11271744966506958
39 11083 0.09467021375894547
40 11083 0.07163247466087341
41 11083 0.09897670894861221
42 11083 0.06832244247198105
43 11083 0.12027222663164139
44 11083 0.08717064559459686
45 11083 0.07844489812850952
46 11083 0.08471551537513733
47 11083 0.060273345559835434
48 11083 0.10233418643474579
49 11083 0.10224849730730057
50 11083 0.10602813959121704
51 11083 0.06467288732528687
52 11083 0.03071015328168869
53 11083 0.07892545312643051
54 11083 0.05221866816282272
55 11083 0.08319266140460968
56 11083 0.11629281938076019
57 11083 0.154544398188591
58 11083 0.27412688732147217
59 11083 0.30633822083473206
60 11083 0.2906595766544342
61 11083 0.14782758057117462
62 11083 0.1303800493478775
63 11083 0.1407739520072937
64 11083 0.113921619951725
65 11083 0.055181704461574554
66 11083 0.22790084779262543
67 11083 0.2479180097579956
68 11083 0.18765385448932648
69 11083 0.21593064069747925
70 11083 0.14178796112537384
71 11083 0.15499863028526306
72 11083 0.08060447871685028
73 11083 0.1342068910598755
74 11083 0.10670005530118942
75 11083 0.09098511189222336
76 11083 0.05062875524163246
77 11083 0.0699818804860115
78 11083 0.07772274315357208
79 11083 0.2670402526855469
80 11083 0.09590663760900497
81 11083 0.05670902132987976
82 11083 0.045893192291259766
83 11083 0.0306635070592165
84 11083 0.12149287015199661
85 11083 0.2961822748184204
86 11083 0.031030157580971718
87 11083 0.0782441794872284
88 11083 0.04303205385804176
89 11083 0.07071154564619064
90 11083 0.09529706090688705
91 11083 0.16351023316383362
92 11083 0.23378293216228485
93 11083 0.08366859704256058
94 11083 0.05446947365999222
95 11083 0.08343375474214554
96 11083 0.07448545098304749
97 11083 0.13198614120483398
98 11083 0.08172199875116348
99 11083 0.08250309526920319
100 11083 0.07744073867797852
101 11083 0.0719929188489914
102 11083 0.11577528715133667
103 11083 0.08119632303714752
104 11083 0.1392163336277008
105 11083 0.1494535207748413
106 11083 0.09779952466487885
107 11083 0.08904571086168289
108 11083 0.10563124716281891
109 11083 0.07980424165725708
110 11083 0.10017458349466324
train - Global loss: 0.103910    Embedding norm: 1.0000   Triplets (all/active): 99.8/2104.4
Pos dist (min/mean/max): 0.4051/0.7951/1.1607   Neg dist (min/mean/max): 1.0449/1.4101/1.6840
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.012991990894079208
4 445 0.0
val - Global loss: 0.002598    Embedding norm: 1.0000   Triplets (all/active): 89.0/1.6
Pos dist (min/mean/max): 0.1431/0.2908/0.5101   Neg dist (min/mean/max): 1.0063/1.3197/1.5894
0 11083 0.08505815267562866
1 11083 0.08300807327032089
2 11083 0.0825541764497757
3 11083 0.07992617785930634
4 11083 0.09243066608905792
5 11083 0.09558545053005219
6 11083 0.08673331886529922
7 11083 0.07466379553079605
8 11083 0.10690715909004211
9 11083 0.04357219487428665
10 11083 0.05430550128221512
11 11083 0.11452590674161911
12 11083 0.11837805807590485
13 11083 0.09161089360713959
14 11083 0.06682910770177841
15 11083 0.050151366740465164
16 11083 0.07523155957460403
17 11083 0.08234784752130508
18 11083 0.05830284208059311
19 11083 0.07228197157382965
20 11083 0.09254062175750732
21 11083 0.024051688611507416
22 11083 0.08453157544136047
23 11083 0.06120775267481804
24 11083 0.10646533221006393
25 11083 0.05411571264266968
26 11083 0.06747885793447495
27 11083 0.06966487318277359
28 11083 0.08367420732975006
29 11083 0.08246417343616486
30 11083 0.07285960018634796
31 11083 0.09705444425344467
32 11083 0.08347124606370926
33 11083 0.10510988533496857
34 11083 0.11836012452840805
35 11083 0.04923495277762413
36 11083 0.06229595094919205
37 11083 0.06446737796068192
38 11083 0.08243062347173691
39 11083 0.08195853233337402
40 11083 0.08520089834928513
41 11083 0.079019695520401
42 11083 0.06566710770130157
43 11083 0.1209498941898346
44 11083 0.08668378740549088
45 11083 0.0904344692826271
46 11083 0.09043030440807343
47 11083 0.09387373179197311
48 11083 0.09329670667648315
49 11083 0.08832655847072601
50 11083 0.06381501257419586
51 11083 0.06439539045095444
52 11083 0.11217629909515381
53 11083 0.07619712501764297
54 11083 0.06077699363231659
55 11083 0.06878023594617844
56 11083 0.12684352695941925
57 11083 0.15509644150733948
58 11083 0.24704766273498535
59 11083 0.3238030970096588
60 11083 0.309342622756958
61 11083 0.1232009306550026
62 11083 0.17316193878650665
63 11083 0.13584162294864655
64 11083 0.09650509059429169
65 11083 0.06685228645801544
66 11083 0.18963517248630524
67 11083 0.2653141915798187
68 11083 0.18760474026203156
69 11083 0.21606288850307465
70 11083 0.14127665758132935
71 11083 0.13449540734291077
72 11083 0.04617350175976753
73 11083 0.1669268012046814
74 11083 0.09583272784948349
75 11083 0.1094745546579361
76 11083 0.07484537363052368
77 11083 0.059603091329336166
78 11083 0.08160911500453949
79 11083 0.2057361602783203
80 11083 0.10454905033111572
81 11083 0.092147096991539
82 11083 0.11178810149431229
83 11083 0.08473896235227585
84 11083 0.11903823167085648
85 11083 0.31104159355163574
86 11083 0.06686707586050034
87 11083 0.07479646056890488
88 11083 0.05918920412659645
89 11083 0.05932126194238663
90 11083 0.14849868416786194
91 11083 0.12445158511400223
92 11083 0.23831936717033386
93 11083 0.055231522768735886
94 11083 0.05847516655921936
95 11083 0.043939851224422455
96 11083 0.11450662463903427
97 11083 0.14420999586582184
98 11083 0.06111450865864754
99 11083 0.09542740881443024
100 11083 0.047083109617233276
101 11083 0.1015395075082779
102 11083 0.09226664155721664
103 11083 0.0746852457523346
104 11083 0.12125970423221588
105 11083 0.11127530783414841
106 11083 0.08423022925853729
107 11083 0.08942882716655731
108 11083 0.11624161154031754
109 11083 0.0788358524441719
110 11083 0.09304020553827286
train - Global loss: 0.102772    Embedding norm: 1.0000   Triplets (all/active): 99.8/1909.7
Pos dist (min/mean/max): 0.4125/0.7856/1.1491   Neg dist (min/mean/max): 1.0561/1.4101/1.6757
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.026761820539832115
4 445 0.0
val - Global loss: 0.005352    Embedding norm: 1.0000   Triplets (all/active): 89.0/3.8
Pos dist (min/mean/max): 0.1589/0.3149/0.5537   Neg dist (min/mean/max): 1.0549/1.3596/1.5914
0 11083 0.11181581765413284
1 11083 0.08597735315561295
2 11083 0.0849565714597702
3 11083 0.09352441877126694
4 11083 0.0886266753077507
5 11083 0.06365655362606049
6 11083 0.04298793151974678
7 11083 0.10312429815530777
8 11083 0.09187990427017212
9 11083 0.05386718735098839
10 11083 0.13590270280838013
11 11083 0.0795554518699646
12 11083 0.08519153296947479
13 11083 0.07523585855960846
14 11083 0.06694945693016052
15 11083 0.0486031249165535
16 11083 0.08687753975391388
17 11083 0.04568098857998848
18 11083 0.06362573802471161
19 11083 0.07226341217756271
20 11083 0.02821863442659378
21 11083 0.05915491655468941
22 11083 0.0916469395160675
23 11083 0.07156691700220108
24 11083 0.060405489057302475
25 11083 0.05807491019368172
26 11083 0.08775398135185242
27 11083 0.0664963349699974
28 11083 0.03371520712971687
29 11083 0.08780253678560257
30 11083 0.08714516460895538
31 11083 0.09935158491134644
32 11083 0.05768711119890213
33 11083 0.06967931985855103
34 11083 0.08594990521669388
35 11083 0.06280951201915741
36 11083 0.06772036105394363
37 11083 0.037194374948740005
38 11083 0.12963946163654327
39 11083 0.10694316774606705
40 11083 0.08949998766183853
41 11083 0.06118009611964226
42 11083 0.06466903537511826
43 11083 0.10954835265874863
44 11083 0.12981274724006653
45 11083 0.05808715894818306
46 11083 0.09292803704738617
47 11083 0.06137659028172493
48 11083 0.08822555094957352
49 11083 0.10226019471883774
50 11083 0.05183833837509155
51 11083 0.059420548379421234
52 11083 0.059531982988119125
53 11083 0.0933806374669075
54 11083 0.09386791288852692
55 11083 0.06447475403547287
56 11083 0.09238427132368088
57 11083 0.13486047089099884
58 11083 0.23615163564682007
59 11083 0.3001490533351898
60 11083 0.3020462393760681
61 11083 0.16779875755310059
62 11083 0.08491834998130798
63 11083 0.14637380838394165
64 11083 0.11285702139139175
65 11083 0.06285843998193741
66 11083 0.15911370515823364
67 11083 0.21036148071289062
68 11083 0.1672685444355011
69 11083 0.18847468495368958
70 11083 0.1274886429309845
71 11083 0.11250320076942444
72 11083 0.061995137482881546
73 11083 0.15416474640369415
74 11083 0.12870965898036957
75 11083 0.061965227127075195
76 11083 0.06580778956413269
77 11083 0.06509902328252792
78 11083 0.0897253155708313
79 11083 0.21230554580688477
80 11083 0.10397064685821533
81 11083 0.12227435410022736
82 11083 0.08358658850193024
83 11083 0.042094841599464417
84 11083 0.11345645040273666
85 11083 0.34650692343711853
86 11083 0.050921618938446045
87 11083 0.08584623038768768
88 11083 0.10380164533853531
89 11083 0.08000078797340393
90 11083 0.2016417533159256
91 11083 0.13305535912513733
92 11083 0.1948053538799286
93 11083 0.07206325232982635
94 11083 0.04640327766537666
95 11083 0.07405798882246017
96 11083 0.08427681773900986
97 11083 0.10751327872276306
98 11083 0.11025544255971909
99 11083 0.07690674066543579
100 11083 0.10229048132896423
101 11083 0.08816567808389664
102 11083 0.10462989658117294
103 11083 0.06550092250108719
104 11083 0.09150216728448868
105 11083 0.11059343814849854
106 11083 0.059573639184236526
107 11083 0.05740796774625778
108 11083 0.09326998889446259
109 11083 0.06651464104652405
110 11083 0.0841064602136612
train - Global loss: 0.098304    Embedding norm: 1.0000   Triplets (all/active): 99.8/1798.3
Pos dist (min/mean/max): 0.4124/0.7804/1.1348   Neg dist (min/mean/max): 1.0539/1.4103/1.6716
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.04909032955765724
4 445 0.0
val - Global loss: 0.009818    Embedding norm: 1.0000   Triplets (all/active): 89.0/28.4
Pos dist (min/mean/max): 0.1514/0.2988/0.5100   Neg dist (min/mean/max): 1.0463/1.3519/1.6205
0 11083 0.0817379280924797
1 11083 0.0839259922504425
2 11083 0.06294531375169754
3 11083 0.08947385847568512
4 11083 0.10030796378850937
5 11083 0.06376060843467712
6 11083 0.05919473618268967
7 11083 0.08105392754077911
8 11083 0.09643238037824631
9 11083 0.059728238731622696
10 11083 0.06505107879638672
11 11083 0.12659800052642822
12 11083 0.10194797813892365
13 11083 0.07810985296964645
14 11083 0.07073894888162613
15 11083 0.05545780435204506
16 11083 0.051767487078905106
17 11083 0.04187854751944542
18 11083 0.06123221293091774
19 11083 0.11334534734487534
20 11083 0.08281059563159943
21 11083 0.0857417955994606
22 11083 0.07696783542633057
23 11083 0.054594896733760834
24 11083 0.07548284530639648
25 11083 0.06520553678274155
26 11083 0.09658931195735931
27 11083 0.041895292699337006
28 11083 0.0338779054582119
29 11083 0.06396225094795227
30 11083 0.0748286172747612
31 11083 0.09094799309968948
32 11083 0.04228216037154198
33 11083 0.10382649302482605
34 11083 0.036239828914403915
35 11083 0.05094550549983978
36 11083 0.06352543085813522
37 11083 0.045719046145677567
38 11083 0.07560323923826218
39 11083 0.07736752927303314
40 11083 0.07931239902973175
41 11083 0.08190307021141052
42 11083 0.06319911032915115
43 11083 0.08143538236618042
44 11083 0.07294503599405289
45 11083 0.07143517583608627
46 11083 0.09251829981803894
47 11083 0.06066063418984413
48 11083 0.10422436892986298
49 11083 0.09216105192899704
50 11083 0.13046735525131226
51 11083 0.048075512051582336
52 11083 0.07121551781892776
53 11083 0.044865019619464874
54 11083 0.06156931445002556
55 11083 0.08860436826944351
56 11083 0.08866824954748154
57 11083 0.13581396639347076
58 11083 0.24608148634433746
59 11083 0.32352104783058167
60 11083 0.32659366726875305
61 11083 0.143202543258667
62 11083 0.06533516943454742
63 11083 0.16053302586078644
64 11083 0.11187700182199478
65 11083 0.07443588227033615
66 11083 0.11926163733005524
67 11083 0.23322640359401703
68 11083 0.20361559092998505
69 11083 0.1960788518190384
70 11083 0.16999688744544983
71 11083 0.14810705184936523
72 11083 0.07656078785657883
73 11083 0.10627003759145737
74 11083 0.10338769108057022
75 11083 0.08856292814016342
76 11083 0.09738698601722717
77 11083 0.048919789493083954
78 11083 0.07727249711751938
79 11083 0.24573452770709991
80 11083 0.0827632024884224
81 11083 0.04933657497167587
82 11083 0.08870580792427063
83 11083 0.040674638003110886
84 11083 0.10871399939060211
85 11083 0.2838057279586792
86 11083 0.04991905391216278
87 11083 0.06530185788869858
88 11083 0.05782666802406311
89 11083 0.05434282124042511
90 11083 0.13188600540161133
91 11083 0.09934650361537933
92 11083 0.19439999759197235
93 11083 0.05773649737238884
94 11083 0.03419188782572746
95 11083 0.05882665514945984
96 11083 0.08604314923286438
97 11083 0.14391827583312988
98 11083 0.03854930400848389
99 11083 0.0530523955821991
100 11083 0.09046270698308945
101 11083 0.059134189039468765
102 11083 0.0763840451836586
103 11083 0.062058791518211365
104 11083 0.07887157052755356
105 11083 0.10081252455711365
106 11083 0.06421487033367157
107 11083 0.056251730769872665
108 11083 0.09369208663702011
109 11083 0.08314953744411469
110 11083 0.0793992131948471
train - Global loss: 0.093170    Embedding norm: 1.0000   Triplets (all/active): 99.8/1709.9
Pos dist (min/mean/max): 0.4088/0.7817/1.1209   Neg dist (min/mean/max): 1.0637/1.4108/1.6698
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1418/0.2960/0.5125   Neg dist (min/mean/max): 1.1084/1.3878/1.6994
0 11083 0.08029965311288834
1 11083 0.04840075969696045
2 11083 0.07592099905014038
3 11083 0.07131681591272354
4 11083 0.08189115673303604
5 11083 0.07926858216524124
6 11083 0.0751664936542511
7 11083 0.029268812388181686
8 11083 0.046426888555288315
9 11083 0.1163967177271843
10 11083 0.05339130014181137
11 11083 0.0785001814365387
12 11083 0.10784060508012772
13 11083 0.07195363938808441
14 11083 0.04177768528461456
15 11083 0.06575299054384232
16 11083 0.06565830111503601
17 11083 0.05499738082289696
18 11083 0.10546328127384186
19 11083 0.12131071090698242
20 11083 0.055670931935310364
21 11083 0.03146466240286827
22 11083 0.06615249067544937
23 11083 0.049173079431056976
24 11083 0.04303911700844765
25 11083 0.03489961475133896
26 11083 0.08463689684867859
27 11083 0.038237474858760834
28 11083 0.012595050036907196
29 11083 0.0722297728061676
30 11083 0.0642584040760994
31 11083 0.04736857861280441
32 11083 0.05853528156876564
33 11083 0.05656321719288826
34 11083 0.054858334362506866
35 11083 0.058447763323783875
36 11083 0.01672045886516571
37 11083 0.02354387193918228
38 11083 0.07284150272607803
39 11083 0.0468917153775692
40 11083 0.07401090860366821
41 11083 0.05749950185418129
42 11083 0.06470009684562683
43 11083 0.07369676232337952
44 11083 0.07311015576124191
45 11083 0.07799890637397766
46 11083 0.08781041204929352
47 11083 0.08495797961950302
48 11083 0.1035243347287178
49 11083 0.0954650342464447
50 11083 0.0282207690179348
51 11083 0.045851681381464005
52 11083 0.05160864070057869
53 11083 0.07130936533212662
54 11083 0.04109465330839157
55 11083 0.046759456396102905
56 11083 0.08003661036491394
57 11083 0.12152113020420074
58 11083 0.2126464992761612
59 11083 0.312564492225647
60 11083 0.2943054139614105
61 11083 0.11305901408195496
62 11083 0.08968617022037506
63 11083 0.1387968212366104
64 11083 0.1256856620311737
65 11083 0.09621221572160721
66 11083 0.1817793995141983
67 11083 0.21542033553123474
68 11083 0.1528637856245041
69 11083 0.16494765877723694
70 11083 0.14291365444660187
71 11083 0.12330884486436844
72 11083 0.04226095601916313
73 11083 0.10252252221107483
74 11083 0.08959238231182098
75 11083 0.06162702292203903
76 11083 0.036279112100601196
77 11083 0.04311145097017288
78 11083 0.07154987007379532
79 11083 0.1716393530368805
80 11083 0.07325390726327896
81 11083 0.040064189583063126
82 11083 0.06284617632627487
83 11083 0.021427081897854805
84 11083 0.10304208844900131
85 11083 0.3232281506061554
86 11083 0.0461512915790081
87 11083 0.03584188222885132
88 11083 0.044400110840797424
89 11083 0.08147572726011276
90 11083 0.20739558339118958
91 11083 0.10633674263954163
92 11083 0.21878167986869812
93 11083 0.03061053529381752
94 11083 0.053769566118717194
95 11083 0.02599356696009636
96 11083 0.09800056368112564
97 11083 0.12172508984804153
98 11083 0.060819704085588455
99 11083 0.06759779900312424
100 11083 0.09224909543991089
101 11083 0.041018296033144
102 11083 0.09890656918287277
103 11083 0.06780252605676651
104 11083 0.11045955121517181
105 11083 0.09730146825313568
106 11083 0.06414484232664108
107 11083 0.06563064455986023
108 11083 0.08783748745918274
109 11083 0.06016245856881142
110 11083 0.059778254479169846
train - Global loss: 0.084587    Embedding norm: 1.0000   Triplets (all/active): 99.8/1423.7
Pos dist (min/mean/max): 0.4054/0.7676/1.0971   Neg dist (min/mean/max): 1.0743/1.4110/1.6703
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1550/0.3030/0.5311   Neg dist (min/mean/max): 1.0756/1.3701/1.6160
0 11083 0.07785552740097046
1 11083 0.0774926021695137
2 11083 0.014561130665242672
3 11083 0.07768632471561432
4 11083 0.07614459842443466
5 11083 0.06771892309188843
6 11083 0.056355081498622894
7 11083 0.0783107653260231
8 11083 0.0433490127325058
9 11083 0.06872116029262543
10 11083 0.055653005838394165
11 11083 0.08211954683065414
12 11083 0.07311877608299255
13 11083 0.06562094390392303
14 11083 0.040256649255752563
15 11083 0.10436218231916428
16 11083 0.045258358120918274
17 11083 0.02457990124821663
18 11083 0.04779484495520592
19 11083 0.06073567643761635
20 11083 0.09743467718362808
21 11083 0.05643070116639137
22 11083 0.0899052619934082
23 11083 0.048438746482133865
24 11083 0.05080965533852577
25 11083 0.04512330889701843
26 11083 0.09792810678482056
27 11083 0.034370750188827515
28 11083 0.04431607201695442
29 11083 0.1142929196357727
30 11083 0.05647745728492737
31 11083 0.053359780460596085
32 11083 0.034072600305080414
33 11083 0.06935708969831467
34 11083 0.029054997488856316
35 11083 0.06674142926931381
36 11083 0.038612816482782364
37 11083 0.028737720102071762
38 11083 0.07189033180475235
39 11083 0.055748771876096725
40 11083 0.049286093562841415
41 11083 0.10802541673183441
42 11083 0.055228885263204575
43 11083 0.08558861166238785
44 11083 0.09078168869018555
45 11083 0.08975420147180557
46 11083 0.059710871428251266
47 11083 0.05583495274186134
48 11083 0.0915270671248436
49 11083 0.05637858435511589
50 11083 0.05696568638086319
51 11083 0.04404313862323761
52 11083 0.033868368715047836
53 11083 0.10541150718927383
54 11083 0.0823410376906395
55 11083 0.046279825270175934
56 11083 0.07868320494890213
57 11083 0.10091213881969452
58 11083 0.23323026299476624
59 11083 0.28796446323394775
60 11083 0.27954524755477905
61 11083 0.12541474401950836
62 11083 0.11430320143699646
63 11083 0.12312095612287521
64 11083 0.10816600173711777
65 11083 0.06908680498600006
66 11083 0.192118838429451
67 11083 0.20423664152622223
68 11083 0.17293637990951538
69 11083 0.18167883157730103
70 11083 0.16545113921165466
71 11083 0.10252252221107483
72 11083 0.042805030941963196
73 11083 0.08380667120218277
74 11083 0.1008702889084816
75 11083 0.061840642243623734
76 11083 0.03375783562660217
77 11083 0.06694503873586655
78 11083 0.10208798199892044
79 11083 0.17370714247226715
80 11083 0.08928410708904266
81 11083 0.04390155151486397
82 11083 0.03819030523300171
83 11083 0.04136119410395622
84 11083 0.13035522401332855
85 11083 0.26846450567245483
86 11083 0.03923608735203743
87 11083 0.01585051417350769
88 11083 0.05328638479113579
89 11083 0.021451426669955254
90 11083 0.22126947343349457
91 11083 0.07649976015090942
92 11083 0.18397372961044312
93 11083 0.05647797882556915
94 11083 0.04169198498129845
95 11083 0.04988265782594681
96 11083 0.07746227085590363
97 11083 0.12194395810365677
98 11083 0.05517616495490074
99 11083 0.053386881947517395
100 11083 0.03556857630610466
101 11083 0.05622505396604538
102 11083 0.07416215538978577
103 11083 0.05583922937512398
104 11083 0.07276292890310287
105 11083 0.12734238803386688
106 11083 0.08142508566379547
107 11083 0.048764847218990326
108 11083 0.06527823209762573
109 11083 0.07763320952653885
110 11083 0.0876927375793457
train - Global loss: 0.082873    Embedding norm: 1.0000   Triplets (all/active): 99.8/1322.1
Pos dist (min/mean/max): 0.4072/0.7607/1.0807   Neg dist (min/mean/max): 1.0814/1.4107/1.6631
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1523/0.2856/0.4931   Neg dist (min/mean/max): 1.1043/1.3765/1.6145
0 11083 0.076317198574543
1 11083 0.05437283590435982
2 11083 0.06533190608024597
3 11083 0.07023467868566513
4 11083 0.0797160416841507
5 11083 0.03838646784424782
6 11083 0.037936918437480927
7 11083 0.06442242115736008
8 11083 0.05700264498591423
9 11083 0.03780375048518181
10 11083 0.015198616310954094
11 11083 0.08842034637928009
12 11083 0.09184658527374268
13 11083 0.05281249061226845
14 11083 0.08312621712684631
15 11083 0.05632271245121956
16 11083 0.0525830015540123
17 11083 0.03174517676234245
18 11083 0.0587947778403759
19 11083 0.043435681611299515
20 11083 0.036016952246427536
21 11083 0.039171431213617325
22 11083 0.10953262448310852
23 11083 0.04373086616396904
24 11083 0.06351412832736969
25 11083 0.04829356074333191
26 11083 0.04815404862165451
27 11083 0.049472082406282425
28 11083 0.01227635145187378
29 11083 0.08316419273614883
30 11083 0.060677364468574524
31 11083 0.07057153433561325
32 11083 0.03451347351074219
33 11083 0.050032056868076324
34 11083 0.019196538254618645
35 11083 0.03275711461901665
36 11083 0.03471411392092705
37 11083 0.04247765243053436
38 11083 0.05857057124376297
39 11083 0.08439922332763672
40 11083 0.05345435068011284
41 11083 0.053404781967401505
42 11083 0.05180312320590019
43 11083 0.0805048793554306
44 11083 0.09940976649522781
45 11083 0.056432466953992844
46 11083 0.08904716372489929
47 11083 0.025543127208948135
48 11083 0.06525783240795135
49 11083 0.07028828561306
50 11083 0.030528275296092033
51 11083 0.03532511740922928
52 11083 0.03434952720999718
53 11083 0.07626711577177048
54 11083 0.04240164905786514
55 11083 0.05454585328698158
56 11083 0.07350525259971619
57 11083 0.09691711515188217
58 11083 0.2015470564365387
59 11083 0.2651868164539337
60 11083 0.2320547103881836
61 11083 0.09094176441431046
62 11083 0.08304573595523834
63 11083 0.10945397615432739
64 11083 0.07008851319551468
65 11083 0.04684120789170265
66 11083 0.13227395713329315
67 11083 0.1955568790435791
68 11083 0.16229049861431122
69 11083 0.16553838551044464
70 11083 0.12032856792211533
71 11083 0.13437628746032715
72 11083 0.03979615867137909
73 11083 0.07979259639978409
74 11083 0.07381384819746017
75 11083 0.04993239790201187
76 11083 0.0506921112537384
77 11083 0.07177484035491943
78 11083 0.08420281857252121
79 11083 0.15998294949531555
80 11083 0.10017949342727661
81 11083 0.042417652904987335
82 11083 0.04076988622546196
83 11083 0.022986434400081635
84 11083 0.09340417385101318
85 11083 0.2638757526874542
86 11083 0.025621376931667328
87 11083 0.042003083974123
88 11083 0.06019312143325806
89 11083 0.04815081134438515
90 11083 0.12570787966251373
91 11083 0.09968270361423492
92 11083 0.19422872364521027
93 11083 0.015378352254629135
94 11083 0.07186659425497055
95 11083 0.029646648094058037
96 11083 0.08177069574594498
97 11083 0.07091972976922989
98 11083 0.05209603160619736
99 11083 0.026838744059205055
100 11083 0.010724365711212158
101 11083 0.043925121426582336
102 11083 0.06867163628339767
103 11083 0.0843600407242775
104 11083 0.08109889924526215
105 11083 0.09963595122098923
106 11083 0.035626377910375595
107 11083 0.06028478220105171
108 11083 0.05276546627283096
109 11083 0.03730686381459236
110 11083 0.05508189648389816
train - Global loss: 0.072277    Embedding norm: 1.0000   Triplets (all/active): 99.8/1201.3
Pos dist (min/mean/max): 0.4051/0.7522/1.0658   Neg dist (min/mean/max): 1.0917/1.4109/1.6572
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1471/0.2817/0.4631   Neg dist (min/mean/max): 1.1318/1.3994/1.6272
0 11083 0.06428717076778412
1 11083 0.022029679268598557
2 11083 0.01927081309258938
3 11083 0.06529153883457184
4 11083 0.06345659494400024
5 11083 0.045297350734472275
6 11083 0.03708973526954651
7 11083 0.04347832128405571
8 11083 0.03555959463119507
9 11083 0.06311169266700745
10 11083 0.04520067200064659
11 11083 0.03349194675683975
12 11083 0.050551045686006546
13 11083 0.06696600466966629
14 11083 0.060960184782743454
15 11083 0.042148709297180176
16 11083 0.07368205487728119
17 11083 0.07992970943450928
18 11083 0.04853083938360214
19 11083 0.02204553596675396
20 11083 0.04467370733618736
21 11083 0.03179595246911049
22 11083 0.04588150605559349
23 11083 0.041416436433792114
24 11083 0.04035312682390213
25 11083 0.06045626848936081
26 11083 0.051596786826848984
27 11083 0.02430773712694645
28 11083 0.024289801716804504
29 11083 0.037194252014160156
30 11083 0.05624110624194145
31 11083 0.04532497003674507
32 11083 0.042426709085702896
33 11083 0.05023142322897911
34 11083 0.011889368295669556
35 11083 0.02905232459306717
36 11083 0.03585919737815857
37 11083 0.01470278762280941
38 11083 0.05452283099293709
39 11083 0.05630671977996826
40 11083 0.06884004175662994
41 11083 0.05557485297322273
42 11083 0.022315125912427902
43 11083 0.041783157736063004
44 11083 0.06857573240995407
45 11083 0.05726465955376625
46 11083 0.05026831477880478
47 11083 0.059419337660074234
48 11083 0.0500413179397583
49 11083 0.04990081861615181
50 11083 0.03280044347047806
51 11083 0.03331133350729942
52 11083 0.029037704691290855
53 11083 0.04504777863621712
54 11083 0.1280977725982666
55 11083 0.04554634168744087
56 11083 0.1007380411028862
57 11083 0.10729844123125076
58 11083 0.1790965497493744
59 11083 0.25827157497406006
60 11083 0.2602023184299469
61 11083 0.08917031437158585
62 11083 0.06918428838253021
63 11083 0.12265093624591827
64 11083 0.05351843684911728
65 11083 0.04033837839961052
66 11083 0.10728703439235687
67 11083 0.19469526410102844
68 11083 0.15043474733829498
69 11083 0.1790764033794403
70 11083 0.14561490714550018
71 11083 0.08868063986301422
72 11083 0.03256824240088463
73 11083 0.07199615240097046
74 11083 0.053705811500549316
75 11083 0.024042848497629166
76 11083 0.04945624619722366
77 11083 0.039343368262052536
78 11083 0.06150463595986366
79 11083 0.15809905529022217
80 11083 0.06256133317947388
81 11083 0.01874370686709881
82 11083 0.08718191832304001
83 11083 0.03330954536795616
84 11083 0.11712320894002914
85 11083 0.31600770354270935
86 11083 0.033299945294857025
87 11083 0.05805587023496628
88 11083 0.028112037107348442
89 11083 0.055539753288030624
90 11083 0.10590272396802902
91 11083 0.0797308087348938
92 11083 0.22131435573101044
93 11083 0.08557550609111786
94 11083 0.03694840520620346
95 11083 0.0192546509206295
96 11083 0.07907935231924057
97 11083 0.09848694503307343
98 11083 0.0374019518494606
99 11083 0.06839804351329803
100 11083 0.07487735897302628
101 11083 0.03678099811077118
102 11083 0.06585954874753952
103 11083 0.059978075325489044
104 11083 0.06984904408454895
105 11083 0.07428780943155289
106 11083 0.014994671568274498
107 11083 0.05598245933651924
108 11083 0.06680584698915482
109 11083 0.06307557225227356
110 11083 0.045539963990449905
train - Global loss: 0.067800    Embedding norm: 1.0000   Triplets (all/active): 99.8/1063.0
Pos dist (min/mean/max): 0.4053/0.7461/1.0535   Neg dist (min/mean/max): 1.0930/1.4104/1.6606
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1521/0.2937/0.4873   Neg dist (min/mean/max): 1.1586/1.3951/1.6243
0 11083 0.052432432770729065
1 11083 0.025970710441470146
2 11083 0.03504607453942299
3 11083 0.040594492107629776
4 11083 0.0718485489487648
5 11083 0.04196438193321228
6 11083 0.012164518237113953
7 11083 0.02555893361568451
8 11083 0.04385533556342125
9 11083 0.023127268999814987
10 11083 0.02388845942914486
11 11083 0.04221157729625702
12 11083 0.052711065858602524
13 11083 0.09402719140052795
14 11083 0.015964506193995476
15 11083 0.08464893698692322
16 11083 0.0447004996240139
17 11083 0.02536650002002716
18 11083 0.0296490378677845
19 11083 0.09349683672189713
20 11083 0.03869442641735077
21 11083 0.03309864178299904
22 11083 0.04594001546502113
23 11083 0.06095651909708977
24 11083 0.03984296694397926
25 11083 0.024689018726348877
26 11083 0.02827303670346737
27 11083 0.03757956624031067
28 11083 0.00821615755558014
29 11083 0.08179594576358795
30 11083 0.03891976922750473
31 11083 0.07524649053812027
32 11083 0.03604397550225258
33 11083 0.06076148524880409
34 11083 0.04444346949458122
35 11083 0.05603669956326485
36 11083 0.02150655724108219
37 11083 0.012305647134780884
38 11083 0.02660469524562359
39 11083 0.06563438475131989
40 11083 0.05296625196933746
41 11083 0.03560316935181618
42 11083 0.047660332173109055
43 11083 0.05425875633955002
44 11083 0.0551341250538826
45 11083 0.03510546311736107
46 11083 0.04654862359166145
47 11083 0.024659039452672005
48 11083 0.027347151190042496
49 11083 0.06349597871303558
50 11083 0.03984598442912102
51 11083 0.00261591374874115
52 11083 0.025991423055529594
53 11083 0.08387823402881622
54 11083 0.03905004262924194
55 11083 0.07126264274120331
56 11083 0.06469623744487762
57 11083 0.12228552997112274
58 11083 0.21201442182064056
59 11083 0.26658952236175537
60 11083 0.24848827719688416
61 11083 0.09584718942642212
62 11083 0.07075101137161255
63 11083 0.11529858410358429
64 11083 0.05427677556872368
65 11083 0.03210710361599922
66 11083 0.09331054985523224
67 11083 0.18073615431785583
68 11083 0.14602802693843842
69 11083 0.1368613988161087
70 11083 0.11146395653486252
71 11083 0.09585306793451309
72 11083 0.014537452720105648
73 11083 0.07374729216098785
74 11083 0.06371152400970459
75 11083 0.05774476006627083
76 11083 0.11230967938899994
77 11083 0.03463186323642731
78 11083 0.05807388573884964
79 11083 0.20265723764896393
80 11083 0.05623675137758255
81 11083 0.02163001149892807
82 11083 0.009671801701188087
83 11083 0.03150657191872597
84 11083 0.07364995777606964
85 11083 0.2648804485797882
86 11083 0.034427642822265625
87 11083 0.02246171422302723
88 11083 0.038182150572538376
89 11083 0.025868479162454605
90 11083 0.10626129060983658
91 11083 0.07838691025972366
92 11083 0.19380709528923035
93 11083 0.0169975645840168
94 11083 0.03910557180643082
95 11083 0.020617220550775528
96 11083 0.08167219907045364
97 11083 0.10088172554969788
98 11083 0.04017852246761322
99 11083 0.06515704840421677
100 11083 0.038450937718153
101 11083 0.0632648840546608
102 11083 0.09517959505319595
103 11083 0.04002850502729416
104 11083 0.08104017376899719
105 11083 0.07180454581975937
106 11083 0.061759524047374725
107 11083 0.051694370806217194
108 11083 0.06674913316965103
109 11083 0.05621105059981346
110 11083 0.029862165451049805
train - Global loss: 0.063630    Embedding norm: 1.0000   Triplets (all/active): 99.8/1022.7
Pos dist (min/mean/max): 0.4136/0.7460/1.0360   Neg dist (min/mean/max): 1.1008/1.4112/1.6544
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1567/0.2947/0.4601   Neg dist (min/mean/max): 1.0857/1.4043/1.5980
0 11083 0.08048972487449646
1 11083 0.03196883946657181
2 11083 0.02256728522479534
3 11083 0.027914319187402725
4 11083 0.05347573384642601
5 11083 0.008083934895694256
6 11083 0.01611185073852539
7 11083 0.044410161674022675
8 11083 0.042430464178323746
9 11083 0.021281516179442406
10 11083 0.04141923412680626
11 11083 0.06362763792276382
12 11083 0.05304955691099167
13 11083 0.02590174973011017
14 11083 0.05628169700503349
15 11083 0.073048897087574
16 11083 0.0332210510969162
17 11083 0.016912229359149933
18 11083 0.040053512901067734
19 11083 0.07430598884820938
20 11083 0.03750188276171684
21 11083 0.008536468259990215
22 11083 0.0860004797577858
23 11083 0.026018746197223663
24 11083 0.015504671260714531
25 11083 0.009859919548034668
26 11083 0.021330678835511208
27 11083 0.09651421010494232
28 11083 0.005702972412109375
29 11083 0.042464207857847214
30 11083 0.028183363378047943
31 11083 0.05513012781739235
32 11083 0.03195269778370857
33 11083 0.06718481332063675
34 11083 0.04205676540732384
35 11083 0.013485138304531574
36 11083 0.020900428295135498
37 11083 0.0129247410222888
38 11083 0.025629740208387375
39 11083 0.08550240099430084
40 11083 0.03955227881669998
41 11083 0.046348512172698975
42 11083 0.032495662569999695
43 11083 0.05720606446266174
44 11083 0.05198003351688385
45 11083 0.005564393475651741
46 11083 0.032876674085855484
47 11083 0.03153228759765625
48 11083 0.036927495151758194
49 11083 0.022628093138337135
50 11083 0.03209657222032547
51 11083 0.028233783319592476
52 11083 0.0345798023045063
53 11083 0.059266217052936554
54 11083 0.0276070274412632
55 11083 0.039246439933776855
56 11083 0.06220070645213127
57 11083 0.10586560517549515
58 11083 0.15061387419700623
59 11083 0.23860786855220795
60 11083 0.22631476819515228
61 11083 0.09500981122255325
62 11083 0.0475747175514698
63 11083 0.1020321473479271
64 11083 0.05237350985407829
65 11083 0.031511545181274414
66 11083 0.13409976661205292
67 11083 0.14611715078353882
68 11083 0.13374610245227814
69 11083 0.14476142823696136
70 11083 0.08926989138126373
71 11083 0.09831924736499786
72 11083 0.024253830313682556
73 11083 0.07631592452526093
74 11083 0.035214319825172424
75 11083 0.026757895946502686
76 11083 0.04193409904837608
77 11083 0.03189188241958618
78 11083 0.07365968823432922
79 11083 0.19742362201213837
80 11083 0.048785094171762466
81 11083 0.017901280894875526
82 11083 0.015794333070516586
83 11083 0.032955557107925415
84 11083 0.05485609173774719
85 11083 0.2402908354997635
86 11083 0.06385484337806702
87 11083 0.02623368799686432
88 11083 0.02911088988184929
89 11083 0.016391173005104065
90 11083 0.08236140012741089
91 11083 0.05453518405556679
92 11083 0.1553204357624054
93 11083 0.05090061202645302
94 11083 0.00840826891362667
95 11083 0.00818246603012085
96 11083 0.08241617679595947
97 11083 0.04525217041373253
98 11083 0.015844136476516724
99 11083 0.038576725870370865
100 11083 0.010618813335895538
101 11083 0.039796944707632065
102 11083 0.07674668729305267
103 11083 0.01791541278362274
104 11083 0.06524242460727692
105 11083 0.05719446390867233
106 11083 0.05741848796606064
107 11083 0.03821118548512459
108 11083 0.036153264343738556
109 11083 0.06067800894379616
110 11083 0.05497188866138458
train - Global loss: 0.055008    Embedding norm: 1.0000   Triplets (all/active): 99.8/801.1
Pos dist (min/mean/max): 0.4087/0.7348/1.0025   Neg dist (min/mean/max): 1.1041/1.4111/1.6514
0 445 0.0
1 445 0.0
2 445 0.010739505290985107
3 445 0.0
4 445 0.0
val - Global loss: 0.002148    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.2
Pos dist (min/mean/max): 0.1531/0.2905/0.5133   Neg dist (min/mean/max): 1.1431/1.3908/1.6220
0 11083 0.031509339809417725
1 11083 0.0916585698723793
2 11083 0.0
3 11083 0.06915794312953949
4 11083 0.05489316210150719
5 11083 0.033651962876319885
6 11083 0.010364091023802757
7 11083 0.05218701437115669
8 11083 0.03552893176674843
9 11083 0.027879714965820312
10 11083 0.0431915707886219
11 11083 0.0345698744058609
12 11083 0.05423565208911896
13 11083 0.05895010009407997
14 11083 0.04725232720375061
15 11083 0.038446441292762756
16 11083 0.02149892970919609
17 11083 0.028942324221134186
18 11083 0.03359711915254593
19 11083 0.011183182708919048
20 11083 0.03246576711535454
21 11083 0.012746959924697876
22 11083 0.04934235289692879
23 11083 0.04191882163286209
24 11083 0.05071483924984932
25 11083 0.030454132705926895
26 11083 0.026238294318318367
27 11083 0.07909351587295532
28 11083 0.0
29 11083 0.042634304612874985
30 11083 0.05437140911817551
31 11083 0.03915275260806084
32 11083 0.04283600300550461
33 11083 0.06423185765743256
34 11083 0.014978533610701561
35 11083 0.04849715530872345
36 11083 0.026371488347649574
37 11083 0.0
38 11083 0.03003069758415222
39 11083 0.04742222651839256
40 11083 0.04848207160830498
41 11083 0.021138083189725876
42 11083 0.035911791026592255
43 11083 0.09733704477548599
44 11083 0.08160801976919174
45 11083 0.030471976846456528
46 11083 0.04476017504930496
47 11083 0.04395236074924469
48 11083 0.029662251472473145
49 11083 0.05181603133678436
50 11083 0.0
51 11083 0.029914336279034615
52 11083 0.016238238662481308
53 11083 0.041457731276750565
54 11083 0.07216508686542511
55 11083 0.03475905582308769
56 11083 0.0497320219874382
57 11083 0.09195972234010696
58 11083 0.17961837351322174
59 11083 0.2053249180316925
60 11083 0.2403385490179062
61 11083 0.10837914794683456
62 11083 0.053359244018793106
63 11083 0.08074846118688583
64 11083 0.04764099419116974
65 11083 0.0031744837760925293
66 11083 0.10471080988645554
67 11083 0.17299869656562805
68 11083 0.1417716145515442
69 11083 0.12466800957918167
70 11083 0.10854501277208328
71 11083 0.044530436396598816
72 11083 0.023836039006710052
73 11083 0.04443301260471344
74 11083 0.02400272898375988
75 11083 0.031607579439878464
76 11083 0.02386714518070221
77 11083 0.02223450317978859
78 11083 0.037448640912771225
79 11083 0.17916260659694672
80 11083 0.04245280846953392
81 11083 0.03924714773893356
82 11083 0.004561722278594971
83 11083 0.0
84 11083 0.05482858791947365
85 11083 0.25773751735687256
86 11083 0.021102424710989
87 11083 0.0274810791015625
88 11083 0.03501296788454056
89 11083 0.040381141006946564
90 11083 0.06226377561688423
91 11083 0.05961326137185097
92 11083 0.13027067482471466
93 11083 0.016373980790376663
94 11083 0.024180611595511436
95 11083 0.028324592858552933
96 11083 0.055269431322813034
97 11083 0.07209035754203796
98 11083 0.02340530976653099
99 11083 0.02375880815088749
100 11083 0.02180078811943531
101 11083 0.02640766277909279
102 11083 0.05197279155254364
103 11083 0.05164046213030815
104 11083 0.0424920879304409
105 11083 0.05165436491370201
106 11083 0.0336197204887867
107 11083 0.025771364569664
108 11083 0.03079792857170105
109 11083 0.04848538711667061
110 11083 0.07209815084934235
train - Global loss: 0.052352    Embedding norm: 1.0000   Triplets (all/active): 99.8/670.8
Pos dist (min/mean/max): 0.4033/0.7272/0.9978   Neg dist (min/mean/max): 1.1101/1.4110/1.6479
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1535/0.2830/0.4577   Neg dist (min/mean/max): 1.1352/1.4007/1.6303
0 11083 0.025473618879914284
1 11083 0.009585072286427021
2 11083 0.029080715030431747
3 11083 0.016443349421024323
4 11083 0.03921378776431084
5 11083 0.013343896716833115
6 11083 0.032344214618206024
7 11083 0.029710229486227036
8 11083 0.032081689685583115
9 11083 0.0
10 11083 0.04405812919139862
11 11083 0.05296236649155617
12 11083 0.03417925536632538
13 11083 0.036643508821725845
14 11083 0.03883134946227074
15 11083 0.024326762184500694
16 11083 0.0
17 11083 0.006970882415771484
18 11083 0.023652469739317894
19 11083 0.04097375646233559
20 11083 0.0
21 11083 0.002616479992866516
22 11083 0.02985083870589733
23 11083 0.033889882266521454
24 11083 0.04465698450803757
25 11083 0.006602957844734192
26 11083 0.030415594577789307
27 11083 0.008537232875823975
28 11083 0.04525157809257507
29 11083 0.026294061914086342
30 11083 0.03478564694523811
31 11083 0.03975833207368851
32 11083 0.008662961423397064
33 11083 0.021346667781472206
34 11083 0.012183284386992455
35 11083 0.0
36 11083 0.0
37 11083 0.0
38 11083 0.037756215780973434
39 11083 0.03263869881629944
40 11083 0.0545673705637455
41 11083 0.03533891215920448
42 11083 0.018291160464286804
43 11083 0.024583470076322556
44 11083 0.042780909687280655
45 11083 0.03849386051297188
46 11083 0.031474899500608444
47 11083 0.06599060446023941
48 11083 0.04118739441037178
49 11083 0.055882152169942856
50 11083 0.02658180706202984
51 11083 0.013260602951049805
52 11083 0.0
53 11083 0.017163297161459923
54 11083 0.020858902484178543
55 11083 0.0322326235473156
56 11083 0.026913849636912346
57 11083 0.06698454916477203
58 11083 0.18620681762695312
59 11083 0.22260965406894684
60 11083 0.2339484542608261
61 11083 0.07526072859764099
62 11083 0.04577158764004707
63 11083 0.084934301674366
64 11083 0.03697467967867851
65 11083 0.005239665508270264
66 11083 0.11824340373277664
67 11083 0.14510565996170044
68 11083 0.12991251051425934
69 11083 0.13834567368030548
70 11083 0.06896981596946716
71 11083 0.05655748024582863
72 11083 0.035801663994789124
73 11083 0.03418587148189545
74 11083 0.022494014352560043
75 11083 0.022167913615703583
76 11083 0.02673530764877796
77 11083 0.012782663106918335
78 11083 0.030867988243699074
79 11083 0.19548311829566956
80 11083 0.03617028519511223
81 11083 0.015585890039801598
82 11083 0.0
83 11083 0.027562178671360016
84 11083 0.054650407284498215
85 11083 0.21906332671642303
86 11083 0.0007991790771484375
87 11083 0.006826367229223251
88 11083 0.012637993320822716
89 11083 0.01955965720117092
90 11083 0.06421773135662079
91 11083 0.06664721667766571
92 11083 0.12691867351531982
93 11083 0.02125803381204605
94 11083 0.015930593013763428
95 11083 0.0
96 11083 0.06655728071928024
97 11083 0.08572030812501907
98 11083 0.014433253556489944
99 11083 0.003090187907218933
100 11083 0.0
101 11083 0.04099266976118088
102 11083 0.04387276992201805
103 11083 0.03115774132311344
104 11083 0.03764958307147026
105 11083 0.01844123750925064
106 11083 0.02426995523273945
107 11083 0.015142606571316719
108 11083 0.01092215720564127
109 11083 0.027333330363035202
110 11083 0.015570370480418205
train - Global loss: 0.041525    Embedding norm: 1.0000   Triplets (all/active): 99.8/555.9
Pos dist (min/mean/max): 0.4050/0.7201/0.9713   Neg dist (min/mean/max): 1.1216/1.4108/1.6423
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1682/0.2892/0.4498   Neg dist (min/mean/max): 1.1679/1.4067/1.6153
0 11083 0.04262274131178856
1 11083 0.027732020244002342
2 11083 0.010681748390197754
3 11083 0.01942763850092888
4 11083 0.0491614006459713
5 11083 0.0
6 11083 0.002924710512161255
7 11083 0.0
8 11083 0.018677324056625366
9 11083 0.0
10 11083 0.015880918130278587
11 11083 0.12832951545715332
12 11083 0.02122701145708561
13 11083 0.04007381200790405
14 11083 0.0
15 11083 0.039308346807956696
16 11083 0.018818140029907227
17 11083 0.0
18 11083 0.01015251874923706
19 11083 0.0
20 11083 0.0
21 11083 0.0
22 11083 0.03440871834754944
23 11083 0.03808411955833435
24 11083 0.013067884370684624
25 11083 0.03621271252632141
26 11083 0.03370146453380585
27 11083 0.03114328533411026
28 11083 0.02871938794851303
29 11083 0.022463738918304443
30 11083 0.053193747997283936
31 11083 0.037709396332502365
32 11083 0.0
33 11083 0.024719180539250374
34 11083 0.0
35 11083 0.046219807118177414
36 11083 0.018533697351813316
37 11083 0.0
38 11083 0.02484072558581829
39 11083 0.02629496343433857
40 11083 0.04208787903189659
41 11083 0.023114845156669617
42 11083 0.02377353236079216
43 11083 0.020098499953746796
44 11083 0.03227205574512482
45 11083 0.012869155965745449
46 11083 0.016204243525862694
47 11083 0.014023324474692345
48 11083 0.03776509687304497
49 11083 0.019414309412240982
50 11083 0.0
51 11083 0.0
52 11083 0.008525749668478966
53 11083 0.040541741997003555
54 11083 0.03351375088095665
55 11083 0.002807915210723877
56 11083 0.06984532624483109
57 11083 0.05757971853017807
58 11083 0.18903081119060516
59 11083 0.20532865822315216
60 11083 0.21072562038898468
61 11083 0.08281134814023972
62 11083 0.02906566485762596
63 11083 0.06429632008075714
64 11083 0.022201096639037132
65 11083 0.013211175799369812
66 11083 0.10336149483919144
67 11083 0.13897399604320526
68 11083 0.10515598207712173
69 11083 0.12139102816581726
70 11083 0.053246065974235535
71 11083 0.05810840055346489
72 11083 0.04156931862235069
73 11083 0.049445196986198425
74 11083 0.022382788360118866
75 11083 0.015101362951099873
76 11083 0.0
77 11083 0.023150449618697166
78 11083 0.019486121833324432
79 11083 0.18223506212234497
80 11083 0.012079203501343727
81 11083 0.0
82 11083 0.0
83 11083 0.01880766823887825
84 11083 0.05688157677650452
85 11083 0.2177380919456482
86 11083 0.02302597090601921
87 11083 0.029727624729275703
88 11083 0.031194722279906273
89 11083 0.013984687626361847
90 11083 0.0695156678557396
91 11083 0.034214235842227936
92 11083 0.09876767545938492
93 11083 0.02170291170477867
94 11083 0.004379391670227051
95 11083 0.0
96 11083 0.033855196088552475
97 11083 0.027014778926968575
98 11083 0.0
99 11083 0.022344136610627174
100 11083 0.0
101 11083 0.019110798835754395
102 11083 0.03837646543979645
103 11083 0.006399152800440788
104 11083 0.027233555912971497
105 11083 0.023448791354894638
106 11083 0.0
107 11083 0.024936746805906296
108 11083 0.030224403366446495
109 11083 0.030696222558617592
110 11083 0.020603880286216736
train - Global loss: 0.036534    Embedding norm: 1.0000   Triplets (all/active): 99.8/491.9
Pos dist (min/mean/max): 0.4080/0.7143/0.9592   Neg dist (min/mean/max): 1.1298/1.4112/1.6395
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1601/0.2909/0.4751   Neg dist (min/mean/max): 1.1932/1.4160/1.6160
0 11083 0.026963265612721443
1 11083 0.02565084397792816
2 11083 0.021763082593679428
3 11083 0.04053899273276329
4 11083 0.03274628147482872
5 11083 0.030138518661260605
6 11083 0.020135700702667236
7 11083 0.0
8 11083 0.009842982515692711
9 11083 0.0
10 11083 0.03564923256635666
11 11083 0.03941456228494644
12 11083 0.012382772751152515
13 11083 0.005540579557418823
14 11083 0.01885971799492836
15 11083 0.01905025728046894
16 11083 0.0
17 11083 0.0
18 11083 0.01904737949371338
19 11083 0.0
20 11083 0.0
21 11083 0.02243330143392086
22 11083 0.03290833160281181
23 11083 0.017983712255954742
24 11083 0.00702880322933197
25 11083 0.0
26 11083 0.0
27 11083 0.0
28 11083 0.0
29 11083 0.011434067040681839
30 11083 0.021633414551615715
31 11083 0.029424060136079788
32 11083 0.03288645297288895
33 11083 0.0
34 11083 0.006468638777732849
35 11083 0.020083332434296608
36 11083 0.0
37 11083 0.0
38 11083 0.04223230481147766
39 11083 0.03566195070743561
40 11083 0.035529155284166336
41 11083 0.0
42 11083 0.0
43 11083 0.05568092316389084
44 11083 0.03469536826014519
45 11083 0.018953323364257812
46 11083 0.027961233630776405
47 11083 0.0
48 11083 0.03949268162250519
49 11083 0.03841748088598251
50 11083 0.0
51 11083 0.03144855052232742
52 11083 0.0
53 11083 0.09735486656427383
54 11083 0.0
55 11083 0.040879081934690475
56 11083 0.018894750624895096
57 11083 0.05349649861454964
58 11083 0.16979937255382538
59 11083 0.2133074551820755
60 11083 0.1917218416929245
61 11083 0.05303911492228508
62 11083 0.028168419376015663
63 11083 0.06208455190062523
64 11083 0.03241714462637901
65 11083 0.0
66 11083 0.08255794644355774
67 11083 0.1382414549589157
68 11083 0.08816008269786835
69 11083 0.10097108781337738
70 11083 0.05390211567282677
71 11083 0.03323081508278847
72 11083 0.0
73 11083 0.03956827521324158
74 11083 0.011189639568328857
75 11083 0.02339119277894497
76 11083 0.017903640866279602
77 11083 0.0
78 11083 0.013694817200303078
79 11083 0.1526905745267868
80 11083 0.01669221930205822
81 11083 0.0
82 11083 0.03067363239824772
83 11083 0.0
84 11083 0.04423226788640022
85 11083 0.19969208538532257
86 11083 0.0
87 11083 0.0
88 11083 0.010706424713134766
89 11083 0.014066792093217373
90 11083 0.05106231942772865
91 11083 0.03863223269581795
92 11083 0.10418356209993362
93 11083 0.0
94 11083 0.0027977824211120605
95 11083 0.0015044212341308594
96 11083 0.042445581406354904
97 11083 0.029309634119272232
98 11083 0.02070808783173561
99 11083 0.014661120250821114
100 11083 0.0
101 11083 0.0025370121002197266
102 11083 0.018543796613812447
103 11083 0.0
104 11083 0.03862456604838371
105 11083 0.013829648494720459
106 11083 0.0068170130252838135
107 11083 0.019194552674889565
108 11083 0.0094958720728755
109 11083 0.023287808522582054
110 11083 0.01872243359684944
train - Global loss: 0.030713    Embedding norm: 1.0000   Triplets (all/active): 99.8/465.7
Pos dist (min/mean/max): 0.4084/0.7117/0.9499   Neg dist (min/mean/max): 1.1425/1.4113/1.6386
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1605/0.2917/0.4711   Neg dist (min/mean/max): 1.1917/1.4167/1.6141
0 11083 0.020578082650899887
1 11083 0.030693810433149338
2 11083 0.026165500283241272
3 11083 0.021653171628713608
4 11083 0.07138288766145706
5 11083 0.016882581636309624
6 11083 0.0
7 11083 0.02731035090982914
8 11083 0.0
9 11083 0.0
10 11083 0.0
11 11083 0.0
12 11083 0.01616767607629299
13 11083 0.018625151365995407
14 11083 0.0
15 11083 0.02250473015010357
16 11083 0.0
17 11083 0.0
18 11083 0.0
19 11083 0.0
20 11083 0.0
21 11083 0.0
22 11083 0.016501933336257935
23 11083 0.0
24 11083 0.0
25 11083 0.0011814385652542114
26 11083 0.0025196373462677
27 11083 0.031717777252197266
28 11083 0.0
29 11083 0.04115389660000801
30 11083 0.031177939847111702
31 11083 0.00781603530049324
32 11083 0.0
33 11083 0.05029340460896492
34 11083 0.0
35 11083 0.0
36 11083 0.0
37 11083 0.0
38 11083 0.0
39 11083 0.10908738523721695
40 11083 0.015760915353894234
41 11083 0.0
42 11083 0.0
43 11083 0.047757718712091446
44 11083 0.020765528082847595
45 11083 0.0038134753704071045
46 11083 0.038026437163352966
47 11083 0.0
48 11083 0.013502180576324463
49 11083 0.025882115587592125
50 11083 0.02546561323106289
51 11083 0.0
52 11083 0.030269164592027664
53 11083 0.02875937521457672
54 11083 0.037317097187042236
55 11083 0.010782867670059204
56 11083 0.022991178557276726
57 11083 0.06349144876003265
58 11083 0.17800335586071014
59 11083 0.19830071926116943
60 11083 0.22318227589130402
61 11083 0.07410043478012085
62 11083 0.037366099655628204
63 11083 0.0511830598115921
64 11083 0.02203970029950142
65 11083 0.029051881283521652
66 11083 0.05306417495012283
67 11083 0.1268450766801834
68 11083 0.09411876648664474
69 11083 0.11640746891498566
70 11083 0.059287555515766144
71 11083 0.02779380977153778
72 11083 0.0
73 11083 0.016452385112643242
74 11083 0.010989944450557232
75 11083 0.03785713389515877
76 11083 0.0
77 11083 0.0
78 11083 0.0022618472576141357
79 11083 0.1391264796257019
80 11083 0.014550588093698025
81 11083 0.0
82 11083 0.02177063561975956
83 11083 0.0182679183781147
84 11083 0.028729218989610672
85 11083 0.17809587717056274
86 11083 0.0
87 11083 0.006122216582298279
88 11083 0.0
89 11083 0.028528371825814247
90 11083 0.06466222554445267
91 11083 0.04087582230567932
92 11083 0.08433183282613754
93 11083 0.0
94 11083 0.01632426306605339
95 11083 0.017016887664794922
96 11083 0.04398871585726738
97 11083 0.026497213169932365
98 11083 0.03506815806031227
99 11083 0.0
100 11083 0.006060443818569183
101 11083 0.01175302267074585
102 11083 0.011098389513790607
103 11083 0.025336049497127533
104 11083 0.021154211834073067
105 11083 0.02737220749258995
106 11083 0.0
107 11083 0.025870254263281822
108 11083 0.020436128601431847
109 11083 0.0224007535725832
110 11083 0.012353453785181046
train - Global loss: 0.029316    Embedding norm: 1.0000   Triplets (all/active): 99.8/409.6
Pos dist (min/mean/max): 0.4080/0.7079/0.9355   Neg dist (min/mean/max): 1.1366/1.4110/1.6382
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1615/0.2937/0.4781   Neg dist (min/mean/max): 1.1623/1.4169/1.6177
0 11083 0.022134913131594658
1 11083 0.005288422107696533
2 11083 0.0031245946884155273
3 11083 0.03439490497112274
4 11083 0.04781906306743622
5 11083 0.02388048730790615
6 11083 0.0
7 11083 0.08987356722354889
8 11083 0.0
9 11083 0.0
10 11083 0.0
11 11083 0.017061926424503326
12 11083 0.012454479932785034
13 11083 0.0029492974281311035
14 11083 0.0
15 11083 0.0
16 11083 0.03927171230316162
17 11083 0.02034684643149376
18 11083 0.005759894847869873
19 11083 0.0
20 11083 0.0
21 11083 0.0
22 11083 0.006248056888580322
23 11083 0.0
24 11083 0.0251566544175148
25 11083 0.02056175470352173
26 11083 0.016780167818069458
27 11083 0.0
28 11083 0.0
29 11083 0.011811770498752594
30 11083 0.022042151540517807
31 11083 0.01862674579024315
32 11083 0.0
33 11083 0.013203371316194534
34 11083 0.0
35 11083 0.021500777453184128
36 11083 0.0
37 11083 0.0
38 11083 0.0
39 11083 0.03415113687515259
40 11083 0.039840880781412125
41 11083 0.0
42 11083 0.0
43 11083 0.013650036416947842
44 11083 0.02389715425670147
45 11083 0.034506238996982574
46 11083 0.033856168389320374
47 11083 0.0
48 11083 0.013005971908569336
49 11083 0.03474504128098488
50 11083 0.0
51 11083 0.0
52 11083 0.0
53 11083 0.00411631166934967
54 11083 0.0
55 11083 0.0
56 11083 0.0481257438659668
57 11083 0.047699954360723495
58 11083 0.174704447388649
59 11083 0.1926615983247757
60 11083 0.21753230690956116
61 11083 0.07233876734972
62 11083 0.024136560037732124
63 11083 0.05790258198976517
64 11083 0.0059905946254730225
65 11083 0.021432673558592796
66 11083 0.05577291175723076
67 11083 0.12536118924617767
68 11083 0.09540962427854538
69 11083 0.09935356676578522
70 11083 0.06398393958806992
71 11083 0.02245311252772808
72 11083 0.02090287208557129
73 11083 0.02878558821976185
74 11083 0.004478514194488525
75 11083 0.006366848945617676
76 11083 0.005760125815868378
77 11083 0.019217362627387047
78 11083 0.011721888557076454
79 11083 0.12847955524921417
80 11083 0.016333993524312973
81 11083 0.0
82 11083 0.0
83 11083 0.006537000648677349
84 11083 0.04193802922964096
85 11083 0.17392337322235107
86 11083 0.0
87 11083 0.03893482685089111
88 11083 0.0202958881855011
89 11083 0.0
90 11083 0.049838680773973465
91 11083 0.04115733504295349
92 11083 0.08207815140485764
93 11083 0.011371612548828125
94 11083 0.0036355257034301758
95 11083 0.0
96 11083 0.047186870127916336
97 11083 0.02743147686123848
98 11083 0.010704874992370605
99 11083 0.0
100 11083 0.0
101 11083 0.008591234683990479
102 11083 0.029942499473690987
103 11083 0.015260772779583931
104 11083 0.02143990807235241
105 11083 0.03275132179260254
106 11083 0.0
107 11083 0.005779969971626997
108 11083 0.0
109 11083 0.021298041567206383
110 11083 0.021216057240962982
train - Global loss: 0.026939    Embedding norm: 1.0000   Triplets (all/active): 99.8/384.0
Pos dist (min/mean/max): 0.4073/0.7068/0.9308   Neg dist (min/mean/max): 1.1404/1.4109/1.6400
0 445 0.0
1 445 0.0
2 445 0.0
3 445 0.0
4 445 0.0
val - Global loss: 0.000000    Embedding norm: 1.0000   Triplets (all/active): 89.0/0.0
Pos dist (min/mean/max): 0.1611/0.2932/0.4724   Neg dist (min/mean/max): 1.1613/1.4150/1.6239
Training completed.
  0%|                                                   | 0/24 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 502, in do_train
    global_stats = evaluator_test_set.evaluate(model)
  File "/code/RLoc/eval/evaluate.py", line 1469, in evaluate
    query_embeddings, map_embeddings, query_positions, map_positions = self.compute_embeddings(model)
  File "/code/RLoc/eval/evaluate.py", line 1498, in compute_embeddings
    for query, maps, query_pos, map_pos in tqdm.tqdm(self.test_loader):
ValueError: not enough values to unpack (expected 4, got 2)
