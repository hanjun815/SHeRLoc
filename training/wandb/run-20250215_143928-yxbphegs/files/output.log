  0%|                                                                     | 0/120 [00:00<?, ?it/s]
0 25113 52.59347915649414
1 25113 47.860843658447266
2 25113 49.7158317565918
3 25113 39.3931884765625
4 25113 42.7987174987793
5 25113 25.883134841918945
6 25113 34.53313446044922
7 25113 18.226173400878906
8 25113 17.001201629638672
9 25113 35.80884552001953
10 25113 23.685016632080078
11 25113 19.107248306274414
12 25113 17.26804542541504
13 25113 20.881528854370117
14 25113 14.884795188903809
15 25113 11.357246398925781
16 25113 13.078252792358398
17 25113 14.890340805053711
18 25113 12.088618278503418
19 25113 8.434206008911133
20 25113 8.323531150817871
21 25113 4.722306251525879
22 25113 7.539458274841309
23 25113 5.757041931152344
24 25113 6.288193225860596
25 25113 7.807414531707764
26 25113 6.406967639923096
27 25113 5.935815334320068
28 25113 4.8246026039123535
29 25113 5.284249782562256
30 25113 3.7402422428131104
31 25113 5.302177906036377
32 25113 3.2167086601257324
33 25113 4.4377899169921875
34 25113 4.148801326751709
35 25113 4.734172821044922
36 25113 4.258554935455322
37 25113 7.88862943649292
38 25113 5.395895004272461
39 25113 3.490049123764038
40 25113 4.20938777923584
41 25113 3.3274309635162354
42 25113 2.879075527191162
43 25113 3.3098084926605225
44 25113 1.919464111328125
45 25113 5.236256122589111
46 25113 2.274735927581787
47 25113 2.0263590812683105
48 25113 2.626084566116333
49 25113 4.608947277069092
50 25113 3.3749656677246094
51 25113 5.790550708770752
52 25113 4.942203521728516
53 25113 2.4093587398529053
54 25113 2.5797078609466553
55 25113 3.3625988960266113
56 25113 2.2605879306793213
57 25113 2.791341781616211
58 25113 1.7057615518569946
59 25113 3.99867844581604
60 25113 3.003872871398926
61 25113 2.8094873428344727
62 25113 2.944401979446411
63 25113 3.2903032302856445
64 25113 3.4032599925994873
65 25113 5.735275745391846
66 25113 2.3680834770202637
67 25113 2.4244301319122314
68 25113 3.4476184844970703
69 25113 3.106360912322998
70 25113 4.363226890563965
71 25113 3.6417789459228516
72 25113 4.5730204582214355
73 25113 4.241415500640869
74 25113 2.945977210998535
75 25113 2.793832540512085
76 25113 2.525947332382202
77 25113 2.7764687538146973
78 25113 2.5836641788482666
79 25113 2.3398423194885254
80 25113 7.081737518310547
81 25113 2.4605069160461426
82 25113 2.2192749977111816
83 25113 3.569042921066284
train - Global loss: 9.229459    Embedding norm: 168.8611   Triplets (all/active): 299.0/74871.1
Pos dist (min/mean/max): 16.7113/28.6275/47.8150   Neg dist (min/mean/max): 15.0136/27.6910/61.0648
0 1011 7.456179141998291
1 1011 9.59302043914795
2 1011 7.747776508331299
3 1011 14.639519691467285
val - Global loss: 9.859124    Embedding norm: 150.8165   Triplets (all/active): 252.8/64017.5
Pos dist (min/mean/max): 17.5573/29.6293/45.1265   Neg dist (min/mean/max): 16.1800/27.2217/43.6283
0 25113 2.338259696960449
1 25113 2.218956470489502
2 25113 2.8032689094543457
3 25113 2.80956768989563
4 25113 2.3599743843078613
5 25113 2.734646797180176
6 25113 2.5902318954467773
7 25113 3.2464468479156494
8 25113 2.3275411128997803
9 25113 3.2857956886291504
10 25113 2.429316520690918
11 25113 2.0284621715545654
12 25113 2.1052660942077637
13 25113 2.2385146617889404
14 25113 2.347902774810791
15 25113 2.9093682765960693
16 25113 1.4935989379882812
17 25113 1.9642386436462402
18 25113 2.109337329864502
19 25113 2.5296437740325928
20 25113 1.901670217514038
21 25113 2.082853078842163
22 25113 2.4529924392700195
23 25113 2.1191675662994385
24 25113 2.752277135848999
25 25113 2.788844347000122
26 25113 2.2034192085266113
27 25113 2.3101816177368164
28 25113 1.8637975454330444
29 25113 1.9992612600326538
30 25113 2.042013168334961
31 25113 2.338320732116699
32 25113 1.3186317682266235
33 25113 2.290586233139038
34 25113 2.0263020992279053
35 25113 2.2417330741882324
36 25113 2.216010093688965
37 25113 3.080057382583618
38 25113 2.62850022315979
39 25113 1.6142467260360718
40 25113 2.028517484664917
41 25113 1.8622304201126099
42 25113 1.6753722429275513
43 25113 1.8073559999465942
44 25113 1.1613261699676514
45 25113 2.4250426292419434
46 25113 1.3148934841156006
47 25113 1.1489653587341309
48 25113 1.7144323587417603
49 25113 2.9930989742279053
50 25113 2.3448760509490967
51 25113 2.789954423904419
52 25113 2.8391001224517822
53 25113 1.3873249292373657
54 25113 1.5707027912139893
55 25113 2.248897075653076
56 25113 1.2910573482513428
57 25113 1.5057892799377441
58 25113 0.9113307595252991
59 25113 2.452763557434082
60 25113 1.947160243988037
61 25113 1.568211555480957
62 25113 1.4512630701065063
63 25113 2.117079257965088
64 25113 1.474632740020752
65 25113 3.380218744277954
66 25113 1.4433619976043701
67 25113 1.2162060737609863
68 25113 2.029924154281616
69 25113 1.7614682912826538
70 25113 2.218125104904175
71 25113 2.299715518951416
72 25113 2.891282796859741
73 25113 2.3659121990203857
74 25113 1.7808233499526978
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 408, in do_train
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.9/site-packages/torch/cuda/memory.py", line 121, in empty_cache
    torch._C._cuda_emptyCache()
KeyboardInterrupt
