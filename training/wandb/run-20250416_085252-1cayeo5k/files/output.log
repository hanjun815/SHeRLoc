  0%|                                                    | 0/80 [00:00<?, ?it/s]
0 25113 0.5138773918151855
1 25113 0.5623946785926819
2 25113 0.5768094658851624
3 25113 0.5035771131515503
4 25113 0.45482343435287476
5 25113 0.5666595697402954
6 25113 0.5493806004524231
7 25113 0.43138644099235535
8 25113 0.43167704343795776
9 25113 0.5016979575157166
10 25113 0.4401068091392517
11 25113 0.3788762390613556
12 25113 0.4504719376564026
13 25113 0.3863142132759094
14 25113 0.482499897480011
15 25113 0.47807127237319946
16 25113 0.4545416235923767
17 25113 0.5974269509315491
18 25113 0.43212100863456726
19 25113 0.4716801941394806
20 25113 0.6443161368370056
21 25113 0.5301544666290283
22 25113 0.36678531765937805
23 25113 0.39128607511520386
24 25113 0.3219042122364044
25 25113 nan
26 25113 nan
27 25113 nan
28 25113 nan
29 25113 nan
30 25113 nan
31 25113 nan
32 25113 nan
33 25113 nan
34 25113 nan
35 25113 nan
36 25113 nan
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 407, in do_train
    loss.backward()
  File "/usr/local/lib/python3.9/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
