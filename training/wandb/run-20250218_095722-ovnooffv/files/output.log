  0%|                                                           | 0/80 [00:00<?, ?it/s]
0 25113 0.39019426703453064
1 25113 0.33172905445098877
2 25113 0.3337775468826294
3 25113 0.32788777351379395
4 25113 0.32765042781829834
5 25113 0.3203789293766022
6 25113 0.32285332679748535
7 25113 0.32266750931739807
8 25113 0.32079243659973145
9 25113 0.31612420082092285
10 25113 0.3165331482887268
11 25113 0.3112342357635498
12 25113 0.3094119429588318
13 25113 0.3109360933303833
14 25113 0.31268244981765747
15 25113 0.310893714427948
16 25113 0.3109718859195709
17 25113 0.30961278080940247
18 25113 0.30777379870414734
19 25113 0.31442806124687195
20 25113 0.3098364770412445
21 25113 0.3054843544960022
22 25113 0.30759570002555847
23 25113 0.30859139561653137
24 25113 0.31149446964263916
25 25113 0.305838942527771
26 25113 0.3073177933692932
27 25113 0.30886125564575195
28 25113 0.3076587915420532
29 25113 0.3051099181175232
30 25113 0.30406996607780457
31 25113 0.30920976400375366
32 25113 0.30626556277275085
33 25113 0.305740624666214
34 25113 0.31139153242111206
35 25113 0.30443570017814636
36 25113 0.30318015813827515
37 25113 0.3005497455596924
38 25113 0.30422356724739075
39 25113 0.3024269938468933
40 25113 0.30384567379951477
41 25113 0.30178403854370117
42 25113 0.29956313967704773
43 25113 0.30353569984436035
44 25113 0.3046277165412903
45 25113 0.30147695541381836
46 25113 0.3004031777381897
47 25113 0.3070145547389984
48 25113 0.29718539118766785
49 25113 0.3002130389213562
50 25113 0.300477534532547
51 25113 0.2968822121620178
52 25113 0.2984151244163513
53 25113 0.29649806022644043
54 25113 0.2906271517276764
55 25113 0.2997497022151947
56 25113 0.3041769862174988
57 25113 0.2967316806316376
58 25113 0.2918342351913452
59 25113 0.29835715889930725
60 25113 0.29205042123794556
61 25113 0.2961478531360626
62 25113 0.30031445622444153
63 25113 0.2986432611942291
64 25113 0.3001171946525574
65 25113 0.2791301906108856
66 25113 0.28229063749313354
67 25113 0.2916412949562073
68 25113 0.2822719216346741
69 25113 0.2845933735370636
70 25113 0.2767244577407837
71 25113 0.28837698698043823
72 25113 0.2854466438293457
73 25113 0.27821487188339233
74 25113 0.31191304326057434
75 25113 0.26616665720939636
76 25113 0.2916543781757355
77 25113 0.27759766578674316
78 25113 0.2847822308540344
79 25113 0.24751615524291992
80 25113 0.24803709983825684
81 25113 0.28094497323036194
82 25113 0.3088196814060211
83 25113 0.2660016417503357
84 25113 0.30196061730384827
85 25113 0.273716539144516
86 25113 0.21451815962791443
87 25113 0.23046068847179413
88 25113 0.24560390412807465
89 25113 0.22729875147342682
90 25113 0.2583576440811157
91 25113 0.2642609179019928
92 25113 0.2594228684902191
93 25113 0.26483526825904846
94 25113 0.24015416204929352
95 25113 0.184517502784729
96 25113 0.20912562310695648
97 25113 0.2364836037158966
98 25113 0.24229377508163452
99 25113 0.30531349778175354
100 25113 0.25503185391426086
101 25113 0.35027220845222473
102 25113 0.33405977487564087
103 25113 0.23605310916900635
104 25113 0.3248937726020813
105 25113 0.2864806652069092
106 25113 0.20443694293498993
107 25113 0.2671630084514618
108 25113 0.21888406574726105
109 25113 0.2481987476348877
110 25113 0.21422933042049408
111 25113 0.22186429798603058
112 25113 0.300063818693161
113 25113 0.3155364692211151
114 25113 0.24129025638103485
115 25113 0.22593453526496887
116 25113 0.30831798911094666
117 25113 0.25598660111427307
118 25113 0.15939496457576752
119 25113 0.16533316671848297
120 25113 0.2888355851173401
121 25113 0.19218872487545013
122 25113 0.24077725410461426
123 25113 0.19301697611808777
124 25113 0.24772387742996216
125 25113 0.2475331872701645
train - Global loss: 0.284702    Embedding norm: 1.0000   Triplets (all/active): 199.3/39600.9
Pos dist (min/mean/max): 0.1754/0.2463/0.3806   Neg dist (min/mean/max): 0.1941/0.3539/0.5636
0 1011 0.3738040328025818
1 1011 0.3019554913043976
2 1011 0.522396981716156
3 1011 0.3236815631389618
4 1011 0.5298371315002441
5 1011 0.37085455656051636
val - Global loss: 0.403755    Embedding norm: 1.0000   Triplets (all/active): 168.5/33275.3
Pos dist (min/mean/max): 0.0982/0.3041/0.7239   Neg dist (min/mean/max): 0.0725/0.4565/1.1691
0 25113 0.21911415457725525
1 25113 0.1104297935962677
2 25113 0.16586315631866455
3 25113 0.15739840269088745
4 25113 0.1901118904352188
5 25113 0.1469637006521225
6 25113 0.30150431394577026
7 25113 0.09485980123281479
8 25113 0.19794565439224243
9 25113 0.28281843662261963
10 25113 0.09771764278411865
11 25113 0.3014398217201233
12 25113 0.258994460105896
13 25113 0.2424459308385849
14 25113 0.07339844107627869
15 25113 0.09759637713432312
16 25113 0.3265773057937622
17 25113 0.239981546998024
18 25113 0.2845907211303711
19 25113 0.29233723878860474
20 25113 0.35785919427871704
21 25113 0.24861811101436615
22 25113 0.2457551807165146
23 25113 0.23175540566444397
24 25113 0.17475172877311707
25 25113 0.0660129114985466
26 25113 0.10340914130210876
27 25113 0.20549622178077698
28 25113 0.0987289696931839
29 25113 0.15679165720939636
30 25113 0.17003826797008514
31 25113 0.03912597894668579
32 25113 0.16311118006706238
33 25113 0.39639508724212646
34 25113 0.14928068220615387
35 25113 0.1863943636417389
36 25113 0.39247360825538635
37 25113 0.11725763231515884
38 25113 0.10987947136163712
39 25113 0.06426194310188293
40 25113 0.38542094826698303
41 25113 0.25882604718208313
42 25113 0.03912726789712906
43 25113 0.22369484603405
44 25113 0.44422221183776855
45 25113 0.1405051201581955
46 25113 0.17032700777053833
47 25113 0.28916043043136597
48 25113 0.017894377931952477
49 25113 0.049267951399087906
50 25113 0.29106026887893677
51 25113 0.02828815020620823
52 25113 0.07562711089849472
53 25113 0.2805590033531189
54 25113 0.04777628928422928
55 25113 0.3924863040447235
56 25113 0.23072336614131927
57 25113 0.373018354177475
58 25113 0.1779283732175827
59 25113 0.1410563737154007
60 25113 0.2616317570209503
61 25113 0.3648185729980469
62 25113 0.2945215404033661
63 25113 0.44493773579597473
64 25113 0.12070311605930328
65 25113 0.03878319635987282
66 25113 0.03714372590184212
67 25113 0.7623229026794434
68 25113 0.04957477003335953
69 25113 0.25728580355644226
70 25113 0.0
71 25113 0.5832457542419434
72 25113 0.2644805610179901
73 25113 0.06176374852657318
74 25113 0.24329626560211182
75 25113 0.23701682686805725
76 25113 0.34389129281044006
77 25113 0.0
78 25113 0.28619384765625
79 25113 0.12228372693061829
80 25113 0.21794383227825165
81 25113 0.2044433206319809
82 25113 0.3302707374095917
83 25113 0.06885207444429398
84 25113 0.1324968934059143
85 25113 0.06307746469974518
86 25113 0.04648372903466225
87 25113 0.0
88 25113 0.47217097878456116
89 25113 0.05865863338112831
90 25113 0.1318969577550888
91 25113 0.12793971598148346
92 25113 0.04879016801714897
93 25113 0.10847581923007965
94 25113 0.02192312479019165
95 25113 0.1111174151301384
96 25113 0.023316454142332077
97 25113 0.28122320771217346
98 25113 0.03619534149765968
99 25113 0.48516610264778137
100 25113 0.7331130504608154
101 25113 0.10324208438396454
102 25113 0.4164619743824005
103 25113 0.039836157113313675
104 25113 0.0
105 25113 0.3307165801525116
106 25113 0.08160267025232315
107 25113 0.32890963554382324
108 25113 0.0
109 25113 0.1979576051235199
110 25113 0.14320418238639832
111 25113 0.3732497990131378
112 25113 0.15896621346473694
113 25113 0.29825788736343384
114 25113 0.09434070438146591
115 25113 0.05035370960831642
116 25113 0.1989896148443222
117 25113 0.20058801770210266
118 25113 0.015212774276733398
119 25113 0.0
120 25113 0.61380535364151
121 25113 0.0021230578422546387
122 25113 0.4152325689792633
123 25113 0.24469569325447083
124 25113 0.08343207091093063
125 25113 0.5142180323600769
train - Global loss: 0.199994    Embedding norm: 1.0000   Triplets (all/active): 199.3/18964.4
Pos dist (min/mean/max): 0.3085/0.5196/0.8759   Neg dist (min/mean/max): 0.5478/1.0749/1.4918
0 1011 0.3844221830368042
1 1011 0.2990121841430664
2 1011 0.4529742896556854
3 1011 0.32506752014160156
4 1011 0.5322389006614685
5 1011 0.28364434838294983
val - Global loss: 0.379560    Embedding norm: 1.0000   Triplets (all/active): 168.5/32617.0
Pos dist (min/mean/max): 0.1841/0.4675/0.8889   Neg dist (min/mean/max): 0.1615/0.7250/1.3734
0 25113 0.03765473887324333
1 25113 0.0
2 25113 0.05902503803372383
3 25113 0.0
4 25113 0.08116985857486725
5 25113 0.0
6 25113 0.6836439371109009
7 25113 0.0
8 25113 0.7256117463111877
9 25113 0.12415637075901031
10 25113 0.0
11 25113 0.2927853465080261
12 25113 0.32753708958625793
13 25113 0.2656099200248718
14 25113 0.04063338413834572
15 25113 0.0
16 25113 0.19540859758853912
17 25113 0.2028828114271164
18 25113 0.5147809982299805
19 25113 0.19776424765586853
20 25113 0.44767552614212036
21 25113 0.06664282083511353
22 25113 0.24492663145065308
23 25113 0.16620899736881256
24 25113 0.07636453211307526
25 25113 0.0
26 25113 0.009026288986206055
27 25113 0.4164483845233917
28 25113 0.0
29 25113 0.3440549373626709
30 25113 0.2996034324169159
31 25113 0.01578236185014248
32 25113 0.3344464600086212
33 25113 0.12238636612892151
34 25113 0.04244619235396385
35 25113 0.0799727514386177
36 25113 0.22599941492080688
37 25113 0.061255380511283875
38 25113 0.0
39 25113 0.0
40 25113 0.26210764050483704
41 25113 0.08638987690210342
42 25113 0.05315341800451279
43 25113 0.14745494723320007
44 25113 0.38070711493492126
45 25113 0.0063081225380301476
46 25113 0.05417279526591301
47 25113 0.44224536418914795
48 25113 0.03389803692698479
49 25113 0.0
50 25113 0.23980000615119934
51 25113 0.0
52 25113 0.0
53 25113 0.11496200412511826
54 25113 0.06349936127662659
55 25113 0.38405176997184753
56 25113 0.08418045192956924
57 25113 0.14941926300525665
58 25113 0.1848970204591751
59 25113 0.12162832915782928
60 25113 0.13931965827941895
61 25113 0.5537890791893005
62 25113 0.08527223765850067
63 25113 0.0
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.4838697612285614
68 25113 0.02502153255045414
69 25113 0.14032527804374695
70 25113 0.0
71 25113 0.15659017860889435
72 25113 0.0681246891617775
73 25113 0.0
74 25113 0.19615304470062256
75 25113 0.1049661710858345
76 25113 0.2053391933441162
77 25113 0.04639226943254471
78 25113 0.10643680393695831
79 25113 0.011490300297737122
80 25113 0.04352162405848503
81 25113 0.04774883762001991
82 25113 0.3909150958061218
83 25113 0.03473135083913803
84 25113 0.0853075459599495
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.20314206182956696
89 25113 0.0
90 25113 0.04915865138173103
91 25113 0.032837267965078354
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.026119019836187363
97 25113 0.10669849067926407
98 25113 0.0362439788877964
99 25113 0.1054396778345108
100 25113 0.098469577729702
101 25113 0.06074947491288185
102 25113 0.08308791369199753
103 25113 0.0
104 25113 0.0
105 25113 0.09945398569107056
106 25113 0.0
107 25113 0.07252854853868484
108 25113 0.0
109 25113 0.09994783997535706
110 25113 0.0
111 25113 0.003645462216809392
112 25113 0.0
113 25113 0.10742877423763275
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.01340733002871275
120 25113 0.0649947077035904
121 25113 0.0
122 25113 0.08148060739040375
123 25113 0.0
124 25113 0.0
125 25113 0.0
train - Global loss: 0.109372    Embedding norm: 1.0000   Triplets (all/active): 199.3/6080.4
Pos dist (min/mean/max): 0.2994/0.4707/0.7616   Neg dist (min/mean/max): 0.7925/1.2672/1.6041
0 1011 0.4061223566532135
1 1011 0.36550113558769226
2 1011 0.5056353211402893
3 1011 0.3716343343257904
4 1011 0.6025897264480591
5 1011 0.3419473171234131
val - Global loss: 0.432238    Embedding norm: 1.0000   Triplets (all/active): 168.5/33168.7
Pos dist (min/mean/max): 0.1615/0.4488/0.8472   Neg dist (min/mean/max): 0.1414/0.6028/1.3547
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.046759530901908875
4 25113 0.0
5 25113 0.0
6 25113 0.055016059428453445
7 25113 0.0
8 25113 0.03540824353694916
9 25113 0.060572300106287
10 25113 0.0
11 25113 0.0
12 25113 0.32287368178367615
13 25113 0.19726572930812836
14 25113 0.0
15 25113 0.015910936519503593
16 25113 0.03811284899711609
17 25113 0.04294315353035927
18 25113 0.0
19 25113 0.08151060342788696
20 25113 0.4352323114871979
21 25113 0.0
22 25113 0.0
23 25113 0.0
24 25113 0.006801247596740723
25 25113 0.0
26 25113 0.0
27 25113 0.11692791432142258
28 25113 0.0
29 25113 0.01512650866061449
30 25113 0.013203786686062813
31 25113 0.0
32 25113 0.06163942441344261
33 25113 0.0
34 25113 0.019415082409977913
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.560845136642456
41 25113 0.21938593685626984
42 25113 0.0
43 25113 0.08693519979715347
44 25113 0.44728806614875793
45 25113 0.071427121758461
46 25113 0.05983436480164528
47 25113 0.1478699892759323
48 25113 0.03497669845819473
49 25113 0.04285036027431488
50 25113 0.18846681714057922
51 25113 0.14798450469970703
52 25113 0.14421109855175018
53 25113 0.17255574464797974
54 25113 0.10716493427753448
55 25113 0.1421024352312088
56 25113 0.12088458985090256
57 25113 0.16581900417804718
58 25113 0.07595890760421753
59 25113 0.041361309587955475
60 25113 0.10289733856916428
61 25113 0.11530797928571701
62 25113 0.03420913591980934
63 25113 0.0
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.30478689074516296
68 25113 0.0
69 25113 0.09867630153894424
70 25113 0.0
71 25113 0.06680811196565628
72 25113 0.0
73 25113 0.0
74 25113 0.013483531773090363
75 25113 0.06515173614025116
76 25113 0.06502865999937057
77 25113 0.0
78 25113 0.1244090124964714
79 25113 0.0
80 25113 0.0
81 25113 0.06222754716873169
82 25113 0.34659406542778015
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.006248543970286846
89 25113 0.0
90 25113 0.06254105269908905
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.3233952820301056
98 25113 0.0
99 25113 0.1739674210548401
100 25113 0.0
101 25113 0.0020582377910614014
102 25113 0.08295539766550064
103 25113 0.02806457318365574
104 25113 0.054009970277547836
105 25113 0.08248918503522873
106 25113 0.044533871114254
107 25113 0.021022530272603035
108 25113 0.0
109 25113 0.0651978999376297
110 25113 0.023093653842806816
111 25113 0.0
112 25113 0.0
113 25113 0.0862109586596489
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.08746865391731262
121 25113 0.0
122 25113 0.0
123 25113 0.013769852928817272
124 25113 0.0
125 25113 0.0
train - Global loss: 0.056343    Embedding norm: 1.0000   Triplets (all/active): 199.3/6103.3
Pos dist (min/mean/max): 0.2535/0.3855/0.5985   Neg dist (min/mean/max): 0.8631/1.3143/1.6414
0 1011 0.3704075813293457
1 1011 0.33451220393180847
2 1011 0.38554224371910095
3 1011 0.33641645312309265
4 1011 0.4808879792690277
5 1011 0.32391923666000366
val - Global loss: 0.371948    Embedding norm: 1.0000   Triplets (all/active): 168.5/33139.2
Pos dist (min/mean/max): 0.1816/0.4007/0.7826   Neg dist (min/mean/max): 0.1622/0.5962/1.2539
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.028498083353042603
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.04567830637097359
17 25113 0.0
18 25113 0.0
19 25113 0.07973816990852356
20 25113 0.44631052017211914
21 25113 0.0
22 25113 0.0
23 25113 0.01545694749802351
24 25113 0.019962430000305176
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.10355477780103683
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.30531546473503113
45 25113 0.0
46 25113 0.057204362004995346
47 25113 0.11117919534444809
48 25113 0.0
49 25113 0.0
50 25113 0.10087620466947556
51 25113 0.0
52 25113 0.08807593584060669
53 25113 0.02978103794157505
54 25113 0.0
55 25113 0.0
56 25113 0.03562763333320618
57 25113 0.042391322553157806
58 25113 0.0
59 25113 0.0
60 25113 0.11831516772508621
61 25113 0.4592171609401703
62 25113 0.0
63 25113 0.0
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.0
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.012989806942641735
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
99 25113 0.0
100 25113 0.0
101 25113 0.0
102 25113 0.0
103 25113 0.0
104 25113 0.0
105 25113 0.07655225694179535
106 25113 0.0
107 25113 0.0
108 25113 0.0
109 25113 0.02796109952032566
110 25113 0.03515888750553131
111 25113 0.02414688840508461
112 25113 0.0
113 25113 0.0
114 25113 0.0
115 25113 0.0
116 25113 0.0
117 25113 0.0
118 25113 0.0
119 25113 0.0
120 25113 0.0
121 25113 0.0
122 25113 0.05031762272119522
123 25113 0.0
124 25113 0.0
125 25113 0.0
train - Global loss: 0.018368    Embedding norm: 1.0000   Triplets (all/active): 199.3/962.1
Pos dist (min/mean/max): 0.2276/0.3293/0.4985   Neg dist (min/mean/max): 1.0269/1.5005/1.7897
0 1011 0.45862409472465515
1 1011 0.3510911464691162
2 1011 0.6030066013336182
3 1011 0.4137217700481415
4 1011 0.6538758277893066
5 1011 0.3142145276069641
val - Global loss: 0.465756    Embedding norm: 1.0000   Triplets (all/active): 168.5/32979.5
Pos dist (min/mean/max): 0.1662/0.4733/1.0001   Neg dist (min/mean/max): 0.1331/0.6542/1.4811
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.047140270471572876
6 25113 0.022003360092639923
7 25113 0.0
8 25113 0.0
9 25113 0.04008111730217934
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.16167181730270386
17 25113 0.17616857588291168
18 25113 0.0
19 25113 0.0
20 25113 0.5409878492355347
21 25113 0.0
22 25113 0.007115811109542847
23 25113 0.09043089300394058
24 25113 0.03975847363471985
25 25113 0.0
26 25113 0.0147178303450346
27 25113 0.05176309868693352
28 25113 0.0
29 25113 0.005277550313621759
30 25113 0.010265226475894451
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.0
38 25113 0.0
39 25113 0.0
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.21763260662555695
45 25113 0.0
46 25113 0.0
47 25113 0.0917077511548996
48 25113 0.0
49 25113 0.0
50 25113 0.07484164088964462
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.015344681218266487
56 25113 0.0
57 25113 0.03404957801103592
58 25113 0.0
59 25113 0.008141934871673584
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.0
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.0
71 25113 0.03705035522580147
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.02849080227315426
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.022871943190693855
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 391, in do_train
    outputs = model(inputs, n_pos, n_neg)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 78, in parallel_apply
    thread.join()
  File "/usr/local/lib/python3.9/threading.py", line 1053, in join
    self._wait_for_tstate_lock()
  File "/usr/local/lib/python3.9/threading.py", line 1073, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt
