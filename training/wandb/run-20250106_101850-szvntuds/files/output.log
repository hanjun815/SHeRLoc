  5%|██                                      | 6/120 [14:15<4:16:26, 134.97s/it]
train - Global loss: 0.276142    Embedding norm: 2.6996   Triplets (all/active): 16.1/9.7
Pos dist (min/mean/max): 0.0000/7.2570/17.3420   Neg dist (min/mean/max): 10.0354/10.2156/10.8438
val - Global loss: 0.171997    Embedding norm: 0.9283   Triplets (all/active): 136.2/31.0
Pos dist (min/mean/max): 0.0000/8.2009/18.7003   Neg dist (min/mean/max): 9.4001/9.4981/9.9695
=> Batch size increased from: 32 to 44
train - Global loss: 0.206495    Embedding norm: 0.9133   Triplets (all/active): 22.3/13.1
Pos dist (min/mean/max): 0.0000/7.9803/18.9452   Neg dist (min/mean/max): 11.0378/11.1347/11.6962
val - Global loss: 0.175961    Embedding norm: 0.9399   Triplets (all/active): 136.2/46.2
Pos dist (min/mean/max): 0.0000/8.2209/18.7381   Neg dist (min/mean/max): 9.4337/9.5113/9.9572
=> Batch size increased from: 44 to 61
train - Global loss: 0.200516    Embedding norm: 0.7619   Triplets (all/active): 31.5/14.5
Pos dist (min/mean/max): 0.0000/8.0900/19.2980   Neg dist (min/mean/max): 10.7593/10.8335/11.3516
val - Global loss: 0.222222    Embedding norm: 0.6750   Triplets (all/active): 136.2/16.6
Pos dist (min/mean/max): 0.0000/8.3116/18.8990   Neg dist (min/mean/max): 9.6720/9.7235/10.0623
=> Batch size increased from: 61 to 85
train - Global loss: 0.197598    Embedding norm: 0.6906   Triplets (all/active): 43.9/17.0
Pos dist (min/mean/max): 0.0000/8.1714/19.5458   Neg dist (min/mean/max): 10.5459/10.6102/11.0743
val - Global loss: 0.196414    Embedding norm: 0.6963   Triplets (all/active): 136.0/30.0
Pos dist (min/mean/max): 0.0000/8.3341/18.9903   Neg dist (min/mean/max): 9.5663/9.6131/10.0477
=> Batch size increased from: 85 to 118
train - Global loss: 0.201851    Embedding norm: 0.6777   Triplets (all/active): 60.7/20.4
Pos dist (min/mean/max): 0.0000/8.2812/19.8110   Neg dist (min/mean/max): 10.2380/10.2968/10.7193
val - Global loss: 0.199868    Embedding norm: 0.6210   Triplets (all/active): 136.5/21.0
Pos dist (min/mean/max): 0.0000/8.3515/19.0004   Neg dist (min/mean/max): 9.7138/9.7615/10.0724
=> Batch size increased from: 118 to 165
train - Global loss: 0.192843    Embedding norm: 0.6955   Triplets (all/active): 86.4/27.9
Pos dist (min/mean/max): 0.0000/8.3954/19.9095   Neg dist (min/mean/max): 9.9178/9.9712/10.3653
val - Global loss: 0.216241    Embedding norm: 0.7661   Triplets (all/active): 136.0/56.1
Pos dist (min/mean/max): 0.0000/8.2983/18.8972   Neg dist (min/mean/max): 9.5734/9.6160/9.9769
=> Batch size increased from: 165 to 230
train - Global loss: 0.201438    Embedding norm: 0.8275   Triplets (all/active): 121.7/28.9
Pos dist (min/mean/max): 0.0000/8.5313/20.0675   Neg dist (min/mean/max): 9.4737/9.5308/9.9252
val - Global loss: 0.149627    Embedding norm: 0.6708   Triplets (all/active): 136.0/59.5
Pos dist (min/mean/max): 0.0000/8.3934/19.0730   Neg dist (min/mean/max): 9.7437/9.8104/10.1023
=> Batch size increased from: 230 to 256
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 375, in do_train
    pos_neg_embeddings = common_model(batch)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/code/RLoc/models/radar/radar_net.py", line 16, in forward
    x = self.fe_net(x)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/code/RLoc/models/radar/cylindrical_resnet_FPN.py", line 89, in forward
    x = self.blocks[str(i)](x)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/code/RLoc/models/radar/cylindrical_resnet.py", line 73, in forward
    identity = self.downsample(x)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 168, in forward
    return F.batch_norm(
  File "/usr/local/lib/python3.9/site-packages/torch/nn/functional.py", line 2438, in batch_norm
    return torch.batch_norm(
RuntimeError: CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 10.75 GiB total capacity; 9.47 GiB already allocated; 7.88 MiB free; 9.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
