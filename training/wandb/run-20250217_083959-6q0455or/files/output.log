  0%|                                                           | 0/80 [00:00<?, ?it/s]
0 25113 0.29088860750198364
1 25113 0.23444265127182007
2 25113 0.24184420704841614
3 25113 0.23903405666351318
4 25113 0.23127210140228271
5 25113 0.22920429706573486
6 25113 0.2257639318704605
7 25113 0.2232365608215332
8 25113 0.21661503612995148
9 25113 0.21522647142410278
10 25113 0.21614328026771545
11 25113 0.21904687583446503
12 25113 0.21507501602172852
13 25113 0.2165917158126831
14 25113 0.21786537766456604
15 25113 0.22003591060638428
16 25113 0.2149686962366104
17 25113 0.212305948138237
18 25113 0.2124345302581787
19 25113 0.21407920122146606
20 25113 0.21247345209121704
21 25113 0.21475349366664886
22 25113 0.21652403473854065
23 25113 0.21213756501674652
24 25113 0.2154940813779831
25 25113 0.21558743715286255
26 25113 0.21647530794143677
27 25113 0.21134303510189056
28 25113 0.2095671147108078
29 25113 0.20985329151153564
30 25113 0.20917212963104248
31 25113 0.2112853229045868
32 25113 0.2107621431350708
33 25113 0.21004028618335724
34 25113 0.21188923716545105
35 25113 0.2080879658460617
36 25113 0.2097853422164917
37 25113 0.21072018146514893
38 25113 0.21249184012413025
39 25113 0.20988976955413818
40 25113 0.20882919430732727
41 25113 0.20864684879779816
42 25113 0.20557746291160583
43 25113 0.20957572758197784
44 25113 0.20873671770095825
45 25113 0.20780712366104126
46 25113 0.2076754868030548
47 25113 0.20990025997161865
48 25113 0.20769143104553223
49 25113 0.20598842203617096
50 25113 0.20689450204372406
51 25113 0.20661406219005585
52 25113 0.2077406793832779
53 25113 0.2074241042137146
54 25113 0.20661234855651855
55 25113 0.208083838224411
56 25113 0.20640461146831512
57 25113 0.20588162541389465
58 25113 0.20402324199676514
59 25113 0.20394548773765564
60 25113 0.20683401823043823
61 25113 0.20546871423721313
62 25113 0.2042994499206543
63 25113 0.20609432458877563
64 25113 0.2075698971748352
65 25113 0.2043839395046234
66 25113 0.20173829793930054
67 25113 0.2046847939491272
68 25113 0.2037351280450821
69 25113 0.20522712171077728
70 25113 0.2043534368276596
71 25113 0.2059890329837799
72 25113 0.20459944009780884
73 25113 0.2078585922718048
74 25113 0.20468243956565857
75 25113 0.20713722705841064
76 25113 0.20751890540122986
77 25113 0.20452921092510223
78 25113 0.20791469514369965
79 25113 0.20631268620491028
80 25113 0.2077699899673462
81 25113 0.20497772097587585
82 25113 0.20613372325897217
83 25113 0.20459488034248352
84 25113 0.20852798223495483
85 25113 0.20513829588890076
86 25113 0.20819620788097382
87 25113 0.2053111046552658
88 25113 0.2073861062526703
89 25113 0.202138751745224
90 25113 0.203321635723114
91 25113 0.20597298443317413
92 25113 0.20319348573684692
93 25113 0.20206010341644287
94 25113 0.20471680164337158
95 25113 0.2039247453212738
96 25113 0.204463392496109
97 25113 0.20550870895385742
98 25113 0.20204100012779236
train - Global loss: 0.211058    Embedding norm: 1.0000   Triplets (all/active): 253.7/64880.3
Pos dist (min/mean/max): 0.1169/0.1471/0.1894   Neg dist (min/mean/max): 0.1145/0.1523/0.2155
0 1011 0.20762747526168823
1 1011 0.20615851879119873
2 1011 0.20686575770378113
3 1011 0.211195707321167
val - Global loss: 0.207962    Embedding norm: 1.0000   Triplets (all/active): 252.8/63914.2
Pos dist (min/mean/max): 0.0650/0.0875/0.1251   Neg dist (min/mean/max): 0.0661/0.0984/0.1732
0 25113 0.20155277848243713
1 25113 0.19840577244758606
2 25113 0.20014998316764832
3 25113 0.2012433260679245
4 25113 0.20407631993293762
5 25113 0.20094099640846252
6 25113 0.2024463713169098
7 25113 0.2022937685251236
8 25113 0.19908857345581055
9 25113 0.20264577865600586
10 25113 0.19776979088783264
11 25113 0.19923600554466248
12 25113 0.20176291465759277
13 25113 0.19711178541183472
14 25113 0.19905129075050354
15 25113 0.20420652627944946
16 25113 0.19834785163402557
17 25113 0.19982728362083435
18 25113 0.20006559789180756
19 25113 0.1954668015241623
20 25113 0.19511473178863525
21 25113 0.19986486434936523
22 25113 0.19577232003211975
23 25113 0.1968713104724884
24 25113 0.1970597356557846
25 25113 0.19788700342178345
26 25113 0.21300771832466125
27 25113 0.19782909750938416
28 25113 0.19602061808109283
29 25113 0.19676807522773743
30 25113 0.1938534677028656
31 25113 0.19865815341472626
32 25113 0.19231009483337402
33 25113 0.1959896683692932
34 25113 0.20216044783592224
35 25113 0.19692453742027283
36 25113 0.20023113489151
37 25113 0.19704663753509521
38 25113 0.19249866902828217
39 25113 0.20096132159233093
40 25113 0.1900099366903305
41 25113 0.19974644482135773
42 25113 0.19362282752990723
43 25113 0.19851917028427124
44 25113 0.19444139301776886
45 25113 0.18849623203277588
46 25113 0.1935671865940094
47 25113 0.1929320991039276
48 25113 0.19073417782783508
49 25113 0.1927993893623352
50 25113 0.19039286673069
51 25113 0.17779630422592163
52 25113 0.19280889630317688
53 25113 0.1852210909128189
54 25113 0.186658576130867
55 25113 0.1793750524520874
56 25113 0.19331957399845123
57 25113 0.1885175257921219
58 25113 0.18454128503799438
59 25113 0.1812441647052765
60 25113 0.1871594786643982
61 25113 0.19258546829223633
62 25113 0.17330262064933777
63 25113 0.17970728874206543
64 25113 0.20231033861637115
65 25113 0.1838310807943344
66 25113 0.17492222785949707
67 25113 0.15263354778289795
68 25113 0.17538143694400787
69 25113 0.16400408744812012
70 25113 0.1897323727607727
71 25113 0.18986111879348755
72 25113 0.18745696544647217
73 25113 0.20232799649238586
74 25113 0.1559242606163025
75 25113 0.18653357028961182
76 25113 0.1681169867515564
77 25113 0.19475451111793518
78 25113 0.17248231172561646
79 25113 0.1955164074897766
80 25113 0.20524650812149048
81 25113 0.1881994605064392
82 25113 0.19806507229804993
83 25113 0.17011669278144836
84 25113 0.1954953372478485
85 25113 0.20176957547664642
86 25113 0.17331981658935547
87 25113 0.17488493025302887
88 25113 0.18091875314712524
89 25113 0.17899945378303528
90 25113 0.17167869210243225
91 25113 0.2026461511850357
92 25113 0.13482126593589783
93 25113 0.14328204095363617
94 25113 0.14195704460144043
95 25113 0.18021699786186218
96 25113 0.14012587070465088
97 25113 0.19958540797233582
98 25113 0.15387777984142303
train - Global loss: 0.189101    Embedding norm: 1.0000   Triplets (all/active): 253.7/64867.1
Pos dist (min/mean/max): 0.1060/0.1443/0.2209   Neg dist (min/mean/max): 0.1181/0.2096/0.3530
0 1011 0.23474650084972382
1 1011 0.22417443990707397
2 1011 0.2604685127735138
3 1011 0.27957117557525635
val - Global loss: 0.249740    Embedding norm: 1.0000   Triplets (all/active): 252.8/63612.5
Pos dist (min/mean/max): 0.0965/0.2330/0.5457   Neg dist (min/mean/max): 0.0911/0.3222/0.7206
0 25113 0.146768718957901
1 25113 0.10133493691682816
2 25113 0.10587108880281448
3 25113 0.13782621920108795
4 25113 0.1500667780637741
5 25113 0.1184379830956459
6 25113 0.12301479279994965
7 25113 0.1904381662607193
8 25113 0.1630816012620926
9 25113 0.21259911358356476
10 25113 0.17392003536224365
11 25113 0.10411542654037476
12 25113 0.19152437150478363
13 25113 0.11153434962034225
14 25113 0.12848030030727386
15 25113 0.20274196565151215
16 25113 0.15261779725551605
17 25113 0.17953528463840485
18 25113 0.16761085391044617
19 25113 0.11397503316402435
20 25113 0.06939869374036789
21 25113 0.20560632646083832
22 25113 0.09608692675828934
23 25113 0.13166147470474243
24 25113 0.08446082472801208
25 25113 0.17584244906902313
26 25113 0.24120062589645386
27 25113 0.13694576919078827
28 25113 0.15651825070381165
29 25113 0.1661992073059082
30 25113 0.06040375307202339
31 25113 0.24140441417694092
32 25113 0.12675604224205017
33 25113 0.12235835939645767
34 25113 0.2689419984817505
35 25113 0.1819675713777542
36 25113 0.1454792022705078
37 25113 0.3030298054218292
38 25113 0.01741483435034752
39 25113 0.23003798723220825
40 25113 0.04717642813920975
41 25113 0.204263374209404
42 25113 0.1285162717103958
43 25113 0.12954926490783691
44 25113 0.10906542092561722
45 25113 0.09907340258359909
46 25113 0.20885077118873596
47 25113 0.16132837533950806
48 25113 0.10338203608989716
49 25113 0.07408276200294495
50 25113 0.06740649789571762
51 25113 0.04307973012328148
52 25113 0.3679496943950653
53 25113 0.06995166838169098
54 25113 0.2044215351343155
55 25113 0.0
56 25113 0.21105514466762543
57 25113 0.02893812209367752
58 25113 0.23074360191822052
59 25113 0.3791867792606354
60 25113 0.03682279959321022
61 25113 0.2894780933856964
62 25113 0.047914061695337296
63 25113 0.07493234425783157
64 25113 0.2975712716579437
65 25113 0.22591035068035126
66 25113 0.04379121586680412
67 25113 0.020843859761953354
68 25113 0.29137665033340454
69 25113 0.01860804669559002
70 25113 0.4335806965827942
71 25113 0.14747367799282074
72 25113 0.06889449805021286
73 25113 0.09593828022480011
74 25113 0.04795088991522789
75 25113 0.38424646854400635
76 25113 0.07046885788440704
77 25113 0.2226213812828064
78 25113 0.3937302529811859
79 25113 0.16205070912837982
80 25113 0.15521755814552307
81 25113 0.0
82 25113 0.25898224115371704
83 25113 0.08415195345878601
84 25113 0.13851326704025269
85 25113 0.2208545207977295
86 25113 0.11784452199935913
87 25113 0.09297686070203781
88 25113 0.32634246349334717
89 25113 0.11868199706077576
90 25113 0.025589393451809883
91 25113 0.14463280141353607
92 25113 0.024685990065336227
93 25113 0.03683925420045853
94 25113 0.03695380687713623
95 25113 0.077238529920578
96 25113 0.0
97 25113 0.6675844192504883
98 25113 2.0697712898254395e-05
train - Global loss: 0.150571    Embedding norm: 1.0000   Triplets (all/active): 253.7/32219.7
Pos dist (min/mean/max): 0.3165/0.5054/0.8334   Neg dist (min/mean/max): 0.4949/0.9343/1.3182
0 1011 0.29835283756256104
1 1011 0.2950754761695862
2 1011 0.32971474528312683
3 1011 0.442781537771225
val - Global loss: 0.341481    Embedding norm: 1.0000   Triplets (all/active): 252.8/61081.8
Pos dist (min/mean/max): 0.1865/0.5638/1.0798   Neg dist (min/mean/max): 0.2005/0.7349/1.3638
0 25113 0.45588618516921997
1 25113 0.08613106608390808
2 25113 0.0
3 25113 0.40315911173820496
4 25113 0.41422468423843384
5 25113 0.0
6 25113 0.18788830935955048
7 25113 0.7555225491523743
8 25113 0.05066584795713425
9 25113 0.22945979237556458
10 25113 0.5179757475852966
11 25113 0.0
12 25113 0.4400287866592407
13 25113 0.05899764224886894
14 25113 0.196999192237854
15 25113 0.17923112213611603
16 25113 0.14250774681568146
17 25113 0.14329499006271362
18 25113 0.14919227361679077
19 25113 0.018792882561683655
20 25113 0.0
21 25113 0.27800461649894714
22 25113 0.017187757417559624
23 25113 0.0548810251057148
24 25113 0.025810662657022476
25 25113 0.24497303366661072
26 25113 0.2900654375553131
27 25113 0.07405532896518707
28 25113 0.14886589348316193
29 25113 0.2014954835176468
30 25113 0.0
31 25113 0.5947870016098022
32 25113 0.0602446086704731
33 25113 0.2239348143339157
34 25113 0.43813735246658325
35 25113 0.12727774679660797
36 25113 0.20897507667541504
37 25113 0.6242749691009521
38 25113 0.0
39 25113 0.2544631063938141
40 25113 0.0
41 25113 0.3030783236026764
42 25113 0.2327745258808136
43 25113 0.2505605220794678
44 25113 0.13832050561904907
45 25113 0.0616530142724514
46 25113 0.24645397067070007
47 25113 0.12823323905467987
48 25113 0.10961152613162994
49 25113 0.04326255992054939
50 25113 0.07135520130395889
51 25113 0.03579059615731239
52 25113 0.2850993573665619
53 25113 0.0
54 25113 0.061786752194166183
55 25113 0.0
56 25113 0.21383512020111084
57 25113 0.0
58 25113 0.2728656530380249
59 25113 0.2478717565536499
60 25113 0.0
61 25113 0.1851666420698166
62 25113 0.019692057743668556
63 25113 0.058295704424381256
64 25113 0.22836726903915405
65 25113 0.1393740475177765
66 25113 0.014975081197917461
67 25113 0.0
68 25113 0.12391438335180283
69 25113 0.0
70 25113 0.32236480712890625
71 25113 0.15521906316280365
72 25113 0.06460516154766083
73 25113 0.06079689785838127
74 25113 0.0315108597278595
75 25113 0.5037887692451477
76 25113 0.03194157034158707
77 25113 0.28343212604522705
78 25113 0.25766482949256897
79 25113 0.08079557865858078
80 25113 0.11373729258775711
81 25113 0.0
82 25113 0.2791830003261566
83 25113 0.07334668189287186
84 25113 0.024080118164420128
85 25113 0.30613577365875244
86 25113 0.07607520371675491
87 25113 0.06342897564172745
88 25113 0.3225589394569397
89 25113 0.1486063152551651
90 25113 0.0
91 25113 0.07671266794204712
92 25113 0.0
93 25113 0.0
94 25113 0.00888168253004551
95 25113 0.06221549212932587
96 25113 0.0
97 25113 0.47621819376945496
98 25113 0.07962223142385483
train - Global loss: 0.158310    Embedding norm: 1.0000   Triplets (all/active): 253.7/14202.5
Pos dist (min/mean/max): 0.3476/0.5624/0.9367   Neg dist (min/mean/max): 0.6929/1.1816/1.5444
0 1011 0.34554633498191833
1 1011 0.35183459520339966
2 1011 0.370872437953949
3 1011 0.4605684280395508
val - Global loss: 0.382205    Embedding norm: 1.0000   Triplets (all/active): 252.8/61083.2
Pos dist (min/mean/max): 0.2176/0.6426/1.1625   Neg dist (min/mean/max): 0.1911/0.8137/1.4788
0 25113 0.10838832706212997
1 25113 0.07318171113729477
2 25113 0.019024072214961052
3 25113 0.666782796382904
4 25113 0.24703845381736755
5 25113 0.0
6 25113 0.10610587149858475
7 25113 0.15316171944141388
8 25113 0.0
9 25113 0.23111627995967865
10 25113 0.30365797877311707
11 25113 0.0
12 25113 0.5544308423995972
13 25113 0.03312703222036362
14 25113 0.04321819171309471
15 25113 0.12715385854244232
16 25113 0.12092974036931992
17 25113 0.1069498211145401
18 25113 0.1287253350019455
19 25113 0.0
20 25113 0.0
21 25113 0.5221031904220581
22 25113 0.016789047047495842
23 25113 0.09104152023792267
24 25113 0.0
25 25113 0.31372520327568054
26 25113 0.10917551070451736
27 25113 0.05566057935357094
28 25113 0.13452033698558807
29 25113 0.12528513371944427
30 25113 0.0
31 25113 0.46510112285614014
32 25113 0.033649761229753494
33 25113 0.07865845412015915
34 25113 0.36372044682502747
35 25113 0.15225596725940704
36 25113 0.08614293485879898
37 25113 0.46557989716529846
38 25113 0.0
39 25113 0.28168976306915283
40 25113 0.0
41 25113 0.2816460430622101
42 25113 0.28412753343582153
43 25113 0.1792742908000946
44 25113 0.10219975560903549
45 25113 0.07210516929626465
46 25113 0.14175653457641602
47 25113 0.062342800199985504
48 25113 0.0778282955288887
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.187979057431221
53 25113 0.0
54 25113 0.04213958606123924
55 25113 0.0
56 25113 0.09995101392269135
57 25113 0.0
58 25113 0.18778476119041443
59 25113 0.0965755432844162
60 25113 0.04175303131341934
61 25113 0.18519631028175354
62 25113 0.019815143197774887
63 25113 0.021219944581389427
64 25113 0.2064952403306961
65 25113 0.07156908512115479
66 25113 0.0
67 25113 0.0
68 25113 0.08305624127388
69 25113 0.0
70 25113 0.2531704306602478
71 25113 0.11629480868577957
72 25113 0.04530145972967148
73 25113 0.05175573378801346
74 25113 0.02183116413652897
75 25113 0.42409151792526245
76 25113 0.0
77 25113 0.29931190609931946
78 25113 0.06670159846544266
79 25113 0.045588959008455276
80 25113 0.12032657861709595
81 25113 0.0
82 25113 0.25232231616973877
83 25113 0.04409768059849739
84 25113 0.0
85 25113 0.2874009609222412
86 25113 0.11328186839818954
87 25113 0.043061476200819016
88 25113 0.29083478450775146
89 25113 0.08113260567188263
90 25113 0.0
91 25113 0.054213009774684906
92 25113 0.02041449397802353
93 25113 0.0
94 25113 0.012895658612251282
95 25113 0.027274413034319878
96 25113 0.0
97 25113 0.42769408226013184
98 25113 0.031844500452280045
train - Global loss: 0.120139    Embedding norm: 1.0000   Triplets (all/active): 253.7/10262.4
Pos dist (min/mean/max): 0.3670/0.5604/0.8871   Neg dist (min/mean/max): 0.7469/1.2180/1.5755
0 1011 0.28079625964164734
1 1011 0.3172469139099121
2 1011 0.32193252444267273
3 1011 0.38976147770881653
val - Global loss: 0.327434    Embedding norm: 1.0000   Triplets (all/active): 252.8/61495.0
Pos dist (min/mean/max): 0.2627/0.6239/1.0982   Neg dist (min/mean/max): 0.2512/0.8050/1.3925
0 25113 0.06686902791261673
1 25113 0.000920906662940979
2 25113 0.0
3 25113 0.29704150557518005
4 25113 0.03897056356072426
5 25113 0.0
6 25113 0.056999173015356064
7 25113 0.18943366408348083
8 25113 0.0
9 25113 0.18666471540927887
10 25113 0.05873706564307213
11 25113 0.0
12 25113 0.5596657991409302
13 25113 0.014263337478041649
14 25113 0.04074300825595856
15 25113 0.09399265050888062
16 25113 0.12454015016555786
17 25113 0.039450425654649734
18 25113 0.020627453923225403
19 25113 0.0
20 25113 0.0
21 25113 0.3191354274749756
22 25113 0.021262837573885918
23 25113 0.029252957552671432
24 25113 0.004322662949562073
25 25113 0.18518073856830597
26 25113 0.06369224935770035
27 25113 0.07452214509248734
28 25113 0.1309979408979416
29 25113 0.0653911679983139
30 25113 0.0
31 25113 0.6269959807395935
32 25113 0.023524591699242592
33 25113 0.017324110493063927
34 25113 0.4299023449420929
35 25113 0.1016424223780632
36 25113 0.03724502772092819
37 25113 0.7070899605751038
38 25113 0.0
39 25113 0.2947427034378052
40 25113 0.0
41 25113 0.25524118542671204
42 25113 0.18798372149467468
43 25113 0.08895187824964523
44 25113 0.11478903144598007
45 25113 0.02233230695128441
46 25113 0.06169377639889717
47 25113 0.06178165227174759
48 25113 0.07455114275217056
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.3145005702972412
53 25113 0.0
54 25113 0.039600737392902374
55 25113 0.0
56 25113 0.07705201953649521
57 25113 0.0
58 25113 0.1721237599849701
59 25113 0.07586881518363953
60 25113 0.0
61 25113 0.25969356298446655
62 25113 0.0
63 25113 0.0
64 25113 0.2766953408718109
65 25113 0.16685420274734497
66 25113 0.0
67 25113 0.0
68 25113 0.08475867658853531
69 25113 0.0
70 25113 0.39444488286972046
71 25113 0.07581295073032379
72 25113 0.03159769997000694
73 25113 0.06330447643995285
74 25113 0.03273443505167961
75 25113 0.3438578248023987
76 25113 0.0
77 25113 0.2715208828449249
78 25113 0.027207907289266586
79 25113 0.04083132743835449
80 25113 0.07810381799936295
81 25113 0.017141783609986305
82 25113 0.2044306844472885
83 25113 0.02267078496515751
84 25113 0.03539778292179108
85 25113 0.2792814373970032
86 25113 0.052743129432201385
87 25113 0.035501040518283844
88 25113 0.23581300675868988
89 25113 0.10370442271232605
90 25113 0.0
91 25113 0.04650826379656792
92 25113 0.0
93 25113 0.029249683022499084
94 25113 0.0
95 25113 0.055114660412073135
96 25113 0.0
97 25113 0.4226864278316498
98 25113 0.07721090316772461
train - Global loss: 0.103358    Embedding norm: 1.0000   Triplets (all/active): 253.7/7756.9
Pos dist (min/mean/max): 0.3553/0.5404/0.8559   Neg dist (min/mean/max): 0.7604/1.2277/1.5810
0 1011 0.35234037041664124
1 1011 0.3273536264896393
2 1011 0.3660741150379181
3 1011 0.40506064891815186
val - Global loss: 0.362707    Embedding norm: 1.0000   Triplets (all/active): 252.8/61467.0
Pos dist (min/mean/max): 0.2941/0.6851/1.1351   Neg dist (min/mean/max): 0.2935/0.8439/1.4252
0 25113 0.03846427798271179
1 25113 0.024628445506095886
2 25113 0.014234709553420544
3 25113 0.1672014445066452
4 25113 0.03815188258886337
5 25113 0.0
6 25113 0.02986191213130951
7 25113 0.06641662865877151
8 25113 0.0
9 25113 0.15371401607990265
10 25113 0.04475801810622215
11 25113 0.0
12 25113 0.49384453892707825
13 25113 0.01377406157553196
14 25113 0.006521835923194885
15 25113 0.11012749373912811
16 25113 0.06082789972424507
17 25113 0.06149165704846382
18 25113 0.036298967897892
19 25113 0.0
20 25113 0.0
21 25113 0.47777748107910156
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0898381918668747
26 25113 0.08126482367515564
27 25113 0.036964431405067444
28 25113 0.09688664227724075
29 25113 0.04042590409517288
30 25113 0.0
31 25113 0.37576115131378174
32 25113 0.0250933188945055
33 25113 0.07511494308710098
34 25113 0.28844648599624634
35 25113 0.16645000874996185
36 25113 0.0
37 25113 0.5690881013870239
38 25113 0.0
39 25113 0.22940406203269958
40 25113 0.028109397739171982
41 25113 0.2385927140712738
42 25113 0.2398076206445694
43 25113 0.05583322048187256
44 25113 0.09256558120250702
45 25113 0.03398954123258591
46 25113 0.029009731486439705
47 25113 0.03834392875432968
48 25113 0.04366309195756912
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.14263661205768585
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.03774811327457428
57 25113 0.0
58 25113 0.15424863994121552
59 25113 0.04738011211156845
60 25113 0.0
61 25113 0.18946322798728943
62 25113 0.0
63 25113 0.016096195206046104
64 25113 0.2537180483341217
65 25113 0.04384535551071167
66 25113 0.0
67 25113 0.0
68 25113 0.028572889044880867
69 25113 0.03161856159567833
70 25113 0.2975664436817169
71 25113 0.012345992028713226
72 25113 0.0
73 25113 0.024356108158826828
74 25113 0.0
75 25113 0.1922651082277298
76 25113 0.011264722794294357
77 25113 0.316828191280365
78 25113 0.017383167520165443
79 25113 0.020439831539988518
80 25113 0.07202209532260895
81 25113 0.0
82 25113 0.18876749277114868
83 25113 0.0
84 25113 0.013486112467944622
85 25113 0.21067380905151367
86 25113 0.039175521582365036
87 25113 0.05997850000858307
88 25113 0.17374318838119507
89 25113 0.08382236957550049
90 25113 0.0
91 25113 0.016731593757867813
92 25113 0.0
93 25113 0.0
94 25113 0.04114227369427681
95 25113 0.05026521161198616
96 25113 0.03039076179265976
97 25113 0.34976306557655334
98 25113 0.002182498574256897
train - Global loss: 0.079623    Embedding norm: 1.0000   Triplets (all/active): 253.7/6510.7
Pos dist (min/mean/max): 0.3573/0.5207/0.7872   Neg dist (min/mean/max): 0.7760/1.2271/1.5707
0 1011 0.3070856034755707
1 1011 0.3421671390533447
2 1011 0.3449501395225525
3 1011 0.4373653829097748
val - Global loss: 0.357892    Embedding norm: 1.0000   Triplets (all/active): 252.8/60767.8
Pos dist (min/mean/max): 0.2906/0.6801/1.1692   Neg dist (min/mean/max): 0.2696/0.8584/1.4773
0 25113 0.08199384063482285
1 25113 0.0
2 25113 0.0
3 25113 0.17745397984981537
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0584859773516655
8 25113 0.016925225034356117
9 25113 0.10415830463171005
10 25113 0.0092637212947011
11 25113 0.012297764420509338
12 25113 0.5608106851577759
13 25113 0.027182672172784805
14 25113 0.0
15 25113 0.09771004319190979
16 25113 0.06519173085689545
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.20091938972473145
22 25113 0.03791484981775284
23 25113 0.01802540011703968
24 25113 0.0
25 25113 0.01902788132429123
26 25113 0.058230482041835785
27 25113 0.004175499081611633
28 25113 0.08836119621992111
29 25113 0.03291451558470726
30 25113 0.0
31 25113 0.5232107639312744
32 25113 0.029069814831018448
33 25113 0.0
34 25113 0.29861244559288025
35 25113 0.046517498791217804
36 25113 0.025771021842956543
37 25113 0.4823000729084015
38 25113 0.0
39 25113 0.2424999624490738
40 25113 0.0
41 25113 0.14295142889022827
42 25113 0.14768262207508087
43 25113 0.1553160548210144
44 25113 0.0655243843793869
45 25113 0.0
46 25113 0.02636732906103134
47 25113 0.03827457129955292
48 25113 0.05071249231696129
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.09902269393205643
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.03403297811746597
57 25113 0.0
58 25113 0.0857456773519516
59 25113 0.036571282893419266
60 25113 0.0
61 25113 0.10635701566934586
62 25113 0.028587065637111664
63 25113 0.0049092648550868034
64 25113 0.3043748736381531
65 25113 0.05101704224944115
66 25113 0.0
67 25113 0.0
68 25113 0.021806692704558372
69 25113 0.0
70 25113 0.12419643998146057
71 25113 0.06122288107872009
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.150735542178154
76 25113 0.01940724439918995
77 25113 0.2752300500869751
78 25113 0.02485699951648712
79 25113 0.008559051901102066
80 25113 0.06823604553937912
81 25113 0.0
82 25113 0.16148453950881958
83 25113 0.013032004237174988
84 25113 0.0
85 25113 0.14702026546001434
86 25113 0.04154401272535324
87 25113 0.019946135580539703
88 25113 0.1688137799501419
89 25113 0.030498947948217392
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.029289722442626953
96 25113 0.0
97 25113 0.25664398074150085
98 25113 0.08647450804710388
train - Global loss: 0.064702    Embedding norm: 1.0000   Triplets (all/active): 253.7/5036.5
Pos dist (min/mean/max): 0.3531/0.5063/0.7554   Neg dist (min/mean/max): 0.7927/1.2441/1.5905
0 1011 0.35017335414886475
1 1011 0.2998957633972168
2 1011 0.3756525218486786
3 1011 0.4192076623439789
val - Global loss: 0.361232    Embedding norm: 1.0000   Triplets (all/active): 252.8/61314.2
Pos dist (min/mean/max): 0.2977/0.6632/1.0821   Neg dist (min/mean/max): 0.2741/0.8057/1.3281
0 25113 0.07434245944023132
1 25113 0.013897066004574299
2 25113 0.00873430073261261
3 25113 0.037595946341753006
4 25113 0.0
5 25113 0.009881519712507725
6 25113 0.0
7 25113 0.1034993901848793
8 25113 0.0
9 25113 0.14080141484737396
10 25113 0.016030477359890938
11 25113 0.0
12 25113 0.42105573415756226
13 25113 0.011761382222175598
14 25113 0.0
15 25113 0.0755198672413826
16 25113 0.05702422559261322
17 25113 0.018041862174868584
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.3496014475822449
22 25113 0.0
23 25113 0.042981140315532684
24 25113 0.0
25 25113 0.06666366755962372
26 25113 0.05477238446474075
27 25113 0.01792784035205841
28 25113 0.09753149002790451
29 25113 0.04975635185837746
30 25113 0.0
31 25113 0.4865451753139496
32 25113 0.010615721344947815
33 25113 0.0
34 25113 0.13907067477703094
35 25113 0.040770404040813446
36 25113 0.024204513058066368
37 25113 0.5223609209060669
38 25113 0.0
39 25113 0.23707294464111328
40 25113 0.0
41 25113 0.12691451609134674
42 25113 0.1539129912853241
43 25113 0.05513296648859978
44 25113 0.07158786803483963
45 25113 0.032959241420030594
46 25113 0.02242259494960308
47 25113 0.02823067456483841
48 25113 0.0227873083204031
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.1696762889623642
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.015480275265872478
57 25113 0.0
58 25113 0.13770094513893127
59 25113 0.059440433979034424
60 25113 0.0
61 25113 0.28089022636413574
62 25113 0.0
63 25113 0.008652135729789734
64 25113 0.21904586255550385
65 25113 0.04492948576807976
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.19827115535736084
71 25113 0.024196408689022064
72 25113 0.0
73 25113 0.007780179381370544
74 25113 0.0
75 25113 0.14390058815479279
76 25113 0.0
77 25113 0.3190426826477051
78 25113 0.019413581117987633
79 25113 0.03814200684428215
80 25113 0.030926821753382683
81 25113 0.0
82 25113 0.12765464186668396
83 25113 0.02258647046983242
84 25113 0.0
85 25113 0.1327991485595703
86 25113 0.03959903120994568
87 25113 0.006462171673774719
88 25113 0.10134781897068024
89 25113 0.031813591718673706
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.00167000200599432
95 25113 0.037643495947122574
96 25113 0.0
97 25113 0.2069917768239975
98 25113 0.009555324912071228
train - Global loss: 0.061390    Embedding norm: 1.0000   Triplets (all/active): 253.7/4916.6
Pos dist (min/mean/max): 0.3254/0.4698/0.7101   Neg dist (min/mean/max): 0.7706/1.1937/1.5376
0 1011 0.3272528052330017
1 1011 0.3135272264480591
2 1011 0.37741950154304504
3 1011 0.443491131067276
val - Global loss: 0.365423    Embedding norm: 1.0000   Triplets (all/active): 252.8/61171.8
Pos dist (min/mean/max): 0.3176/0.7141/1.1941   Neg dist (min/mean/max): 0.2882/0.8732/1.3971
0 25113 0.0
1 25113 0.02505958080291748
2 25113 0.0
3 25113 0.05034308508038521
4 25113 0.01620788872241974
5 25113 0.0
6 25113 0.03534660488367081
7 25113 0.054247092455625534
8 25113 0.0
9 25113 0.10719779878854752
10 25113 0.0
11 25113 0.0
12 25113 0.47578543424606323
13 25113 0.0
14 25113 0.0
15 25113 0.03845134750008583
16 25113 0.01229642890393734
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.1988690197467804
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.029307756572961807
26 25113 0.09842686355113983
27 25113 0.0
28 25113 0.05827092379331589
29 25113 0.028157122433185577
30 25113 0.0
31 25113 0.3266879618167877
32 25113 0.013130448758602142
33 25113 0.0
34 25113 0.09093474596738815
35 25113 0.05002344027161598
36 25113 0.0
37 25113 0.5626403093338013
38 25113 0.0
39 25113 0.24571390450000763
40 25113 0.0
41 25113 0.11625795811414719
42 25113 0.11635653674602509
43 25113 0.07491911202669144
44 25113 0.057014986872673035
45 25113 0.018751133233308792
46 25113 0.03405335173010826
47 25113 0.027328714728355408
48 25113 0.0
49 25113 0.0
50 25113 0.0028672367334365845
51 25113 0.0
52 25113 0.2451746165752411
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.056735679507255554
57 25113 0.0
58 25113 0.08373253792524338
59 25113 0.03656364977359772
60 25113 0.0
61 25113 0.2026946246623993
62 25113 0.0
63 25113 0.0
64 25113 0.19860967993736267
65 25113 0.005904143210500479
66 25113 0.0
67 25113 0.0
68 25113 0.019754424691200256
69 25113 0.0
70 25113 0.08028406649827957
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.06058356538414955
76 25113 0.009046133607625961
77 25113 0.25438129901885986
78 25113 0.0
79 25113 0.0
80 25113 0.028699593618512154
81 25113 0.0
82 25113 0.08745508641004562
83 25113 0.0
84 25113 0.0
85 25113 0.1030096486210823
86 25113 0.022787276655435562
87 25113 0.006991937756538391
88 25113 0.09493405371904373
89 25113 0.0
90 25113 0.0
91 25113 0.006098493933677673
92 25113 0.0
93 25113 0.0
94 25113 0.03686153143644333
95 25113 0.03565447777509689
96 25113 0.0
97 25113 0.1376868486404419
98 25113 0.0
train - Global loss: 0.048266    Embedding norm: 1.0000   Triplets (all/active): 253.7/4088.1
Pos dist (min/mean/max): 0.3197/0.4647/0.6880   Neg dist (min/mean/max): 0.7859/1.2377/1.5716
0 1011 0.3417987823486328
1 1011 0.3244863450527191
2 1011 0.4017171561717987
3 1011 0.4381657838821411
val - Global loss: 0.376542    Embedding norm: 1.0000   Triplets (all/active): 252.8/60756.8
Pos dist (min/mean/max): 0.3722/0.7847/1.3214   Neg dist (min/mean/max): 0.3715/0.9729/1.5076
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.026766575872898102
4 25113 0.0
5 25113 0.0
6 25113 0.04040137305855751
7 25113 0.014496617019176483
8 25113 0.0
9 25113 0.09033814072608948
10 25113 0.0
11 25113 0.0
12 25113 0.2695600986480713
13 25113 0.0
14 25113 3.151595592498779e-05
15 25113 0.0593780055642128
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.16304095089435577
22 25113 0.0
23 25113 0.027680160477757454
24 25113 0.0
25 25113 0.0399816669523716
26 25113 0.046793874353170395
27 25113 0.0
28 25113 0.07953047007322311
29 25113 0.006334230303764343
30 25113 0.0
31 25113 0.25918909907341003
32 25113 0.03278225287795067
33 25113 0.0
34 25113 0.10144990682601929
35 25113 0.04288075864315033
36 25113 0.0
37 25113 0.4202255308628082
38 25113 0.0
39 25113 0.17599934339523315
40 25113 0.0
41 25113 0.10343063622713089
42 25113 0.10276685655117035
43 25113 0.04574170336127281
44 25113 0.08221849799156189
45 25113 0.0
46 25113 0.0
47 25113 0.02436140738427639
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.09214243292808533
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.011875107884407043
57 25113 0.0
58 25113 0.04196067526936531
59 25113 0.02018456906080246
60 25113 0.0
61 25113 0.0940675362944603
62 25113 0.0
63 25113 0.0
64 25113 0.3620040714740753
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.018631553277373314
69 25113 0.0
70 25113 0.13036520779132843
71 25113 0.044188227504491806
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.03215401619672775
76 25113 0.0
77 25113 0.17242813110351562
78 25113 0.026117166504263878
79 25113 0.012874022126197815
80 25113 0.02458110824227333
81 25113 0.0
82 25113 0.0739225521683693
83 25113 0.0
84 25113 0.0
85 25113 0.08826470375061035
86 25113 0.013527968898415565
87 25113 0.02150111086666584
88 25113 0.05060071870684624
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.02196337841451168
96 25113 0.0
97 25113 0.08919192850589752
98 25113 0.1140180453658104
train - Global loss: 0.038504    Embedding norm: 1.0000   Triplets (all/active): 253.7/2702.7
Pos dist (min/mean/max): 0.3215/0.4611/0.6712   Neg dist (min/mean/max): 0.8063/1.2502/1.5848
0 1011 0.3580802083015442
1 1011 0.32945993542671204
2 1011 0.4012395739555359
3 1011 0.4174633324146271
val - Global loss: 0.376561    Embedding norm: 1.0000   Triplets (all/active): 252.8/60745.0
Pos dist (min/mean/max): 0.3282/0.7439/1.2527   Neg dist (min/mean/max): 0.3063/0.9185/1.4385
0 25113 0.010636880993843079
1 25113 0.0
2 25113 0.0
3 25113 0.03542812913656235
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.07937221229076385
10 25113 0.0
11 25113 0.0
12 25113 0.3076228201389313
13 25113 0.0
14 25113 0.0
15 25113 0.0314333438873291
16 25113 0.028990045189857483
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.13468611240386963
22 25113 0.0063637481071054935
23 25113 0.0
24 25113 0.0
25 25113 0.025466199964284897
26 25113 0.04205749183893204
27 25113 0.0
28 25113 0.03170887380838394
29 25113 0.0
30 25113 0.0
31 25113 0.19703733921051025
32 25113 0.0
33 25113 0.0
34 25113 0.07956106215715408
35 25113 0.0
36 25113 0.0
37 25113 0.3585284650325775
38 25113 0.0
39 25113 0.2159944474697113
40 25113 0.0
41 25113 0.04160251468420029
42 25113 0.035942401736974716
43 25113 0.04786977171897888
44 25113 0.06467312574386597
45 25113 0.0
46 25113 0.0
47 25113 0.011458276771008968
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.11368735879659653
53 25113 0.0
54 25113 0.002183288335800171
55 25113 0.006633451674133539
56 25113 0.0
57 25113 0.0
58 25113 0.04980272054672241
59 25113 0.011476241052150726
60 25113 0.0
61 25113 0.06302278488874435
62 25113 0.0
63 25113 0.0
64 25113 0.3048086166381836
65 25113 0.03759995847940445
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.1012955978512764
71 25113 0.0
72 25113 0.002955034375190735
73 25113 0.0
74 25113 0.0
75 25113 0.06928335130214691
76 25113 0.0
77 25113 0.08842577785253525
78 25113 0.013162369839847088
79 25113 0.0
80 25113 0.020822808146476746
81 25113 0.0
82 25113 0.0716249868273735
83 25113 0.0
84 25113 0.06451331824064255
85 25113 0.08393832296133041
86 25113 0.0
87 25113 0.0
88 25113 0.07629413157701492
89 25113 0.030513416975736618
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.06759830564260483
98 25113 0.0
train - Global loss: 0.030970    Embedding norm: 1.0000   Triplets (all/active): 253.7/2525.6
Pos dist (min/mean/max): 0.3174/0.4530/0.6458   Neg dist (min/mean/max): 0.8142/1.2481/1.5823
0 1011 0.3048716187477112
1 1011 0.3182891309261322
2 1011 0.35898470878601074
3 1011 0.37986892461776733
val - Global loss: 0.340504    Embedding norm: 1.0000   Triplets (all/active): 252.8/61035.5
Pos dist (min/mean/max): 0.3182/0.6914/1.1939   Neg dist (min/mean/max): 0.2942/0.8869/1.5047
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.018337532877922058
7 25113 0.03574562445282936
8 25113 0.0
9 25113 0.07189452648162842
10 25113 0.0
11 25113 0.0
12 25113 0.23406235873699188
13 25113 0.0
14 25113 0.0
15 25113 0.05083446949720383
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.1695595234632492
22 25113 0.0
23 25113 0.038497939705848694
24 25113 0.03200072795152664
25 25113 0.06197283789515495
26 25113 0.0
27 25113 0.0
28 25113 0.027364255860447884
29 25113 0.0
30 25113 0.0
31 25113 0.1304285079240799
32 25113 0.0
33 25113 0.0
34 25113 0.059271689504384995
35 25113 0.0
36 25113 0.0
37 25113 0.230827197432518
38 25113 0.0
39 25113 0.1735796332359314
40 25113 0.0
41 25113 0.037098996341228485
42 25113 0.04026433452963829
43 25113 0.014701321721076965
44 25113 0.03547503799200058
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.14167506992816925
53 25113 0.026160990819334984
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.08894003927707672
59 25113 0.0
60 25113 0.0
61 25113 0.053295306861400604
62 25113 0.0
63 25113 0.0
64 25113 0.18484362959861755
65 25113 0.010435312986373901
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.08029080927371979
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.09078757464885712
76 25113 0.0028982311487197876
77 25113 0.03004457615315914
78 25113 0.0
79 25113 0.021520432084798813
80 25113 0.04036305099725723
81 25113 0.0
82 25113 0.04886458441615105
83 25113 0.0
84 25113 0.0
85 25113 0.07011225074529648
86 25113 0.0
87 25113 0.0
88 25113 0.04114929586648941
89 25113 0.0
90 25113 0.0
91 25113 0.025182079523801804
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.015038326382637024
97 25113 0.047534387558698654
98 25113 0.053895607590675354
train - Global loss: 0.025606    Embedding norm: 1.0000   Triplets (all/active): 253.7/1916.8
Pos dist (min/mean/max): 0.3137/0.4491/0.6483   Neg dist (min/mean/max): 0.8358/1.2704/1.5939
0 1011 0.30740055441856384
1 1011 0.32997092604637146
2 1011 0.355258971452713
3 1011 0.4059603810310364
val - Global loss: 0.349648    Embedding norm: 1.0000   Triplets (all/active): 252.8/60520.0
Pos dist (min/mean/max): 0.3213/0.7277/1.1986   Neg dist (min/mean/max): 0.2940/0.9257/1.4363
0 25113 0.018658697605133057
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.046103209257125854
10 25113 0.0
11 25113 0.0
12 25113 0.11518324166536331
13 25113 0.0
14 25113 0.0
15 25113 0.024374879896640778
16 25113 0.0
17 25113 0.021477170288562775
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.07586807757616043
22 25113 0.0
23 25113 0.010326703079044819
24 25113 0.0
25 25113 0.0
26 25113 0.024311915040016174
27 25113 0.0
28 25113 0.036472171545028687
29 25113 0.0
30 25113 0.0
31 25113 0.13424842059612274
32 25113 0.0
33 25113 0.0
34 25113 0.03731337934732437
35 25113 0.049657002091407776
36 25113 0.0
37 25113 0.31312739849090576
38 25113 0.0
39 25113 0.23705293238162994
40 25113 0.0
41 25113 0.03942374512553215
42 25113 0.01825219765305519
43 25113 0.011946424841880798
44 25113 0.017483627423644066
45 25113 0.0
46 25113 0.0
47 25113 0.0069852471351623535
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.18574382364749908
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.05866162106394768
59 25113 0.0
60 25113 0.004497304558753967
61 25113 0.09711923450231552
62 25113 0.0
63 25113 0.0
64 25113 0.25315916538238525
65 25113 0.0026973336935043335
66 25113 0.0
67 25113 0.0
68 25113 0.014523640275001526
69 25113 0.0
70 25113 0.07523490488529205
71 25113 0.009874081239104271
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.029310813173651695
76 25113 0.0
77 25113 0.07745036482810974
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.025230975821614265
83 25113 0.0
84 25113 0.0
85 25113 0.06738116592168808
86 25113 0.0
87 25113 0.0
88 25113 0.029369890689849854
89 25113 0.0
90 25113 0.0
91 25113 0.02257559821009636
92 25113 0.0
93 25113 0.0
94 25113 0.024849137291312218
95 25113 0.0
96 25113 0.03989006578922272
97 25113 0.0
98 25113 0.0
train - Global loss: 0.022786    Embedding norm: 1.0000   Triplets (all/active): 253.7/1699.7
Pos dist (min/mean/max): 0.3075/0.4354/0.6262   Neg dist (min/mean/max): 0.8260/1.2490/1.5628
0 1011 0.2866564989089966
1 1011 0.2793141305446625
2 1011 0.3287631869316101
3 1011 0.36455413699150085
val - Global loss: 0.314822    Embedding norm: 1.0000   Triplets (all/active): 252.8/61559.0
Pos dist (min/mean/max): 0.3122/0.6459/1.0767   Neg dist (min/mean/max): 0.3177/0.8296/1.3329
0 25113 0.0
1 25113 0.0060739666223526
2 25113 0.0
3 25113 0.0
4 25113 0.05021139606833458
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.025428924709558487
10 25113 0.0
11 25113 0.0
12 25113 0.1259888857603073
13 25113 0.0
14 25113 0.0
15 25113 0.030363965779542923
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.13821235299110413
22 25113 0.0
23 25113 0.016532694920897484
24 25113 0.0
25 25113 0.023419734090566635
26 25113 0.0
27 25113 0.0
28 25113 0.026121288537979126
29 25113 0.0
30 25113 0.0
31 25113 0.08672976493835449
32 25113 0.0
33 25113 0.0
34 25113 0.03138191998004913
35 25113 0.0
36 25113 0.0
37 25113 0.11517062783241272
38 25113 0.0
39 25113 0.2744441330432892
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.018313422799110413
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.15818879008293152
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.04372106119990349
59 25113 0.01842406950891018
60 25113 0.0
61 25113 0.057515814900398254
62 25113 0.0
63 25113 0.0
64 25113 0.22436290979385376
65 25113 0.025268128141760826
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.08122814446687698
71 25113 0.014580151066184044
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.024158716201782227
78 25113 0.0
79 25113 0.0
80 25113 0.025152992457151413
81 25113 0.012018393725156784
82 25113 0.04900405928492546
83 25113 0.0
84 25113 0.0
85 25113 0.04112659767270088
86 25113 0.0
87 25113 0.0
88 25113 0.02686411142349243
89 25113 0.0
90 25113 0.0
91 25113 0.0003162175416946411
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.03679792582988739
98 25113 0.078866146504879
train - Global loss: 0.019050    Embedding norm: 1.0000   Triplets (all/active): 253.7/1251.0
Pos dist (min/mean/max): 0.2993/0.4252/0.6101   Neg dist (min/mean/max): 0.8570/1.2929/1.6070
0 1011 0.3027825653553009
1 1011 0.30924174189567566
2 1011 0.3268726170063019
3 1011 0.42722955346107483
val - Global loss: 0.341532    Embedding norm: 1.0000   Triplets (all/active): 252.8/60651.2
Pos dist (min/mean/max): 0.3692/0.7347/1.1548   Neg dist (min/mean/max): 0.3596/0.9300/1.4871
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.03324732184410095
10 25113 0.0
11 25113 0.0
12 25113 0.07730665802955627
13 25113 0.0
14 25113 0.0
15 25113 0.026470016688108444
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.07703888416290283
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.008689938113093376
26 25113 0.020771650597453117
27 25113 0.0
28 25113 0.0351698063313961
29 25113 0.011874452233314514
30 25113 0.0
31 25113 0.05096164345741272
32 25113 0.0
33 25113 0.0
34 25113 0.10351752489805222
35 25113 0.0
36 25113 0.0
37 25113 0.09511912614107132
38 25113 0.0
39 25113 0.17375440895557404
40 25113 0.0
41 25113 0.01928975246846676
42 25113 0.0
43 25113 0.0
44 25113 0.027677878737449646
45 25113 0.019182439893484116
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.08568448573350906
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.03390840068459511
59 25113 0.0
60 25113 0.0
61 25113 0.043294575065374374
62 25113 0.0
63 25113 0.0064557939767837524
64 25113 0.11548291891813278
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.025067482143640518
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0007553249597549438
76 25113 0.0
77 25113 0.018803324550390244
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.033063795417547226
86 25113 0.0
87 25113 0.0
88 25113 0.03804345056414604
89 25113 0.0
90 25113 0.0
91 25113 0.02209934964776039
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.017321165651082993
train - Global loss: 0.012324    Embedding norm: 1.0000   Triplets (all/active): 253.7/743.8
Pos dist (min/mean/max): 0.2875/0.4063/0.5752   Neg dist (min/mean/max): 0.8648/1.2964/1.6035
0 1011 0.3098925054073334
1 1011 0.27641937136650085
2 1011 0.3298811614513397
3 1011 0.37504884600639343
val - Global loss: 0.322810    Embedding norm: 1.0000   Triplets (all/active): 252.8/61135.2
Pos dist (min/mean/max): 0.3406/0.6814/1.0987   Neg dist (min/mean/max): 0.3133/0.8602/1.3794
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.053227029740810394
10 25113 0.0
11 25113 0.0
12 25113 0.06632411479949951
13 25113 0.0
14 25113 0.0
15 25113 0.03960004076361656
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.0427619069814682
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.020848440006375313
26 25113 0.022709110751748085
27 25113 0.0
28 25113 0.03075329028069973
29 25113 0.0
30 25113 0.0
31 25113 0.04925606772303581
32 25113 0.0
33 25113 0.0
34 25113 0.020360030233860016
35 25113 0.0
36 25113 0.0
37 25113 0.060160279273986816
38 25113 0.0
39 25113 0.12306707352399826
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.013486489653587341
44 25113 0.018196087330579758
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.12813712656497955
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0319531112909317
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.039626408368349075
62 25113 0.0
63 25113 0.0
64 25113 0.07032518088817596
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.018824413418769836
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.055036332458257675
76 25113 0.0
77 25113 0.0161280557513237
78 25113 0.0
79 25113 0.028403015807271004
80 25113 0.0
81 25113 0.0
82 25113 0.022214291617274284
83 25113 0.0
84 25113 0.0
85 25113 0.050528429448604584
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.027434244751930237
98 25113 0.06135569140315056
train - Global loss: 0.011219    Embedding norm: 1.0000   Triplets (all/active): 253.7/666.1
Pos dist (min/mean/max): 0.2756/0.3946/0.5661   Neg dist (min/mean/max): 0.8508/1.3029/1.6179
0 1011 0.29895880818367004
1 1011 0.32805147767066956
2 1011 0.3352062404155731
3 1011 0.3829904794692993
val - Global loss: 0.336302    Embedding norm: 1.0000   Triplets (all/active): 252.8/61111.2
Pos dist (min/mean/max): 0.3372/0.6954/1.1928   Neg dist (min/mean/max): 0.3440/0.8888/1.4511
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.043824974447488785
8 25113 0.0
9 25113 0.06340570002794266
10 25113 0.0
11 25113 0.0
12 25113 0.02291363663971424
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.06997501850128174
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.04686110094189644
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.01106061041355133
32 25113 0.0
33 25113 0.0
34 25113 0.0164639949798584
35 25113 0.0
36 25113 0.0
37 25113 0.07521044462919235
38 25113 0.0
39 25113 0.09759175032377243
40 25113 0.0009961873292922974
41 25113 0.0
42 25113 0.01157274842262268
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.12425407767295837
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.020587638020515442
59 25113 0.0
60 25113 0.0
61 25113 0.07786771655082703
62 25113 0.0
63 25113 0.011988595128059387
64 25113 0.08200494945049286
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.026515362784266472
69 25113 0.0
70 25113 0.03615831956267357
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.03670601174235344
76 25113 0.0
77 25113 0.06844203174114227
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.017872417345643044
83 25113 0.0
84 25113 0.0
85 25113 0.0
86 25113 0.0
87 25113 0.0
88 25113 0.028681471943855286
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
train - Global loss: 0.010010    Embedding norm: 1.0000   Triplets (all/active): 253.7/474.7
Pos dist (min/mean/max): 0.2789/0.4009/0.5815   Neg dist (min/mean/max): 0.8801/1.3323/1.6433
0 1011 0.3091554343700409
1 1011 0.3056967854499817
2 1011 0.3503682613372803
3 1011 0.37817904353141785
val - Global loss: 0.335850    Embedding norm: 1.0000   Triplets (all/active): 252.8/62116.5
Pos dist (min/mean/max): 0.3364/0.6917/1.1525   Neg dist (min/mean/max): 0.3418/0.8653/1.4385
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.04808466508984566
13 25113 0.0
14 25113 0.0
15 25113 0.014528051018714905
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.05541367083787918
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.017836514860391617
26 25113 0.039546988904476166
27 25113 0.0038337260484695435
28 25113 0.03598728030920029
29 25113 0.0
30 25113 0.0
31 25113 0.05764350667595863
32 25113 0.0
33 25113 0.0
34 25113 0.0266214981675148
35 25113 0.0
36 25113 0.0
37 25113 0.07487122714519501
38 25113 0.0
39 25113 0.2749376595020294
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.02819100208580494
44 25113 0.021575942635536194
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.04378179833292961
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.012432987801730633
62 25113 0.0
63 25113 0.0
64 25113 0.04802050068974495
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.04069984331727028
71 25113 0.0
72 25113 0.008481726050376892
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.0
83 25113 0.0
84 25113 0.0
85 25113 0.014301386661827564
86 25113 0.0
87 25113 0.0
88 25113 0.027206627652049065
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.007098041474819183
train - Global loss: 0.009102    Embedding norm: 1.0000   Triplets (all/active): 253.7/406.8
Pos dist (min/mean/max): 0.2650/0.3743/0.5347   Neg dist (min/mean/max): 0.8478/1.2942/1.6116
0 1011 0.2608163356781006
1 1011 0.24216753244400024
2 1011 0.2882750928401947
3 1011 0.33525052666664124
val - Global loss: 0.281627    Embedding norm: 1.0000   Triplets (all/active): 252.8/62655.5
Pos dist (min/mean/max): 0.2748/0.5505/0.8537   Neg dist (min/mean/max): 0.2844/0.6975/1.1168
0 25113 0.0
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.0
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.017783865332603455
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.014224067330360413
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.0
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.0
30 25113 0.0
31 25113 0.027037668973207474
32 25113 0.0
33 25113 0.0
34 25113 0.0
35 25113 0.0
36 25113 0.0
37 25113 0.029605180025100708
38 25113 0.0
39 25113 0.054589394479990005
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.0
45 25113 0.0
46 25113 0.0
47 25113 0.0
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.0
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.0
62 25113 0.0
63 25113 0.0
64 25113 0.08128540217876434
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.010463312268257141
71 25113 0.0
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.028083190321922302
77 25113 0.0
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.01914346218109131
83 25113 0.0
84 25113 0.0
85 25113 0.010968044400215149
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.0
98 25113 0.0
train - Global loss: 0.002961    Embedding norm: 1.0000   Triplets (all/active): 253.7/34.1
Pos dist (min/mean/max): 0.2706/0.3842/0.5502   Neg dist (min/mean/max): 0.9451/1.4184/1.6787
0 1011 0.2908230125904083
1 1011 0.26241859793663025
2 1011 0.318080335855484
3 1011 0.3646204471588135
val - Global loss: 0.308986    Embedding norm: 1.0000   Triplets (all/active): 252.8/62248.8
Pos dist (min/mean/max): 0.3061/0.5965/0.9740   Neg dist (min/mean/max): 0.2788/0.7378/1.2243
0 25113 0.03325187414884567
1 25113 0.0
2 25113 0.0
3 25113 0.0
4 25113 0.0
5 25113 0.0
6 25113 0.0
7 25113 0.0
8 25113 0.0
9 25113 0.05731968209147453
10 25113 0.0
11 25113 0.0
12 25113 0.0
13 25113 0.0
14 25113 0.0
15 25113 0.0
16 25113 0.0
17 25113 0.0
18 25113 0.0
19 25113 0.0
20 25113 0.0
21 25113 0.08380476385354996
22 25113 0.0
23 25113 0.0
24 25113 0.0
25 25113 0.020784547552466393
26 25113 0.0
27 25113 0.0
28 25113 0.0
29 25113 0.004738186951726675
30 25113 0.0
31 25113 0.0
32 25113 0.0
33 25113 0.0
34 25113 0.00873623788356781
35 25113 0.0
36 25113 0.0
37 25113 0.0330352708697319
38 25113 0.0
39 25113 0.041452936828136444
40 25113 0.0
41 25113 0.0
42 25113 0.0
43 25113 0.0
44 25113 0.03741651028394699
45 25113 0.0
46 25113 0.017390426248311996
47 25113 0.032027341425418854
48 25113 0.0
49 25113 0.0
50 25113 0.0
51 25113 0.0
52 25113 0.018239222466945648
53 25113 0.0
54 25113 0.0
55 25113 0.0
56 25113 0.0
57 25113 0.0
58 25113 0.0
59 25113 0.0
60 25113 0.0
61 25113 0.022980347275733948
62 25113 0.0
63 25113 0.0
64 25113 0.034758325666189194
65 25113 0.0
66 25113 0.0
67 25113 0.0
68 25113 0.0
69 25113 0.0
70 25113 0.03520134091377258
71 25113 0.000136449933052063
72 25113 0.0
73 25113 0.0
74 25113 0.0
75 25113 0.0
76 25113 0.0
77 25113 0.023380637168884277
78 25113 0.0
79 25113 0.0
80 25113 0.0
81 25113 0.0
82 25113 0.01022657286375761
83 25113 0.0
84 25113 0.016469037160277367
85 25113 0.032018113881349564
86 25113 0.0
87 25113 0.0
88 25113 0.0
89 25113 0.0
90 25113 0.0
91 25113 0.0
92 25113 0.0
93 25113 0.0
94 25113 0.0
95 25113 0.0
96 25113 0.0
97 25113 0.15502694249153137
98 25113 0.0
train - Global loss: 0.007257    Embedding norm: 1.0000   Triplets (all/active): 253.7/74.1
Pos dist (min/mean/max): 0.2687/0.3832/0.5538   Neg dist (min/mean/max): 0.9206/1.3947/1.6689
0 1011 0.30050355195999146
1 1011 0.30045661330223083
2 1011 0.37288811802864075
3 1011 0.41587111353874207
val - Global loss: 0.347430    Embedding norm: 1.0000   Triplets (all/active): 252.8/60949.0
Pos dist (min/mean/max): 0.3372/0.7086/1.2212   Neg dist (min/mean/max): 0.3243/0.9139/1.4639
Traceback (most recent call last):
  File "/code/RLoc/training/train.py", line 31, in <module>
    do_train(params, debug=args.debug, device=device)
  File "/code/RLoc/training/trainer.py", line 391, in do_train
    outputs = model(inputs, n_pos, n_neg)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 78, in parallel_apply
    thread.join()
  File "/usr/local/lib/python3.9/threading.py", line 1053, in join
    self._wait_for_tstate_lock()
  File "/usr/local/lib/python3.9/threading.py", line 1073, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt
